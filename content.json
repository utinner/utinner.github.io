{"meta":{"title":"代码乐园","subtitle":"一个默默无闻的代码搬运工","description":"一个默默无闻的代码搬运工(*^▽^*)","author":"JinPing","url":"https://utinner.gitee.io","root":"/"},"pages":[{"title":"about","date":"2020-08-03T03:47:32.000Z","updated":"2021-12-06T09:23:00.942Z","comments":true,"path":"about/index.html","permalink":"https://utinner.gitee.io/about/index.html","excerpt":"","text":""},{"title":"分类","date":"2023-03-26T10:29:45.841Z","updated":"2023-03-26T10:29:45.841Z","comments":false,"path":"categories/index.html","permalink":"https://utinner.gitee.io/categories/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2023-03-26T10:23:56.938Z","updated":"2023-03-26T10:23:56.938Z","comments":false,"path":"repository/index.html","permalink":"https://utinner.gitee.io/repository/index.html","excerpt":"","text":""},{"title":"标签","date":"2023-03-26T10:29:37.802Z","updated":"2023-03-26T10:29:37.802Z","comments":false,"path":"tags/index.html","permalink":"https://utinner.gitee.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"小记","slug":"小记","date":"2023-03-15T06:49:10.000Z","updated":"2023-03-15T06:50:50.377Z","comments":true,"path":"2023/03/15/小记/","link":"","permalink":"https://utinner.gitee.io/2023/03/15/%E5%B0%8F%E8%AE%B0/","excerpt":"","text":"我是标题","categories":[{"name":"生活小记","slug":"生活小记","permalink":"https://utinner.gitee.io/categories/%E7%94%9F%E6%B4%BB%E5%B0%8F%E8%AE%B0/"}],"tags":[{"name":"生活","slug":"生活","permalink":"https://utinner.gitee.io/tags/%E7%94%9F%E6%B4%BB/"}]},{"title":"完形填空","slug":"完形填空","date":"2021-11-10T09:06:34.000Z","updated":"2023-03-15T09:27:23.536Z","comments":true,"path":"2021/11/10/完形填空/","link":"","permalink":"https://utinner.gitee.io/2021/11/10/%E5%AE%8C%E5%BD%A2%E5%A1%AB%E7%A9%BA/","excerpt":"","text":"解题步骤1.句关注空格所在句的搭配线索 2.义关注空格所在句的语义对应线索 3.项空格所对应的4个选项的逻辑关系： A约等于B，这两个选项要同时排除 A的措辞和B相近，倾向于在这两个之中 A和B对立项，蕴含着正确答案（against 和 for） A&gt;B，倾向于选A(范围大的) A明显不同于BCD，正确答案存在于BCD中 4.回看上一句或者上文的主题句，根据句子之间的递进、转折、因果等关系，判断正确项。首段首句一般都是交代文章提纲和背景，下面的句子围绕主题来叙述 5.跳有的时候线索在下一句，跳过当前句子去看下一句发现线索 6.主题找主题词，抓住文章的主题词，凡是跟文章的主题词靠近的，一致的，就是正确答案 7.复查整体考察是按照文章和篇章来的，所以要复查整个全文，进行通读审查 动词考点 主谓对应：谓语动词要符合主语身份 动宾对应：踢足球，不能踢篮球 动状对应：在游泳馆只能swim，不能play baseball 主宾对应：二氧化碳的排放影响了环境","categories":[{"name":"考研英语","slug":"考研英语","permalink":"https://utinner.gitee.io/categories/%E8%80%83%E7%A0%94%E8%8B%B1%E8%AF%AD/"}],"tags":[{"name":"考研英语","slug":"考研英语","permalink":"https://utinner.gitee.io/tags/%E8%80%83%E7%A0%94%E8%8B%B1%E8%AF%AD/"}]},{"title":"英语后缀","slug":"英语后缀","date":"2021-11-09T05:57:52.000Z","updated":"2023-03-15T09:27:17.737Z","comments":true,"path":"2021/11/09/英语后缀/","link":"","permalink":"https://utinner.gitee.io/2021/11/09/%E8%8B%B1%E8%AF%AD%E5%90%8E%E7%BC%80/","excerpt":"","text":"后缀决定词性 一.名词后缀-ability，-ibility表示能力，性质 单词 释义 延伸 flexible 灵活的（可折叠的） flex 折叠 flexibility 灵活性，灵活度 credible 可信的 cred 信誉 credibility 可信度 available 可用的，可得到的 avail 利用，使用 availability 可获得性 sustainable 可支撑的；可维持的 tain 拿sustain 支撑，维持，遭受 sustainability n.可维持性 -age表示某种状态 单词 释义 延伸 shortage 短缺 postage 邮资，邮费 post 邮递，邮寄 package 打好的包裹，包装盒 pack 打包unpack 拆包 marriage 婚姻 marry 结婚 luggage 行李 lug 拉杆 baggage 行李 -al可做名词后缀，也可做形容词词缀 单词 释义 延伸 national adj.国家的，民族的n.国民 nation 国家，民族 mutinational adj.跨国的n.跨国公司 memorial n.纪念物，纪念品 memory 记忆 professional adj.职业的，专业的 fess 讲，说profession 职业 refusal n.拒绝 arrival n.到达 -an,-ian,-arian与人有关 单词 释义 延伸 musician 音乐家 physician n.医生 physics n.物理学physiology n.生理学physical adj.物理的,身体的，有形的，客观存在的physicist n.物理学家 librarian n.图书管理员 library 图书馆 politician n.政界人物 polite 礼貌的politics n.政治 Hungarian n.匈牙利人 -ance,-ence 单词 释义 延伸 appearance 出现 reference 参考 perseverance 坚韧不拔,执着 emergence n.出现 emerg 紧急 -ancy,-ency 单词 释义 延伸 emergency n.紧急事件 expectancy n.期待 -ant,-ent可以是名词后缀，可以是形容词后缀与人有关 单词 释义 延伸 student 学生 applicant 申请人 respondent 被告 correspondent n.通讯员，a.一致的 respond 回应 resident 居民 president 总统 preside vi.主持(会议、仪式等);担任(会议)主席 -cy 单词 释义 延伸 privacy 隐私 private a.私有的 accuracy 精确 accurate a.精确的 -dom -dom 表示范围 dome n.圆屋顶 domestic adj.家庭的，国内的 单词 释义 延伸 kingdom 王国 freedom 自由 -ee表示被…的人 单词 释义 延伸 employee 雇员 interviewee 被采访、面试的人，受访者 referee 裁判 trainee 实习生，新兵 -er,-or,-ar 单词 释义 延伸 scholar 学者 actor 演员 cooker 厨具 cook 厨师 folder 折叠物，文件夹 fold 折叠 icebreaker 破冰船 tractor 拖拉机 loudspeaker 扬声器，扩音器 typewriter 打字机 type写typist 打字员 duplicator 复印机 drawer 抽屉，出票人 skyscraper 摩天大楼 cultivator 耕种机，播种机 cult n.崇拜，膜拜;adj.受特定群体欢迎的；作为偶像崇拜的cultivate -ery 单词 释义 延伸 bravery n.勇敢 brave 勇敢 slavery n.奴隶制 slave 奴隶身份 -ese表示人 单词 释义 Chinese 中国人 -ess表女性 单词 释义 empress 女皇 waitess 女服务员 -ful满满的一…质量 单词 释义 handful 一把 spoonful 一勺 mouthful 一嘴 -hood表示阶段和状态 单词 释义 babyhood 婴儿期 childhood 童年期 adulthood 成年 neighberhood 邻里关系 -ics表示学科 单词 释义 electronics 电子学 linguistics 语言学 physics 物理学 -ion, -ition, -ation 单词 释义 collection 收藏 observation 观察 competition 竞争 repetition 重复 -ism表示理论、主义 单词 释义 延伸 theism 有神论 atheism 无神论 capitalism 资本主义 capital n.首都，资本，资金 socialism 社会主义 social n.社会的 idealism 理想主义 realism 现实主义 -ist…学家，表示人 单词 释义 violinist 小提琴家 pianist 钢琴家 psychologist 心理学家 psychiatrist 精神疾病专家 vocalist 声乐学家 -ity, -ty 单词 释义 延伸 cruelty 残忍 cruel 残忍的 purity 纯洁 pure 纯洁的 beauty 美丽 beautiful 漂亮的 clarity 清晰度 clear 清晰的 identity 身份 -ment 单词 释义 movement 运动 retirement 退休 -meter…表 单词 释义 watermeter 水表 thermometer 温度表 -ness 单词 释义 darkness 黑暗 happiness 幸福 -ology 单词 释义 archeology 考古学 biology 生物学 psychology 心理学 physiology 生理学 futurology 未来主义学科 -scope表示范围 -ship表示关系 单词 释义 延伸 friendship 友谊 fellowship 交情 fellow 伙伴，同胞 scholarship 奖学金 -sion, -ssion 单词 释义 延伸 decision 决定 expansion 扩大 expand 扩大 recession 经济衰退，退后，撤回 excession 超出 exceed 超过 -th 单词 释义 延伸 growth 增长 width 宽度 wide 宽的 birth 出生，诞生 bear 熊，生育 -tive可以表示人，可以表示物 单词 释义 延伸 detective 侦探 detect 侦查 captive 俘虏;囚徒;战俘 capture 俘虏 representative 代表 represent v.代表 motive 动机 emotion 情感，情绪 incentive 激励，鼓励，刺激 -ure 单词 释义 延伸 closure 关闭 exposure 面临，遭受，揭露 expose 暴露 pleasure 高兴 please 请 二.动词后缀-en使得，可做形容词和动词后缀 单词 释义 延伸 widen 加宽 broaden 拓宽 expose 暴露 sharpen 使锋利 sharp 锋利的 shorten 缩短 heighten 加高 deepen 加深 fasten vt.固定 fast 牢固的，牢靠的，快的。vi.斋戒，节食 lengthen 变长 strengthen 加强 -ify 单词 释义 延伸 simplify 使简单化 simple 简单的 beautify 美化 clarify 使变清楚 identify 识别 class 分级，分类，分等级 class 阶层，等级 -ize,-ise使得…化 单词 释义 延伸 popularize 使流行，使普及 popular 流行的 modernize 使现代化 modern 现代的 industrialize 使工业化 industrial 工业的 realize 实现 三.形容词后缀-able, -ible表示能够、可以 单词 释义 延伸 questionable 可疑的 credible 可信的 suitable 适合的 -al可做名词后缀，也可做形容词词缀 单词 释义 延伸 national adj.国家的，民族的n.国民 nation 国家，民族 mutinational adj.跨国的n.跨国公司 memorial n.纪念物，纪念品 memory 记忆 professional adj.职业的，专业的 fess 讲，说profession 职业 conditional a.有条件的 structural a.结构性的 -an,-arian,-ian 单词 释义 延伸 suburban 郊区的 suburb 郊区 urban adj.城市的 Canadian 加拿大的 -ant,-ent可以是名词后缀，可以是形容词后缀 单词 释义 延伸 different 不同的 differ 不同，分歧 pleasant 令人开心的 please 请，使开心 -ary,-ory 单词 释义 延伸 revolutionary 革命的 revolution 革命 prorevolutionary 赞同革命的 advisory 建议性的 advise 建议 ordinary 普通的；平常的；一般的；平凡的 extraordinary 非同寻常的 extra 额外的 -ate名词、形容词后缀 单词 释义 延伸 considerate 考虑周到的，体贴的，体谅的 consider 考虑 fortunate 幸运的 fortune 命运，财富 unfortunate 不幸的 affectionate 充满爱的，充满深情的 affect 影响，打动，感动affection 感情，钟爱，喜爱 motivate 激励，激发 -en动词、形容词后缀 单词 释义 延伸 golden 金色的，美好的，特别的 gold 金 wooden 呆板的，木制的 wood 木材 woolen 羊毛的 wool 羊毛 -ese 单词 释义 Chinese 中国的 -free不受限制的 单词 释义 延伸 icefree 不结冰的 carefree 无忧无虑的 duty-free 免税的，免税商品 duty 职责，责任，关税 -laden充满的 单词 释义 延伸 careladen 忧心忡忡的 -ful充满的 单词 释义 延伸 careful 仔细的，小心的，谨慎的 lustful 好色的 lust 色欲，欲望 -ic,-ical名词、形容词后缀 单词 释义 延伸 domestic 本国的，家的 atomic 原子的 music 音乐 critic 批评家 political 政治的 -ish有点…的 单词 释义 延伸 childish 幼稚的 girlish 少女的 stylish 时尚的 -ive 单词 释义 延伸 creative 有创造力的 excessive 过分的，过度的 supportive 支持的，同情的，给予帮助的 -less没有…的 单词 释义 延伸 helpless 无助的 hopeless 绝望的 painless 无痛的 motionless 一动不动的，静止的 -like 单词 释义 延伸 childlike 孩子气的 ladylike 文静的;温文尔雅的;淑女似的 -ly形容词+ly=副词名词+ly=形容词 单词 释义 manly 男人般的 miserly 吝啬的 friendly 友善的 daily 日常的,日报 scholarly 文质彬彬的，有学问的 -ous,-ious 单词 释义 延伸 dangerous 危险的 poisonous 有毒的 poison 毒药 courageous 勇敢的 courage 勇气 luxurious 奢华的 luxury 奢侈，奢侈品 -some 单词 释义 延伸 tiresome 讨厌的，令人厌烦的 tire 疲惫的，使厌烦的 troublesome adj.麻烦的;讨厌的;令人烦恼的;令人痛苦的 handsome 帅气的，慷慨的 -ward朝着某个方向的toward=to,介词 -y 单词 释义 延伸 thirsty 口渴的 thirst 口渴 greedy adj.贪婪的 greed 贪婪 四.副词后缀-ly-ward,-wards-wisewise 明智的 做后缀，表示方式 单词 释义 延伸 clockwise 顺时针方向的 crabwise 横向地 crab 螃蟹 counterclockwise 逆时针地 表示方面地： 单词 释义 延伸 otherwise 其他方面，否则 educationwise 在教育方面","categories":[{"name":"考研英语","slug":"考研英语","permalink":"https://utinner.gitee.io/categories/%E8%80%83%E7%A0%94%E8%8B%B1%E8%AF%AD/"}],"tags":[{"name":"考研英语","slug":"考研英语","permalink":"https://utinner.gitee.io/tags/%E8%80%83%E7%A0%94%E8%8B%B1%E8%AF%AD/"}]},{"title":"额外的词根","slug":"额外的词根","date":"2021-11-08T06:48:59.000Z","updated":"2021-12-06T09:23:00.942Z","comments":true,"path":"2021/11/08/额外的词根/","link":"","permalink":"https://utinner.gitee.io/2021/11/08/%E9%A2%9D%E5%A4%96%E7%9A%84%E8%AF%8D%E6%A0%B9/","excerpt":"auto-自己的，自身的，自行的 单词 释义 延伸 autonomy n.自治 autonomous adj.自治的 automobile n.汽车=car mobile 可移动的 autograph n.亲笔签名 grapg 图表 autobiography n.自传 biography 传记作品 autocrat n.专制者，独裁者 autocracy n.专制政体 democracy 民主政体 autoalarm n.自动报警器 automate 使自动化 automatic 自动化的 autocriticism 自我批评，自我反省","text":"auto-自己的，自身的，自行的 单词 释义 延伸 autonomy n.自治 autonomous adj.自治的 automobile n.汽车=car mobile 可移动的 autograph n.亲笔签名 grapg 图表 autobiography n.自传 biography 传记作品 autocrat n.专制者，独裁者 autocracy n.专制政体 democracy 民主政体 autoalarm n.自动报警器 automate 使自动化 automatic 自动化的 autocriticism 自我批评，自我反省 bio-生物，生命，生平 单词 释义 biology 生物学 biography 传记 biosphere 生物圈 biochemistry 生物化学 chemistry 化学 chemist 专家 sphere 范围 centi-（cente-）百分之一，百 单词 释义 延伸 cent 美分，分币 percentage 百分比 centigrade 摄氏度 fahrenheit 华氏度 gradual 逐渐的 graduate 毕业 centigram 厘克 gram 克 centimeter 厘米 meter 米，表 milimeter 毫米 centilitre 厘升 litre 升 mililitre 毫升 kilometer 公里 kilogram 公斤 century 世纪，百年 centenary 百年 centennial 百年的，百年纪念 centenarian 百岁老人，人瑞 centepede 蜈蚣 cor-一起，共同 单词 释义 延伸 correct vt./adj.正确的 eract vt./adj.竖起，使直立，竖起的，直立的 direct adj.直接的；vt.指导 rectify 纠正，矫正 rectangle 矩形 tangle 纠纷，正值，打架 correlate vt.相关 correlate A with B A与B相关联 relate 使相关 be related to 与…相关 relative adj.相对的；n.亲属 correspond 保持通信往来，保持一致 correspond with 与…保持一致 correspondence 处于一致的状态 correspondent 记者，通信员 corrupt v.使腐败；adj.贪污的 rupt=break 打碎，使碎裂 corridor 走廊 rid 骑马，骑(交通工具) cross- 跨越，穿越 交叉 单词 释义 延伸 crosscountry adj.横跨全国的，越野的 country 国家，乡下，农村 crosscheck 交叉核对 crossbred 杂交的 breed 繁殖 crosslegged 盘腿，翘腿 leg 腿 crossroads 交叉口，十字路口 at the crossroads 处于人生的十字路口 crosssection 横切面，有代表的一部分，典型的一部分，代表 equi-等同，相等 单词 释义 延伸 equator 赤道 equidistant adj.等距离的 equiform 形状一样的 form 形状 adequate 足够的，令人满意的 -ate 形容词后缀 inadeguate 不足的 hydro-与水相关的（of water） 单词 释义 延伸 hydroelectric 水力发电的 hydrant 消防栓 -ant(ent) 名词后缀 hydrogen 氢气 oxygen 氧气 hydrophobia 狂犬病 phobia 恐惧(症) hydroscope 深水镜 telescope 望远镜 microscope 显微镜 hydrobiologist 水生物学家 hydroplane 水上飞机 in- 单词 释义 延伸 fame 名声，名誉 infamous 臭名卓著的 invaluable 无价的 invisible 无形的，看不见的 infra- 在下面的-&gt;基础的 单词 释义 延伸 infradig 有失身份的，不体面的 dignity 尊严，体面 ingrastructure 基础设施 beyond 超过 单词 释义 infrared 红外线的 ultraviolet 紫外线的 mid- middle/midst 中间，中间的 单词 释义 延伸 midday 正午 midnight 午夜 midtern 期中的 midautumn 仲秋 mid-autumn 中秋的 the Moon Festivalthe Mooncake Festival the Zhongqiu Festival中秋节 midsummer 仲夏 midwife 接生婆 mediate vt.调节 the Mediterranean 地中海 proof-proof n.证据 adj.防止…(的) be proof against… 单词 释义 延伸 proof n.证据 adj.防止…(的) be proof against… waterproof 防水的 fireproof 防火的 soundproof 隔音的 airproof 密封的 self-自己，自我 单词 释义 selfemployed 自由职业的 selftaught 自修的，自学的 selfconfident 自信的 selfesteem 自尊 semi-半 单词 释义 延伸 semiannual adj.每半年的 n.半年刊 be proof against… semicircle 半圆 semiconductor 半导体 conduct 传导 semiconcious 半清醒的 concious 觉察的，意识到的 semitropical 亚热带的 semiofficial 半官方的 semifinal 半决赛 step-迈步，步伐 单词 释义 stepmother 继母 stepparents 继父母 stepbrother 隔山兄弟 stepchildren 养子女 sister-in-law 弟妹，嫂子 father-in-law 岳父，老丈人 mother-in-law 丈母娘 syn-(sym-)合成，单一，同一，相同 单词 释义 延伸 synonym 同义词 sympathy 同情 pathy 心理 apathy 冷漠 telepathy 心灵感应 antipathy 反感 synthesis 合成 thesis 论文，论点 symptom 症状 tomb 坟墓 syndicate 辛迪加;企业联合组织;财团;私人联合会 托拉斯（英語：Trust）是商业信托的音譯，是指在一个行业（商品领域）中，透过生产企业间的收购、合并以及托管等等形式，由一家公司兼併、包容、控股大量同行业企业来达到企业一体化目的的垄断形式 symmetry 对称 metey meter米 tele-远距离的 单词 释义 television 电视 telephone 电话 telegraph 电报 telescope 望远镜 telepathy 心电感应 telecom 电信 teleswitch 遥控器 therm(o)-与热相关的 单词 释义 thermometer 温度计 thermostable 耐热的 stable 稳定的 thermostat n.恒温器 thermos 热水瓶 tri- 三：tri- 单一：mono-；uni- 二(双)：bi- 单词 释义 延伸 triangle 三角形 angel 天使 tricycle 人力三轮车=trike triple 三倍的，三重的，三方的 tricolor adj.三色的，n.三色旗 tricar 三轮汽车，电动三轮车 trilateral 三边的 trilogy 三部曲 trinity 三位一体，三合一 trilingual 三语的 lingual 语言的 Bilingual 双语的","categories":[{"name":"考研英语","slug":"考研英语","permalink":"https://utinner.gitee.io/categories/%E8%80%83%E7%A0%94%E8%8B%B1%E8%AF%AD/"}],"tags":[{"name":"考研英语","slug":"考研英语","permalink":"https://utinner.gitee.io/tags/%E8%80%83%E7%A0%94%E8%8B%B1%E8%AF%AD/"}]},{"title":"大作文","slug":"大作文","date":"2021-10-22T02:46:31.000Z","updated":"2021-12-06T09:23:00.903Z","comments":true,"path":"2021/10/22/大作文/","link":"","permalink":"https://utinner.gitee.io/2021/10/22/%E5%A4%A7%E4%BD%9C%E6%96%87/","excerpt":"一.历年回顾过去10年中，柱状图考了5次，饼状图3次，1年的线形图和表格大纲：还涉及到图表作文的考察 总结核心就是选显著变化的对象来进行中心思想的选择时间安排：20-25分钟","text":"一.历年回顾过去10年中，柱状图考了5次，饼状图3次，1年的线形图和表格大纲：还涉及到图表作文的考察 总结核心就是选显著变化的对象来进行中心思想的选择时间安排：20-25分钟 二.写作及要求2.1 审题题目要求： 1.对数据的解读 2.给出自己的评论 柱状图是最重要的，在分析过程中，要研究出主要变化的趋势，从积极乐观的角度去分析对国民有益的对象。 2.2整体要求阅卷老师对作文的要求有： 1.内容；完整性和连贯性 2.语言：准确性和多样性 3.语篇：自然段逻辑清晰 4.卷面的整洁 5.书写工整 三.写作技巧3.1 字数及段落三段，200词左右，不写标题！不写标题！不写标题！ 3.2 段落的句子安排第一段：一般写三个句子 第一句：要具有概括性，对数据的宏观解读 【bar chart（柱状图）清晰地揭示了xx和xx在xxx方面发生了显著的变化。】 第二句：写非主要讨论的那一方的变化。结束之后用However等转折词对第三句进行过渡 第三句：写主要讨论的那一方的变化。 第二段：主要写出主要讨论的对象之所以成这种走向变化的原因，一般写四句 第一句：xxx在xx方面发生这一变化（产生这种趋势）是有各方面原因的（然后延伸出3~4点进行表述） 第二~第四句从各个角度表达出产生这种趋势（trend、tendency）的原因 要注意总分逻辑的对应性，可以适当举例子，但是不要暴露缺点 万能原因：with the accelerating rate of technological innovation in the xxx industry 第三段：（最好写1~2句）作者的主观感受都是在最后一段，涉及到了作者的立场和态度，所以最后一段要体现出我们的立场和态度。两句：评价+结论（或建议） 四.示例4.1 题目 4.2 作答The bar chart above demonstrates clearly that significant changes have taken place with respect to the shares of HuaWei and Apple in the domestics smart phone market.In the light of the given information,we can notice that in a mere five years,the market percentage of Apple has decreased a lot,dropping by 5% from 2012 to 2017.At the same time,however,the share of the national brand HuaWei has witnessed a dramatic rise,jumping startling to 40% in the year of 2017. It is not a difficult job to point out some influences accounting for these changes.To start,with the accelerating rate of technological innovation in the domestic mobile phone industry,more and more cutting-edge technology has been applied to home-made products,thus enhancing their cost performance and competition fundamentally.Furthermore,the fact cannot be ignored that this phenomenon is bound up with the transformation of Chinese consumers’ outlook on national brands.Lastly,we may notice,the operator’s ingenious marketing strategies and the product optimization based on our national conditons,produce a contributing effect as well. Considering the arguments above,we can conclude with confidence that this trend is quite positive and therefore beneficial.And I firmly believe the tendency in question will keep going in the years to come. 以下文章中有部分错误标识出来了，注意区分 第一段第一句The bar chart above demonstrate clearly that significant changes happened with respect to the shares of HuaWei and Apple in the domestics smart phone market.以上柱状图清晰地展示了关于华为和苹果在国内智能手机市场所占份额的显著变化。 生词 词组 含义 with respect to 关于 shares 份额 demestic 国内的 纠错 错误 纠正 demonstrate 【动词用法不当】不能用原型，因为是第三人称单数，所以要加s.demonstrates happened 【用词不当】表示的是偶然发生，在逻辑层面不能分析偶然发生的事件，可以替换为take place或者arise。用过去式也是错的，解读的东西是根据过去的数据解读出现在的变化，所以时态应该是现在完成时。应该为：have taken place / have arisen. 第二句In the light of the given information,we can notice that in a mere five years,the market percentage of Apple have decreased a lot,dropping by 5% from 2012 to 2017.根据给定的信息，我们可以注意到，在短短五年内，苹果的市场份额大幅下降，从2012年到2017年下降了5%。 逗号之后加伴随状语，所以用动词ing（dropping） 生词 词组 含义 In the light of 根据，依据，按照 a mere = merely 仅仅的 dropping by 下降了 纠错 错误 纠正 have 【动词用法不当】应该改为has，因为主语是parcentage百分率 第三句At the same time,however,the shares of the national brand HuaWei witnessed a dramatic rise,jumping startling to 40% in the year of 2017.然而，与此同时，华为的民族品牌份额大幅上升，在2017年跃升至40%。 生词 词组 含义 dramatic = a lot 令人吃惊的 jumping 激增 纠错 错误 纠正 shares 【名词用法不当】不能用复数，因为是单个品牌的份额，所以用单数share witnessed 【时态问题】应该用现在完成时has witnessed 第二段第一句It is not difficult job to point out some influences accounting for these changes.指出以上产生以上变化的影响并不是件难事 生词 词组 含义 accoun for 解释…的原因,解释，说明 no = not any 表否定语气很强 纠错 错误 纠正 not not应该换成no，或者not后加a，因为job是可数名词 第二句To start,with the accelerating rate of technological innovation in the domestic mobile phone industry,more and more cutting-edge technologies has been applied to home-made products,thus enhancing their cost performance and competition fundamentally.首先，随着国内手机行业技术创新速度的加快，越来越多的尖端技术被应用于国产产品，从而从根本上提高了其性价比和竞争力。 生词 词组 含义 accelerating 加速，加快 rate 比率，速度 technological 技术的 innovation 创新，革新 cutting-edge 尖端的，先进的 thus 因此，引导结果状语从句的 enhance 提高 innovation 创新，革新 cost performance 性价比 competition 竞争力 fundamentally 从根本上 纠错 错误 纠正 technologies 通常是用原型，technology 第三句Furthermore,the fact cannot be ignored that this phenomenon is bound up with the transformation of Chinese consumers’ outlook on national brands.（同位语从句，名词分裂）此外，不可忽视的事实是，这一现象与中国消费者民族品牌观的转变有关。 生词 词组 含义 Furthermore adv.此外；而且；再者 A is bound up with B A和B逻辑上密不可分，前果后因 bound = bind的过去分词 outlook 观念 第四句Lastly,we may notice,the operator’s ingenious marketing strategies and the product optimization based on our national conditons,produces a contributing effect as well.（插入结构和并列）最后，我们注意到，运营人员巧妙的营销策略以及根据我国国情的产品优化，也产生了导致性影响。 双逗原则，可有可无 生词 词组 含义 ingenious adj.精巧的；新颖独特的；巧妙的；心灵手巧的；机敏的；善于创造发明的 strategy 策略 optimization n.优化 optimum 最佳的；最适宜的；最佳结果；最好的条件 operator 运营人员 ingenious marketing strategies 巧妙的营销策略 contributing 导致性的 effect 影响 纠错 错误 纠正 produces and连接的两个因素，不应该用produces了，应该用produce 第三段第一句Considering the arguments above,we can conclude with confidence that this trend is quite positive and therefore beneficial.综上所述，我们可以自信地得出结论，即以上这一趋势是积极乐观的，从而是有益处的。 生词 词组 含义 Considering the arguments above 综上所述 arguments 争吵、观点、论据、论点 conclude that 得出…结论 with+n. 相当于副词，经常做方式状语 therefore 表示两者之间的因果关系 positive 积极乐观的 pessimistic 悲观的 第二句And I firmly believe the tendency in question will keep going in the years to come.我坚信这个所探讨的趋势将会在未来的岁月继续持续。 生词 词组 含义 in question 所探讨的 in the years to come. 在未来的岁月","categories":[{"name":"考研英语","slug":"考研英语","permalink":"https://utinner.gitee.io/categories/%E8%80%83%E7%A0%94%E8%8B%B1%E8%AF%AD/"}],"tags":[{"name":"考研英语","slug":"考研英语","permalink":"https://utinner.gitee.io/tags/%E8%80%83%E7%A0%94%E8%8B%B1%E8%AF%AD/"}]},{"title":"英语2翻译","slug":"英语2翻译","date":"2021-10-20T02:52:42.000Z","updated":"2021-12-06T09:23:00.919Z","comments":true,"path":"2021/10/20/英语2翻译/","link":"","permalink":"https://utinner.gitee.io/2021/10/20/%E8%8B%B1%E8%AF%AD2%E7%BF%BB%E8%AF%91/","excerpt":"一.翻译的整体要点 1.切分长难句，准确的理解原文 2.按照汉语的习惯，调整语序，翻译成地道的汉语","text":"一.翻译的整体要点 1.切分长难句，准确的理解原文 2.按照汉语的习惯，调整语序，翻译成地道的汉语 二.评分细则 档位 要求 第四档（13~15分） 很好地完成了试题规定的任务，理解准确无误；表达通顺清楚；没有错译、漏译 第三档（9~12分） 基本完成了试题规定的任务，理解基本准确，表达比较通顺；没有重大错译、漏译 第二档（5~8分） 未能按照要求完成试题规定的任务。理解原文不够准确，表达欠通顺；有明显错译、漏译 第一档（0~4分） 未完成试题规定的任务。不能理解原文；表达不通顺，文字支离破碎 三.翻译的考点(采分点)1.词性转换英语中多用名词，汉语中多使用动词。需要转化词性 2.习语及固定搭配放在语境中分析，从论点和论据的关系 3.后置定语比较短的后置定语，直接放在被修饰的东西之前，比较长的后置定语，单独成句。 4.状语的处理12种状语，通常放在句子后面。状语的处理和状语从句的处理是一致的 5.被动语态出现被动语态，发现句子不通顺，需要进行调整为主动语态 6.省略的还原省略的句子要还原成原来的部分 7.特殊语序（倒装、强调、宾补前置）英语中五大基本结构：主谓、主谓宾、主谓双宾、主谓宾+宾补、主系表结构，为了表达这些结构，通常进行一些倒装、强调等调整，遇到这些，语序需要调整回去进行翻译 8. 从句的处理四.技巧1.词义的选取（词性、搭配、语境、逻辑的框定）是基本要求，不是考点，但是翻译错了是要扣分的！ 一些生词 单词 翻译 volume n.体积；容积；容量；量；额；音量；响度;书；册 airline n.航空公司 roughly adv.粗略地；大致；大约；差不多；粗暴地；粗鲁地；粗糙地；凹凸不平地 rough adj. 粗糙的；不平滑的；高低不平的；不确切的；粗略的；大致的；粗暴的；粗野的；猛烈的n.(高尔夫球场的)长草区；草稿；草图；暴徒；粗野的人v.粗暴地对待;使粗糙;草拟adv.粗鲁地；粗野地 emission 排放；(光、热、气等的)发出；射出；排放物；散发物 sheer adj.纯粹的；用来强调事物的大小、程度或数量；完全的；十足的；陡峭的 intense adj.强烈的；激烈的；很大的；严肃紧张的；有强烈感情(或意见、想法)的；尖锐的；热切的 intensity n.强烈；紧张；剧烈；强度；烈度 extreme n.极端；极度；极限；极端不同的感情(或境况、行为方式等)；完全相反的事物adj.极端的；极度的；偏激的；极大的；异乎寻常的；严重的；严厉的；过分的 suicide n.自杀；自杀性行为；自毁；自取灭亡的行为；自杀者 ruling n.裁决；裁定；判决adj.统治的；支配的；占统治地位的v.控制；统治；支配；操纵；决定；裁定；判决rule的现在分词 pack v.收拾(行李)；装(箱)；包装；包裹；(在四周填入软料以)包装(易损物品)n.(商品的)纸包，纸袋，纸盒；(一起供应的)全套东西；一捆，一包(尤指适于携带的东西) be packed with 装满 tip n.提示；尖端；小费；端；尖儿；(装在顶端的)小部件；指点；实用的提示v.(使)倾斜；翻覆；倒出；倾倒；轻触；轻碰 slim adj.苗条的；纤细的；单薄的；微薄的；不足的；少的；小的vi.(靠节食等)变苗条，减肥n.(非洲)艾滋病 2.词性的转换2.1 将名词转译为动词（最高频，仔细阅读，大胆突破）2.1.1 例句Rockets have found application for the exploration of the universe.火箭已经用于探索宇宙。 He is good eater and good sleeper.他吃得好，睡得香 We should not be after only fame and position.我们不应该一味追逐名利。 He went to the shop for a bottle of sauce.他去商店买了一瓶酱油。 2.1.2 一些生词 单词 翻译 raw adj.未经加工的；生的；原始的；未烹制的；未煮的；自然状态的；未经处理的；未经分析的 rawness 生的；半生不熟；未成熟 materials n.布料；材料；原料；(某一活动所需的)材料 fame n.名声；声誉；名气vt.使闻名；使出名；使有名望；&lt;古&gt;盛传 2.2 转译为名词2.2.1 例句His paintings are characterized by steady strokes and bright colors.他的绘画特点是笔调沉稳、色彩明快。 Oxygen is very active chemically.氧气的化学性质很活跃。 It was officially announced that Paris is invited to the meeting.(两个被动语态，要翻译成主动)官方宣布，巴黎应邀出席会议。 2.2.2 一些生词 单词 翻译 be characterized by 以…为特征 chemically adv.（在）化学（性质）上；用化学方法；通过化学作用；从化学上来分析 officially adv.正式地；官方地；公开地；依据法规等；据传；据公布 2.3 转译为形容词2.3.1 例句I recognized the absurdity of dealing with them at last.最后，我意识到与他们打交道很荒唐。 Traditionally,there had always been good relations between them.他们拥有传统的友好关系 2.3.2 一些生词 单词 翻译 absurd adj.荒谬的；荒唐的；怪诞不经的；荒诞的事物；悖理的东西 absurdity n.不合理；荒谬；谬论；荒唐的事；荒唐；荒唐行为 career n.生涯，职业，经历，事业 traditionally adv.传统上 2.4 总结英语中多用名词，如果句子按照名词翻译的话不通顺，就需要调整一下，首先要看这个名词它是从形容词变过去的还是从动词变过去的，先将他还原成对应的形容词或者动词。（名词-&gt;动，形）如果出现了介词，比较灵活，但是它只能转成动词。具体翻译成什么东西，需要结合语境。（介词-&gt;动）如果有副词，如果是一个形容词加上ly变过来的，直接尝试去翻译成形容词，如果翻译成形容词还不通顺，就去尝试翻译成名词。（副词-&gt;形，名） 3.词语的增译、省译（非考点，灵活处理）完全是建立在保证这个句子的信息量完整之上，依据表达的需要进行词语的增译、省译，是一种翻译的需要，让句子更加通顺、完整。 例句After the football match,he’s got an important meeting.足球赛结束后，他还要参加一个重要的会议 It is quite possible that there is life out there in the universe.地球之外的宇宙中很可能还有其他生命。 If winter comes,can spring be far behind?冬天来了，春天还会远么？ 4.习语及固定搭配依赖平时的积累！梳理上下文的逻辑来推断词语含义 一些固定搭配 词组 翻译 train of thought 思路，思绪，思维方式 on the ropes 岌岌可危，处于困境 by all accounts 大家都说，人们都认为 take a toll on sth 带来危害，为某事付出代价 一些生词 单词 翻译 particular adj.专指的，特指的(与泛指相对)；不寻常的；格外的；特别的；讲究；挑剔n.(正式记下的)细节；详情；详细资料；详细介绍材料 emigrate vi.移民，移居国外 catake a surprising toll onreer 使人吃惊的是 5.后置定语（永恒的考点）包含了定语从句。 5.1 五种定语从句 1.形容词短语做后置定语 2.现在分词短语 3.过去分词短语 4.动词不定式短语 5.介词短语 5.2 翻译要点 简单的后置定语直接翻译在被修饰的名词之前 复杂的后置定语单独翻译 5.3 例句He believes that this very difficulty may have had the compensating advantage of forcing him to think long and intently about every sentence,and thus enabling him to detect errors in reasoning and in his own observations.他认为正是这种（语言表达上的）困难反而使他拥有了一种优势，即迫使他长时间地认真思考自己要说的每句话，从而能够发现自己推理和观察中的错误 5.4 一些生词 单词 翻译 pure adj.纯净的；纯粹的；纯的；干净的；不含有害物质的；完全的 certain adj.肯定；确定；确实；确信；无疑；(不提及细节时用)某事，某人，某种 6.被动语态（考点）6.1保留主语，直接把被动语态变为主动语态Water can be changed from a liquid into a solid.水可以由固体变为液体。 That young man cannot be relied upon.那个年轻人不可靠。 Heat and light can be given off by this chemical change.这种化学反应能够释放出光和热。 6.2将动作的发出者移到前面去She is given a pen by her father.她的爸爸给了她一支钢笔。 6.3加泛指代词做主语：有人、人们、有关部门等She was seen to enter the building about the time the crime was committed.有人看见他大约在案发时间进入了那座大楼 单词 翻译 crime n.罪行；罪；犯罪活动；不法行为；不道德的行为；罪过 6.4无主语翻译Measures have been taken to prevent the epidemic from spreading quickly.已经采取了相关措施防止瘟疫的快速蔓延。 单词 翻译 put an end to 终止、结束、叫停 6.5是…的The decision to attack was not taken lightly.这个决定不是轻易做出的。printing was introduced into Europe from China.印刷术是从中国引入欧洲的。 6.6将“被”替换为其他的词Problems should be resolved in good time.这些问题应该及时得到解决These challenges need to be addressed by the government.政府需要解决这些问题 6.7总结 1.保留主语，变被动为主动 2.有by的被动，将by后的内容翻译为主语 3.加泛指代词做主语：有人、人们、有关部门等 4.直接不要主语 5.翻译为“是…的” 6.将“被”替换为其他的词，得到、受到、由…来 7.省略的补全（重点）A fool and his words are soon parted;a man of genius and his money.(省略了谓语动词)愚者不守信，智者不恋财 Reading makes a full man;conference a ready man;and writing an exact man.阅读使人充实，讨论使人机敏，写作使人严谨 Formerly,too,pictures had given him considerable(delight),and music very greate,delight.(省略了delight)在以前，绘画和音乐都给他带来了巨大的快乐， By all accounts he was a freethinking person,and a courageous one,and I find courage an essential quality for the understanding,let alone the performance,of his work.人们都说，贝多芬是一个思想自由、充满勇气的人，我认为勇气是理解其作品的必要品质，更不必说演奏其作品了。 单词 翻译 conference n.大型会议，商讨 fool n.蠢人，愚人v.欺骗，愚弄 genius n.天才，天赋 considerable adj.相当大的；相当多(或大、重要等)的 delight n. 高兴；愉快；快乐；令人高兴的事；乐事；乐趣 formerly 以前；原名；往时 let alone 更不用说 essential 本质的，必不可少的，极其重要的；基本的；根本的 8.特殊语序翻译题中重难点是宾补前置，其次是倒装，很少考强调。 8.1 宾补前置宾语补足语前置的原理是因为宾语太长了，先把宾补提前到前面去，让读者尽快抓取句子主干，知道这个句子是有个宾补的，然后再去看宾语，宾语后面还跟着很长的后置定语或者宾语从句。 For example,Tom has as its flagship project a mechanical clock that is designed to still be marking time thousands of years hence.例如，Tom将一台机械钟视为旗舰项目，这台机械钟旨在计时几千年。（先翻译主干，再翻译修饰机械钟的定语从句的部分，have A as B将A看作B,原文中将B提前了：has as B A） On the other hand,he did not accept as well founded the charge made by some of his critics that,while he was a good observer,he had no power of reasoning.另一方面，一些批评家指责他，尽管他善于观察，但他不具备推理能力，而他认为这种指责是没有根据的。（that引导同位语从句，后面的部分是对charge的内容再次进行解释说明） We have at least drawn nearer the point of admitting that birds should continue as a matter of intrinsic right,regardless of the presence or absence of economic advantage to us.至少，我们已经逐渐开始承认，无论鸟类是否对人类有经济价值，它们天生有权活下去。 词组 翻译 have A as B 将A看作B flagship 旗舰 hence 因果，跟在时间的后面表示在这段时间之后 charge n.(商品和服务所需的)要价，收费；指控；控告；指责；谴责 accept A as B 将A看作B critic n.批评家；评论家；评论员；批评者；挑剔的人 while 表示让步、转折 draw v.画；(用铅笔、钢笔或粉笔)描绘；描画；拖(动)；拉(动)；牵引；拖(车)；吸引 draw sth. near 接近、靠近某物 intrinsic adj. 固有的；内在的；本身的 admitting v.承认(过错、罪行)；招认；招供；准许…进入(某处) right adj. 正当；妥当；正确的；真正的；真实的；适当的；正好的；恰当的；右边的adv. 正好；恰好；直接地；一直；径直；完全地；立即；马上；毫不耽搁n. 正当；公正；正义；正确；正当的要求；权利；版权；发行权；右边；右派vt. 使回到正常位置；把…扶正；使…直立；改正；纠正；使恢复正常；向右int.(表示同意或遵从)是的，好的；(引起注意，表示已作好准备或让别人做某事)嗨，喂；(要确保对方同意或明白时说)对不 regardless of 引导让步状语，无论，不管；不顾；不理会 8.2 倒装Only放在句首，后面+状语（副词/介词短语）引起了句子的部分倒装，将动词的助动词拿到主语的前面来，而原来的实例动词还是放在原地。表示强调。 Only gradually was the by-product of the institution noted,and only more gradually still was this effect considered as a directive factor in the conduct of the institution.人们只是逐渐地才注意到机构的这一副产品，而人们把作用视为机构运作的指导性因素的过程则更为缓慢。 词组 翻译 institution 机构 gradually adv.逐步地；逐渐地；渐进地 factor 因素，因子 directive n.指示；命令adj. 指示的；指导的 conduct n. 行为；(人在某地或某种情况下的)举止；经营方式；管理方法；实施办法v.实施；执行；引导；组织；安排；指挥(歌唱或音乐演奏)；带领；为(某人)导游 8.3 强调强调：It is … that/who翻译成：正是这个人/事 9.从句的翻译9.1 名词性（主语）从句主语从句很长的话，单独翻译，然后用代词指代就好了。 What he told me was only half-truth.他所告诉我的只是一些半真半假的事情。 Whether the community’s work contributes muth to an overall accumulation of knowledge is doubtful.该领域的工作是否对知识的整体积累做出巨大的贡献，这一点令人质疑。 It doesn’t make much difference whether he attends the meeting or not.(it做形式主语,把whether引导的真正的主语挪到主语部分)他是否参会没太大影响 It is surely a good thing that the money and attention come to science rather than go elsewhere.金钱和人们的注意力投入到了科学领域而非其他领域，这当然是件好事。 9.2 宾语从句He would remind people that it was devided not only by himself but by lots of others.他会提醒人们这件事不是由他一个人说了算，还有许多其他人一起决定。 it做宾语,把真正的宾语替换掉itWe consider it absolutely necessary that we should open up door to the outside world.我们认为“打开国门，对外开放”是非常必要的。 9.3 表语从句表语从句的翻译方法和宾语从句相同，只不过表语从句的动词是系动词，而宾语从句中的动词是实例动词 It seems that it is going to snow.似乎马上就要下雨了 9.4 同位语从句属于名词性从句，但是作用跟定语从句相似，是对前面的名词的解释说明，简单的要翻译在被解释说明的名词的前面去；复杂的用逗号隔开，分译 I disagree with the opinion that a women’s place is in the home.我不认同“女性应该待在家里”这一观点。 Time was when biologists somewhat overworked the evidence that these creatures preserve the health of game by skilling the physically weak,or that they prey only on “worthless” species.有证据指出，这些（肉食性）动物通过猎杀体弱者维持了猎物种群的健康，或它们猎杀的只是一些“没有价值”的物种，而生物学家在过去有些滥用了这种证据。 词组 翻译 time was when 曾几何时，曾经有这段时间 evidence 证据 overworked 过度工作 9.5 定语从句对名词解释说明，翻译方法与同位语从句类似 9.6 状语从句状语从句本身比较简单、清晰。状语从句和状语是同样的处理方法，状语中包含状语从句。状语包含12种，在英语中一般都会放在句末。状语根据类别，翻译时放置的位置是不同的： 时间、地点、原因、条件、让步、范围状语，在翻译的时候要放在句首； 方式、程度状语，在翻译的时候放在被修饰的名词或者形容词之前； 结果、伴随、比较状语，通常放在句末。 目的状语看情况 9.7 总结对于主从、宾从、表从： 如果是简单从句，直接就地翻译 复杂从句，单独翻译，用逗号隔开，用“这”在主句中来代指。 五.长难句解析Beethoven’s habit of increasing the volume with an extreme intensity and then abruptly following it with a sudden soft passage was only rarely used by composers before him. by composers before him.贝多芬习惯用最大限度提高音量，然后突然转入一段轻柔的乐段，在他之前的作曲家几乎没有使用过这种创作习惯。 1.Beethoven’s habit 贝多芬的习惯从句首开始，到【habit】结束。结束的原因是因为后面出现了介词P【of】，引导了修饰成分。这里是句子的主语，说明了事情发生的主体是什么。 2.介词P：of increasing the volume 提高音量从介词P【of】开始，到【volume】结束。结束的原因是后面出现了介词P【with】，引导了一段修饰。介词P【of】引导的内容，根据修饰的就近原则，判断其修饰对象为紧靠其左边的【that】，说明了习惯的内容是什么。 3.介词：with a extreme intensity 用最大强度从介词P【with】开始，到【intensity】结束。结束的原因是后面出现了连词and，后面跟了一段内容。这里，介词P【with】引导的内容，根据修饰的就近原则，结合意思，判断其修饰对象是【increasing the volume】，说明了增加音量的方式是什么。 介词P【with】在表达方式这一概念时，可以转译为动词词性，译为【用…】。 4.and then abruplly following it 然后突然跟上从连词【and】开始，到【it】结束，结束的原因是后面出现了介词P【with】，引导了一段修饰。这里，连词【and】连接的内容，观察发现【following】和前面的【increasing】结构类似，再结合其意思，判断这个部分也是用于说明【Beethoven’s habit】是什么。 连词【and】起到连接的作用，可以省略不译。【it】代指的是前面的【increasing the volume with an extreme intensity】，这里将其译为或者直译为【它】都不太符合中文的表述，因此在不影响理解的情况下，我们也可以省略不译。 5.with a sudden soft passage 轻柔的乐段从介词P【with】开始，到【passage】结束。结束的原因是后面出现了谓语动词【was used】。谓语动词的出现标志着前段修饰或内容的结束。这里，介词P【with】引导的内容，根据修饰的就近原则，结合意思，判断其修饰对象为【following it】，说明了怎么样【跟上提高音量】。 结合上一分句，这里译为【然后突然跟上轻柔的乐段】比直译【然后用轻柔的乐段跟上它】更符合中文的表述。 【passage】意为【一段】，这里结合句意提到的音乐背景，翻译为【乐段】。 6.was only rarely used 很少被使用这里是整个句子的谓语部分。 7.介词P：by composers before hime. 被他之前的作曲家从介词P【by】开始，到句末结束。这里，介词P【by】引导的内容，根据修饰的就近原则，判断其修饰对象为紧靠其左边的【was used】，说明了是被谁使用的。注意，这里介词P【before】也符合NPC断句原则，但由于【composers before him】意思比较容易理解，鼓不作刻意拆分。 结合上一分句，发现是一个被动语态的运用。我们可以还原为主动语态进行翻译【他之前的作曲家很少使用这种方式】，这里，谓语动词前的内容过长，我们将其代称为【这种方式】。为了与前面的内容衔接更加自然，我们可以将【before him】前置，作为一状态，即【，在他之前，】。 核心知识 1.看到介词P（of，with，by）要留意，其后面的内容往往起着修饰的作用。 2.看到连词（and）要留意，后面往往引导了下一段内容。 3.修饰的就近原则：后置的修饰通常往往用于修饰紧靠其左边的内容，但我们也需要结合意思判断其具体的修饰对象。 4.谓语动词的出现往往标志着前端修饰或内容的结束。","categories":[{"name":"考研英语","slug":"考研英语","permalink":"https://utinner.gitee.io/categories/%E8%80%83%E7%A0%94%E8%8B%B1%E8%AF%AD/"}],"tags":[{"name":"考研英语","slug":"考研英语","permalink":"https://utinner.gitee.io/tags/%E8%80%83%E7%A0%94%E8%8B%B1%E8%AF%AD/"}]},{"title":"2021新增词汇","slug":"2021新增词汇","date":"2021-10-18T03:30:41.000Z","updated":"2021-12-06T09:23:00.644Z","comments":true,"path":"2021/10/18/2021新增词汇/","link":"","permalink":"https://utinner.gitee.io/2021/10/18/2021%E6%96%B0%E5%A2%9E%E8%AF%8D%E6%B1%87/","excerpt":"一.analytics n.分析学1.基本词义n.分析学 动词形式：analyze 名词形式：analysis","text":"一.analytics n.分析学1.基本词义n.分析学 动词形式：analyze 名词形式：analysis n.分析学 The company uses analytics to help identify where there may be bias in the hiring process.该公司使用分析学来帮助确定招聘过程中可能存在的偏见 词组 释义 identify 确定，识别 bias 偏见 process 过程 二.audit n.分析学1.基本词义n.审查，检查，审计v.审计，旁听（大学课程）【词根】audi- 听-&gt;旁听-&gt;审查 n.审计 One accounting firm,EY,uses an AI system that helps review contracts during an audit.安永会计事务所使用人工智能系统，在审计期间帮助审查合同。 词组 释义 contract n.合同 v.收缩 三.deliberation n.细想1.基本词义n.细想，深思熟虑 2.相关词汇 词组 释义 labor 劳动 liberty n.自由 deliberate adj.蓄意的，故意的 四.enact v.将…制定成法律，通过（法案）1.基本词义v.将…制定成法律，通过（法案） That means more battles like the one now going on between the Justice Department and California,which enacted a tough net neutrality law in the wake of the FCC’s abdication.这意味着随之而来的更多的斗争，就像司法部和加州之间正在进行的这场，加州在联邦通信委员会（FCC）失职后，颁布了一项强硬的网络中立法案。 词组 释义 tough adj.强硬的，无情的，健壮的，坚强的 n.粗暴的人，暴徒，恶棍 v.坚持，忍受，忍耐 Act 法案 justice n.争议，公平，法官，司法 Justice Department 司法部 go on 进行 wake 叫醒 neutrality 中立的 dic- 【词根】说话 abdicate 退位，失职 五.immunity n.免疫力1.基本词义n.免疫力 词组 释义 immun(e) adj.免疫的 mu- 【词根】改变 mutate v.变异；(使)突变；转变；转换 六.outperform v.做的比…好，胜过1.基本词义v.做的比…好，胜过 One company in the Uk,Phrasee,claims their software can outperform humans by up to 10 percent when it comes to email open rates.英国一家名为Phrasee的公司声称，他们的软件在（提升）邮件打开率方面比人类高出10%. 词组 释义 claims 声称 七.portraiture n.肖像，画像技法1.基本词义n.肖像，画像技法 词组 释义 portray v.描绘，描写 八.punctuality n.准时1.基本词义n.准时 Buses jump lights almost as frequently as cyclists because the target is punctuality.公交车几乎和骑自行车的人一样频繁闯红灯，因为公交车的目标就是准时。 词组 释义 punch v.打，打孔，用拳猛击 punctual adj.按时的；准时的；守时的 九.sovereignty n.主权1.基本词义n.主权 A move back to self-sufficiency,the argument goes,would boost the farming industry,political sovereignty and even the nation’s health.这种观点认为，恢复自给自足将促进农业，增强政治主权，甚至提升国民健康。 词组 释义 sovereign n.元首，君主 -eign 【词根】统治 foreign a.外国的 move 行动，移动 self-sufficiency a.自给自足的 sufficient adj.充足的 boost v.促进 n.提高 farming 农事，务农 industry 工业，行业 十.thorny adj.棘手的1.基本词义adj.棘手的 The question of who should pay for reskilling is a thorny one.谁应该为学习新技能买单是一个棘手的问题。 词组 释义 thorn n.荆棘，刺 hawthorn 山楂 reskilling v.(为新工作)学习新技能；教(某人)新技能 reskill的现在分词 十一.vacancy n.空位，空缺1.基本词义n.空位，空缺 词组 释义 vain adj.徒劳的；枉然的；无结果的；自负的；自视过高的 vacant adj.空缺的，未被占用的 vacuum n.真空 vanish v.消失 十二.vengeance n.报仇，复仇1.基本词义n.报仇，复仇 The threat of nationalisation may have been seen off for now,but it will return with a vengeance if the justified anger of passengers is not addressed in short order.目前国有化的威胁可能已经被消除，但如果乘客们该有的愤怒不能在短时间内得到解决，这种威胁将变本加厉地再现。 词组 释义 revenge n.报复，复仇 threat n.威胁；恐吓；凶兆； nationalisation 国有化 with a vengeance 程度更深地 justified adj. 正当的；(做某事)有正当理由的；事出有因；合乎情理 address v.解决 passengers 乘客 十三.难句解析 句子 释义 American assumptions and conventions 美国人的观念和习俗 would you mind closing the windows? 你介意去关上窗户吗？ He is no less than 12. 他已经12岁了 He is no more than 12. 他才12岁 He is not less than 12. 他至少12岁了。 He is not more than 12. 他最多12岁。 生词 单词 释义 assume 承担，假设，观点的提出 convention 会议，公约，习俗 sophisticated adj.复杂的；精密的；先进的；老练的；见多识广的；见过世面的；复杂巧妙的；水平高的；在行的 senior 资深的 insufficient adj.不充分的；不足的；不够重要的 remorse n.悔恨；自责；懊悔；非常遗憾 utterance n.用言语的表达；说话；话语；言论 drive a stick shift s驾驶手动换挡汽车 just adj.公正的 period n.一段时间，时期 reinforce vt.加剧，加强","categories":[{"name":"考研英语","slug":"考研英语","permalink":"https://utinner.gitee.io/categories/%E8%80%83%E7%A0%94%E8%8B%B1%E8%AF%AD/"}],"tags":[{"name":"考研英语","slug":"考研英语","permalink":"https://utinner.gitee.io/tags/%E8%80%83%E7%A0%94%E8%8B%B1%E8%AF%AD/"}]},{"title":"unit_1","slug":"unit-1","date":"2021-10-15T07:48:56.000Z","updated":"2021-12-06T09:23:00.895Z","comments":true,"path":"2021/10/15/unit-1/","link":"","permalink":"https://utinner.gitee.io/2021/10/15/unit-1/","excerpt":"一.work1.基本词义n. 工作（量）；职业；产品；著作，工作地点v. （使）工作有效；产生···作用","text":"一.work1.基本词义n. 工作（量）；职业；产品；著作，工作地点v. （使）工作有效；产生···作用 工作work placement 实习工作 | work skills 技能 2.相关词汇career n.生涯，经历，职业Asked about his choice of career,he says at high school he considered medical school before switching to electrical engineering. 被问起他的职业选择，他说高中时自己曾考虑去医学院，后来改修了电气工程。 词组 释义 electrical 电力的 engineering 工程学，工程 Asked 省略，He was asked about…；被动语态，他被问到 medical 医疗 switch to 切换到 labour n.劳动力 v.劳动，工作 词组 释义 labour cost 劳动力成本 cover the cost 支付成本 child labour 童工 work against 竭力反对，阻碍work on sth 从事于work out 成功地发展、计算出、找到（解决办法等）workout 锻炼she does a 20 minutes workout every morning. It turns out that the brain needs exercise in much the same way our muscles do,and the right mental workout can significantly improve our basic cognitive functions. 事实证明大脑跟肌肉一样都需要锻炼。适当的脑力锻炼能显著改善我们的基本认知功能 词组 释义 It turns out 事实证明是，结果是 brain 大脑 muscles 肌肉 significantly 重要地、重大地、明显地、显著地 cognitive 认知的 recognize v.认出 function 能力 workplace 工作场所workaholic 工作狂-aholic：…狂 workstation 工作台Tom senior anthropologist at the Center in Nick Mass,ensure that 90 percent of the uniforms and workstations fit recruits without alteration. Tom是Nick Mass中心的资深人类学家，他确保百分之90的制服和工作台适合新兵，而不需要改动。 词组 释义 anthropologist 人类学家 anthrop- 【词根】人 -ology 【词根】与学科相关 anthropology 人类学 senior 高级的，年龄大的，资深的 ensure v.确保，确定 insure v.投保 percent 百分比 uni- 【词根】统一 uniform 制服 fit 适合 recruits v.招聘。n.新人 alteration n.改变 alter v.改变 = change of+名词=形容词的作用。介词结构的形式之一 patchwork 拼凑物，混合物Tom’s back and forth on clean air is a pointed reminder of the limits to the patchwork,city-by-city approach that characterises efforts on air pollution across Europe,Britain very much included. Tom在清洁空气上的摇摆不定的态度直接表明了这个不一致的方法（不同的城市采取不同的措施）的局限性；这种方法体现了欧洲各国（特别是英国）在治理空气污染方面的努力。 词组 释义 back and forth n.前前后后、后后前前的摇摆不定的态度 back 向后 forth 向前 remind v.提醒 reminder n.提醒，APP中的提醒事项 pointed 直接的 limit 局限 approach v.接近。n.方法 characterises 以…为特点，名词变动词用 character n.性格，特点 effort n.努力 effort on sth 在某方面的努力 二.state1.基本词义n. 洲；国家；政府；状态；情况v. 声明，规定adg. 洲的，国家的，国有的 n.洲The bills are similar to a measure recently adopted in California,which last year became the first state to require gender quotas for private companies.这些提案类似于最近被加利福尼亚州所采用的一项措施,去年加利福尼亚州成为第一个要求对私营公司实行性别配额的洲 词组 释义 bills 比尔盖茨，账单，提案 be similar to 与…相似 measure 措施，方法 recently 最近的 adopted 采纳，采用，收养 require 需要，要求 quotas 配额 n.国家 head of states 国家元首 n.政府 a new State Department Building 美国国务院大楼 n.状态one of these urges has to do with creating a state of peace in the midst of turbulence,a “still point of the turning world” to borrow a phrase from Tom.其中一个迫切需求和在动荡中创造一种和平状态有关，借用Tom的话就是“一个旋转世界的静止点”。 词组 释义 urges n.冲动 v.督促，力劝 have to do with 与…有关 middle 中间 turbulence 动荡，颠簸 borrow a phrase from 借用…的话 adj.洲的federal,state and local government 联邦、洲和地方政府 federal 联邦的 2.相关词汇表示方法的单词 way method approach measure sector n.部门fund n.基金，专款approve v.批准，同意stated adj.规定的，声明的statement n.声明，表述overstate v.过分夸大status n.地位，身份，情形，状态，重要性Other scientists perform the specialised work of peer review also for free,because it is a central element in the acquisition of status and the production of scientific knowledge.其他科学家们也会免费进行专门的同行专家评审工作，因为这是获得学术地位和产出科学知识的核心要素 词组 释义 perform v.表演，履行，执行，演出，工作，运转 do sth. for free 免费做… n.-free 无…的 specialised adj.专门的，专业的 specialize v.专门研究 specialist n.专家 peer 同辈人，同行 pair 一对，一双 review 评审，评论 central adj.中心的 acquire v.获得 acquisition n.获得 immigration status 移民身份 financial status 财务状况 statute n.成文法，法令，法规 词组 释义 conflicted with 与…冲突，矛盾 enforcement n.执行 enforce v.强制执行 prior adj.优先的 priorities n.优先权 even if 即使 = even though even though 即使 as if 好像 = as though as though 好像 comply with 遵守，服从 = conform to = obey comply with…to the letter 严格遵守 statue n.雕像，塑像estate n.地产，庄园，住宅区，遗产real estate 房地产statistical adj.统计的，统计学的Most journals are weak in statistical review,and this damages the quality of what they publish.大多数期刊在统计数据审查方面都很薄弱，而这损害了其出版物的质量。 词组 释义 journal n.期刊，出版物，杂志 be weak in 在某方面弱 damage v.损害 publish 出版，发行 the quality of …的质量 what… 可以引导一个名词性的东西 statistic n.统计数字，统计资料stationary adj.静止不动的，固定的","categories":[{"name":"考研英语","slug":"考研英语","permalink":"https://utinner.gitee.io/categories/%E8%80%83%E7%A0%94%E8%8B%B1%E8%AF%AD/"}],"tags":[{"name":"考研英语","slug":"考研英语","permalink":"https://utinner.gitee.io/tags/%E8%80%83%E7%A0%94%E8%8B%B1%E8%AF%AD/"}]},{"title":"定时任务","slug":"定时任务","date":"2021-09-17T06:03:19.000Z","updated":"2021-12-06T09:23:00.905Z","comments":true,"path":"2021/09/17/定时任务/","link":"","permalink":"https://utinner.gitee.io/2021/09/17/%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1/","excerpt":"一.定时任务解决方案1.单机JVM1.1 Thread-Thread.sleep方法1234567891011121314public static void main(String[] args) &#123; Runnable runnable = () -&gt; &#123; while (true)&#123; try &#123; Thread.sleep(2000); System.out.println(&quot;定时任务执行&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;; Thread thread = new Thread(runnable); thread.start();&#125; 其实定时任务就是死循环","text":"一.定时任务解决方案1.单机JVM1.1 Thread-Thread.sleep方法1234567891011121314public static void main(String[] args) &#123; Runnable runnable = () -&gt; &#123; while (true)&#123; try &#123; Thread.sleep(2000); System.out.println(&quot;定时任务执行&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;; Thread thread = new Thread(runnable); thread.start();&#125; 其实定时任务就是死循环 1.2 TimerTask(java.util)12345678910111213141516171819public class TimerTaskDemo &#123; static int count = 0; public static void main(String[] args) &#123; TimerTask timerTask = new TimerTask() &#123; @Override public void run() &#123; count = count + 1; System.out.println(&quot;定时任务执行&quot; + count); &#125; &#125;; Timer timer = new Timer(); long delay = 0; long period = 1000; timer.scheduleAtFixedRate(timerTask,delay,period); &#125;&#125; 1.3 线程池execute(ScheduledExecutorService)123456789101112public class ScheduledExecutorServiceDemo &#123; static int count = 0; public static void main(String[] args) &#123; Runnable runnable = () -&gt; &#123; count++; System.out.println(&quot;定时任务执行&quot; + count); &#125;; ScheduledExecutorService scheduledExecutorService = new ScheduledThreadPoolExecutor(5); //第二个参数为首次执行的延迟时间，第三个参数为定时任务执行的间隔时间 scheduledExecutorService.scheduleAtFixedRate(runnable,1,3, TimeUnit.SECONDS); &#125;&#125; 1.4 Springboot中的定时任务注解@Schedule添加注解： 1234567@SpringBootApplication@EnableSchedulingpublic class TinnerDemoApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(TinnerDemoApplication.class, args); &#125;&#125; 定义job： 12345678@Componentpublic class BootJob &#123; //表示每两秒执行一次 @Scheduled(cron = &quot;0/2 * * * * ? &quot;) public void cronJob() &#123; System.out.println(new Date() + &quot; 执行中。。。。&quot;); &#125;&#125; 1.5 使用quartz-第三方框架定义job： 123456public class MyJob implements Job &#123; @Override public void execute(JobExecutionContext jobExecutionContext) throws JobExecutionException &#123; System.out.println(&quot;定时执行quartz任务&quot;); &#125;&#125; 测试： 12345678910111213141516171819202122public class TestQuartz &#123; public static void main(String[] args) throws SchedulerException &#123; //创建调度器工厂 SchedulerFactory schedulerFactory = new StdSchedulerFactory(); //从工厂中获取调度器实例 Scheduler scheduler = schedulerFactory.getScheduler(); //创建jobDetail JobDetail jb = JobBuilder.newJob(MyJob.class) .withDescription(&quot;this is a ran job&quot;) //job的描述 .withIdentity(&quot;ranJob&quot;,&quot;ranGroup&quot;) .build(); //3秒后启动任务 long time = System.currentTimeMillis() + 3* 1000L; //创建trigger Trigger t = TriggerBuilder.newTrigger() .startAt(new Date(time)) .withSchedule(CronScheduleBuilder.cronSchedule(&quot;0/2 * * * * ?&quot;)) .build(); scheduler.scheduleJob(jb, t); scheduler.start(); &#125;&#125; 2.传统分布式系统xxl-job","categories":[{"name":"Java","slug":"Java","permalink":"https://utinner.gitee.io/categories/Java/"}],"tags":[{"name":"定时任务","slug":"定时任务","permalink":"https://utinner.gitee.io/tags/%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1/"}]},{"title":"Java非阻塞IO和异步IO","slug":"Java非阻塞IO和异步IO","date":"2021-07-22T06:28:17.000Z","updated":"2021-12-06T09:23:00.734Z","comments":true,"path":"2021/07/22/Java非阻塞IO和异步IO/","link":"","permalink":"https://utinner.gitee.io/2021/07/22/Java%E9%9D%9E%E9%98%BB%E5%A1%9EIO%E5%92%8C%E5%BC%82%E6%AD%A5IO/","excerpt":"一. 阻塞模式 IO使用 Java NIO 包组成一个简单的客户端-服务端网络通讯所需要的 ServerSocketChannel、SocketChannel 和 Buffer 这里整合一下它们，给出一个完整的可运行的例子： 1234567891011121314151617181920public class Server &#123; public static void main(String[] args) throws IOException &#123; ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); // 监听 8080 端口进来的 TCP 链接 serverSocketChannel.socket().bind(new InetSocketAddress(8080)); while (true) &#123; // 这里会阻塞，直到有一个请求的连接进来 SocketChannel socketChannel = serverSocketChannel.accept(); // 开启一个新的线程来处理这个请求，然后在 while 循环中继续监听 8080 端口 SocketHandler handler = new SocketHandler(socketChannel); new Thread(handler).start(); &#125; &#125;&#125;","text":"一. 阻塞模式 IO使用 Java NIO 包组成一个简单的客户端-服务端网络通讯所需要的 ServerSocketChannel、SocketChannel 和 Buffer 这里整合一下它们，给出一个完整的可运行的例子： 1234567891011121314151617181920public class Server &#123; public static void main(String[] args) throws IOException &#123; ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); // 监听 8080 端口进来的 TCP 链接 serverSocketChannel.socket().bind(new InetSocketAddress(8080)); while (true) &#123; // 这里会阻塞，直到有一个请求的连接进来 SocketChannel socketChannel = serverSocketChannel.accept(); // 开启一个新的线程来处理这个请求，然后在 while 循环中继续监听 8080 端口 SocketHandler handler = new SocketHandler(socketChannel); new Thread(handler).start(); &#125; &#125;&#125; 这里看一下新的线程需要做什么，SocketHandler： 12345678910111213141516171819202122232425262728293031323334353637public class SocketHandler implements Runnable &#123; private SocketChannel socketChannel; public SocketHandler(SocketChannel socketChannel) &#123; this.socketChannel = socketChannel; &#125; @Override public void run() &#123; ByteBuffer buffer = ByteBuffer.allocate(1024); try &#123; // 将请求数据读入 Buffer 中 int num; while ((num = socketChannel.read(buffer)) &gt; 0) &#123; // 读取 Buffer 内容之前先 flip 一下 buffer.flip(); // 提取 Buffer 中的数据 byte[] bytes = new byte[num]; buffer.get(bytes); String re = new String(bytes, &quot;UTF-8&quot;); System.out.println(&quot;收到请求：&quot; + re); // 回应客户端 ByteBuffer writeBuffer = ByteBuffer.wrap((&quot;我已经收到你的请求，你的请求内容是：&quot; + re).getBytes()); socketChannel.write(writeBuffer); buffer.clear(); &#125; &#125; catch (IOException e) &#123; IOUtils.closeQuietly(socketChannel); &#125; &#125;&#125; 最后，贴一下客户端 SocketChannel 的使用，客户端比较简单： 1234567891011121314151617181920212223public class SocketChannelTest &#123; public static void main(String[] args) throws IOException &#123; SocketChannel socketChannel = SocketChannel.open(); socketChannel.connect(new InetSocketAddress(&quot;localhost&quot;, 8080)); // 发送请求 ByteBuffer buffer = ByteBuffer.wrap(&quot;1234567890&quot;.getBytes()); socketChannel.write(buffer); // 读取响应 ByteBuffer readBuffer = ByteBuffer.allocate(1024); int num; if ((num = socketChannel.read(readBuffer)) &gt; 0) &#123; readBuffer.flip(); byte[] re = new byte[num]; readBuffer.get(re); String result = new String(re, &quot;UTF-8&quot;); System.out.println(&quot;返回值: &quot; + result); &#125; &#125;&#125; 上面介绍的阻塞模式的代码应该很好理解：来一个新的连接，我们就新开一个线程来处理这个连接，之后的操作全部由那个线程来完成。 那么，这个模式下的性能瓶颈在哪里呢？ 首先，每次来一个连接都开一个新的线程这肯定是不合适的。当活跃连接数在几十几百的时候当然是可以这样做的，但如果活跃连接数是几万几十万的时候，这么多线程明显就不行了。每个线程都需要一部分内存，内存会被迅速消耗，同时，线程切换的开销非常大。 其次，阻塞操作在这里也是一个问题。首先，accept() 是一个阻塞操作，当 accept() 返回的时候，代表有一个连接可以使用了，我们这里是马上就新建线程来处理这个 SocketChannel 了，但是，但是这里不代表对方就将数据传输过来了。所以，SocketChannel#read 方法将阻塞，等待数据，明显这个等待是不值得的。同理，write 方法也需要等待通道可写才能执行写入操作，这边的阻塞等待也是不值得的。 二. 非阻塞 IO说完了阻塞模式的使用及其缺点以后，我们这里就可以介绍非阻塞 IO 了。 非阻塞 IO 的核心在于使用一个 Selector 来管理多个通道，可以是 SocketChannel，也可以是 ServerSocketChannel，将各个通道注册到 Selector 上，指定监听的事件。 之后可以只用一个线程来轮询这个 Selector，看看上面是否有通道是准备好的，当通道准备好可读或可写，然后才去开始真正的读写，这样速度就很快了。我们就完全没有必要给每个通道都起一个线程。 NIO 中 Selector 是对底层操作系统实现的一个抽象，管理通道状态其实都是底层系统实现的，这里简单介绍下在不同系统下的实现。 select：上世纪 80 年代就实现了，它支持注册 FD_SETSIZE(1024) 个 socket，在那个年代肯定是够用的，不过现在嘛，肯定是不行了。 poll：1997 年，出现了 poll 作为 select 的替代者，最大的区别就是，poll 不再限制 socket 数量。 select 和 poll 都有一个共同的问题，那就是它们都只会告诉你有几个通道准备好了，但是不会告诉你具体是哪几个通道。所以，一旦知道有通道准备好以后，自己还是需要进行一次扫描，显然这个不太好，通道少的时候还行，一旦通道的数量是几十万个以上的时候，扫描一次的时间都很可观了，时间复杂度 O(n)。所以，后来才催生了以下实现。 epoll：2002 年随 Linux 内核 2.5.44 发布，epoll 能直接返回具体的准备好的通道，时间复杂度 O(1)。 除了 Linux 中的 epoll，2000 年 FreeBSD 出现了Kqueue，还有就是，Solaris 中有 /dev/poll。 前面说了那么多实现，但是没有出现 Windows，Windows 平台的非阻塞 IO 使用 select，我们也不必觉得 Windows 很落后，在 Windows 中 IOCP 提供的异步 IO 是比较强大的。 我们回到 Selector，毕竟 JVM 就是这么一个屏蔽底层实现的平台，我们面向 Selector 编程就可以了。 来一个可运行的实例代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class SelectorServer &#123; public static void main(String[] args) throws IOException &#123; Selector selector = Selector.open(); ServerSocketChannel server = ServerSocketChannel.open(); server.socket().bind(new InetSocketAddress(8080)); // 将其注册到 Selector 中，监听 OP_ACCEPT 事件 server.configureBlocking(false); server.register(selector, SelectionKey.OP_ACCEPT); while (true) &#123; int readyChannels = selector.select(); if (readyChannels == 0) &#123; continue; &#125; Set&lt;SelectionKey&gt; readyKeys = selector.selectedKeys(); // 遍历 Iterator&lt;SelectionKey&gt; iterator = readyKeys.iterator(); while (iterator.hasNext()) &#123; SelectionKey key = iterator.next(); iterator.remove(); if (key.isAcceptable()) &#123; // 有已经接受的新的到服务端的连接 SocketChannel socketChannel = server.accept(); // 有新的连接并不代表这个通道就有数据， // 这里将这个新的 SocketChannel 注册到 Selector，监听 OP_READ 事件，等待数据 socketChannel.configureBlocking(false); socketChannel.register(selector, SelectionKey.OP_READ); &#125; else if (key.isReadable()) &#123; // 有数据可读 // 上面一个 if 分支中注册了监听 OP_READ 事件的 SocketChannel SocketChannel socketChannel = (SocketChannel) key.channel(); ByteBuffer readBuffer = ByteBuffer.allocate(1024); int num = socketChannel.read(readBuffer); if (num &gt; 0) &#123; // 处理进来的数据... System.out.println(&quot;收到数据：&quot; + new String(readBuffer.array()).trim()); ByteBuffer buffer = ByteBuffer.wrap(&quot;返回给客户端的数据...&quot;.getBytes()); socketChannel.write(buffer); &#125; else if (num == -1) &#123; // -1 代表连接已经关闭 socketChannel.close(); &#125; &#125; &#125; &#125; &#125;&#125; 三. NIOMore New IO，或称 NIO.2，随 JDK 1.7 发布，包括了引入异步 IO 接口和 Paths 等文件访问接口。 异步这个词，我想对于绝大多数开发者来说都很熟悉，很多场景下我们都会使用异步。 通常，我们会有一个线程池用于执行异步任务，提交任务的线程将任务提交到线程池就可以立马返回，不必等到任务真正完成。如果想要知道任务的执行结果，通常是通过传递一个回调函数的方式，任务结束后去调用这个函数。 同样的原理，Java 中的异步 IO 也是一样的，都是由一个线程池来负责执行任务，然后使用回调或自己去查询结果。 大部分开发者都知道为什么要这么设计了，这里再啰嗦一下。异步 IO 主要是为了控制线程数量，减少过多的线程带来的内存消耗和 CPU 在线程调度上的开销。 在 Unix/Linux 等系统中，JDK 使用了并发包中的线程池来管理任务，具体可以查看 AsynchronousChannelGroup 的源码。 在 Windows 操作系统中，提供了一个叫做 I/O Completion Ports 的方案，通常简称为 IOCP，操作系统负责管理线程池，其性能非常优异，所以在 Windows 中 JDK 直接采用了 IOCP 的支持，使用系统支持，把更多的操作信息暴露给操作系统，也使得操作系统能够对我们的 IO 进行一定程度的优化。 在 Linux 中其实也是有异步 IO 系统实现的，但是限制比较多，性能也一般，所以 JDK 采用了自建线程池的方式。 本文还是以实用为主，想要了解更多信息请自行查找其他资料，下面对 Java 异步 IO 进行实践性的介绍。 总共有三个类需要我们关注，分别是 AsynchronousSocketChannel，AsynchronousServerSocketChannel 和 AsynchronousFileChannel。 Java 异步 IO 提供了两种使用方式，分别是返回 Future 实例和使用回调函数。 3.1 返回 Future 实例返回 java.util.concurrent.Future 实例的方式我们应该很熟悉，JDK 线程池就是这么使用的。Future 接口的几个方法语义在这里也是通用的，这里先做简单介绍。 future.isDone();判断操作是否已经完成，包括了正常完成、异常抛出、取消 future.cancel(true);取消操作，方式是中断。参数 true 说的是，即使这个任务正在执行，也会进行中断。 future.isCancelled();是否被取消，只有在任务正常结束之前被取消，这个方法才会返回 true future.get();这是我们的老朋友，获取执行结果，阻塞。 future.get(10, TimeUnit.SECONDS);如果上面的 get() 方法的阻塞你不满意，那就设置个超时时间。 3.2 提供 CompletionHandler 回调函数java.nio.channels.CompletionHandler 接口定义： 123456public interface CompletionHandler&lt;V,A&gt; &#123; void completed(V result, A attachment); void failed(Throwable exc, A attachment);&#125; 注意，参数上有个 attachment，虽然不常用，我们可以在各个支持的方法中传递这个参数值 123456789101112AsynchronousServerSocketChannel listener = AsynchronousServerSocketChannel.open().bind(null);// accept 方法的第一个参数可以传递 attachmentlistener.accept(attachment, new CompletionHandler&lt;AsynchronousSocketChannel, Object&gt;() &#123; public void completed( AsynchronousSocketChannel client, Object attachment) &#123; // &#125; public void failed(Throwable exc, Object attachment) &#123; // &#125;&#125;); 3.3 AsynchronousFileChannel首先，我们就来关注异步的文件 IO，前面我们说了，文件 IO 在所有的操作系统中都不支持非阻塞模式，但是我们可以对文件 IO 采用异步的方式来提高性能。 下面，我会介绍 AsynchronousFileChannel 里面的一些重要的接口，都很简单。实例化： 1AsynchronousFileChannel channel = AsynchronousFileChannel.open(Paths.get(&quot;/Users/hongjie/test.txt&quot;)); 一旦实例化完成，我们就可以着手准备将数据读入到 Buffer 中： 12ByteBuffer buffer = ByteBuffer.allocate(1024);Future&lt;Integer&gt; result = channel.read(buffer, 0); 异步文件通道的读操作和写操作都需要提供一个文件的开始位置，文件开始位置为 0 除了使用返回 Future 实例的方式，也可以采用回调函数进行操作，接口如下： 1234public abstract &lt;A&gt; void read(ByteBuffer dst, long position, A attachment, CompletionHandler&lt;Integer,? super A&gt; handler); 顺便也贴一下写操作的两个版本的接口： 123456public abstract Future&lt;Integer&gt; write(ByteBuffer src, long position);public abstract &lt;A&gt; void write(ByteBuffer src, long position, A attachment, CompletionHandler&lt;Integer,? super A&gt; handler); 我们可以看到，AIO 的读写主要也还是与 Buffer 打交道，这个与 NIO 是一脉相承的。 另外，还提供了用于将内存中的数据刷入到磁盘的方法： 1public abstract void force(boolean metaData) throws IOException; 因为我们对文件的写操作，操作系统并不会直接针对文件操作，系统会缓存，然后周期性地刷入到磁盘。如果希望将数据及时写入到磁盘中，以免断电引发部分数据丢失，可以调用此方法。参数如果设置为 true，意味着同时也将文件属性信息更新到磁盘。 还有，还提供了对文件的锁定功能，我们可以锁定文件的部分数据，这样可以进行排他性的操作。 1public abstract Future&lt;FileLock&gt; lock(long position, long size, boolean shared); position 是要锁定内容的开始位置，size 指示了要锁定的区域大小，shared 指示需要的是共享锁还是排他锁 当然，也可以使用回调函数的版本： 12345public abstract &lt;A&gt; void lock(long position, long size, boolean shared, A attachment, CompletionHandler&lt;FileLock,? super A&gt; handler); 文件锁定功能上还提供了 tryLock 方法，此方法会快速返回结果： 12public abstract FileLock tryLock(long position, long size, boolean shared) throws IOException; 这个方法很简单，就是尝试去获取锁，如果该区域已被其他线程或其他应用锁住，那么立刻返回 null，否则返回 FileLock 对象。 AsynchronousFileChannel 操作大体上也就以上介绍的这些接口。 3.4 AsynchronousServerSocketChannel这个类对应的是非阻塞 IO 的 ServerSocketChannel 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package com.tinner.aio;import java.io.IOException;import java.net.InetSocketAddress;import java.net.SocketAddress;import java.nio.ByteBuffer;import java.nio.channels.AsynchronousServerSocketChannel;import java.nio.channels.AsynchronousSocketChannel;import java.nio.channels.CompletionHandler;public class Server &#123; public static void main(String[] args) throws IOException &#123; // 实例化，并监听端口 AsynchronousServerSocketChannel server = AsynchronousServerSocketChannel.open().bind(new InetSocketAddress(8080)); // 自己定义一个 Attachment 类，用于传递一些信息 Attachment att = new Attachment(); att.setServer(server); server.accept(att, new CompletionHandler&lt;AsynchronousSocketChannel, Attachment&gt;() &#123; @Override public void completed(AsynchronousSocketChannel client, Attachment att) &#123; try &#123; SocketAddress clientAddr = client.getRemoteAddress(); System.out.println(&quot;收到新的连接：&quot; + clientAddr); // 收到新的连接后，server 应该重新调用 accept 方法等待新的连接进来 att.getServer().accept(att, this); Attachment newAtt = new Attachment(); newAtt.setServer(server); newAtt.setClient(client); newAtt.setReadMode(true); newAtt.setBuffer(ByteBuffer.allocate(2048)); // 这里也可以继续使用匿名实现类，不过代码不好看，所以这里专门定义一个类 client.read(newAtt.getBuffer(), newAtt, new ChannelHandler()); &#125; catch (IOException ex) &#123; ex.printStackTrace(); &#125; &#125; @Override public void failed(Throwable t, Attachment att) &#123; System.out.println(&quot;accept failed&quot;); &#125; &#125;); // 为了防止 main 线程退出 try &#123; Thread.currentThread().join(); &#125; catch (InterruptedException e) &#123; &#125; &#125;&#125; 看一下 ChannelHandler 类： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package com.tinner.aio;import java.io.IOException;import java.nio.ByteBuffer;import java.nio.channels.CompletionHandler;import java.nio.charset.Charset;public class ChannelHandler implements CompletionHandler&lt;Integer, Attachment&gt; &#123; @Override public void completed(Integer result, Attachment att) &#123; if (att.isReadMode()) &#123; // 读取来自客户端的数据 ByteBuffer buffer = att.getBuffer(); buffer.flip(); byte bytes[] = new byte[buffer.limit()]; buffer.get(bytes); String msg = new String(buffer.array()).toString().trim(); System.out.println(&quot;收到来自客户端的数据: &quot; + msg); // 响应客户端请求，返回数据 buffer.clear(); buffer.put(&quot;Response from server!&quot;.getBytes(Charset.forName(&quot;UTF-8&quot;))); att.setReadMode(false); buffer.flip(); // 写数据到客户端也是异步 att.getClient().write(buffer, att, this); &#125; else &#123; // 到这里，说明往客户端写数据也结束了，有以下两种选择: // 1. 继续等待客户端发送新的数据过来// att.setReadMode(true);// att.getBuffer().clear();// att.getClient().read(att.getBuffer(), att, this); // 2. 既然服务端已经返回数据给客户端，断开这次的连接 try &#123; att.getClient().close(); &#125; catch (IOException e) &#123; &#125; &#125; &#125; @Override public void failed(Throwable t, Attachment att) &#123; System.out.println(&quot;连接断开&quot;); &#125;&#125; 顺便再贴一下自定义的 Attachment 类： 1234567public class Attachment &#123; private AsynchronousServerSocketChannel server; private AsynchronousSocketChannel client; private boolean isReadMode; private ByteBuffer buffer; // getter &amp; setter&#125; 这样，一个简单的服务端就写好了，接下来可以接收客户端请求了。上面我们用的都是回调函数的方式。 3.5 AsynchronousSocketChannelAsynchronousSocketChannel和非阻塞 IO 基本类似。 这边做个简单演示 12345678910111213141516171819202122232425262728293031323334package com.tinner.aio;import java.io.IOException;import java.net.InetSocketAddress;import java.nio.ByteBuffer;import java.nio.channels.AsynchronousSocketChannel;import java.nio.charset.Charset;import java.util.concurrent.ExecutionException;import java.util.concurrent.Future;public class Client &#123; public static void main(String[] args) throws Exception &#123; AsynchronousSocketChannel client = AsynchronousSocketChannel.open(); // 来个 Future 形式的 Future&lt;?&gt; future = client.connect(new InetSocketAddress(8080)); // 阻塞一下，等待连接成功 future.get(); Attachment att = new Attachment(); att.setClient(client); att.setReadMode(false); att.setBuffer(ByteBuffer.allocate(2048)); byte[] data = &quot;I am obot!&quot;.getBytes(); att.getBuffer().put(data); att.getBuffer().flip(); // 异步发送数据到服务端 client.write(att.getBuffer(), att, new ClientChannelHandler()); // 这里休息一下再退出，给出足够的时间处理数据 Thread.sleep(2000); &#125;&#125; 往里面看下 ClientChannelHandler 类： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package com.tinner.aio;import java.io.IOException;import java.nio.ByteBuffer;import java.nio.channels.CompletionHandler;import java.nio.charset.Charset;public class ClientChannelHandler implements CompletionHandler&lt;Integer, Attachment&gt; &#123; @Override public void completed(Integer result, Attachment att) &#123; ByteBuffer buffer = att.getBuffer(); if (att.isReadMode()) &#123; // 读取来自服务端的数据 buffer.flip(); byte[] bytes = new byte[buffer.limit()]; buffer.get(bytes); String msg = new String(bytes, Charset.forName(&quot;UTF-8&quot;)); System.out.println(&quot;收到来自服务端的响应数据: &quot; + msg); // 接下来，有以下两种选择: // 1. 向服务端发送新的数据// att.setReadMode(false);// buffer.clear();// String newMsg = &quot;new message from client&quot;;// byte[] data = newMsg.getBytes(Charset.forName(&quot;UTF-8&quot;));// buffer.put(data);// buffer.flip();// att.getClient().write(buffer, att, this); // 2. 关闭连接 try &#123; att.getClient().close(); &#125; catch (IOException e) &#123; &#125; &#125; else &#123; // 写操作完成后，会进到这里 att.setReadMode(true); buffer.clear(); att.getClient().read(buffer, att, this); &#125; &#125; @Override public void failed(Throwable t, Attachment att) &#123; System.out.println(&quot;服务器无响应&quot;); &#125;&#125; 以上代码都是可以运行调试的，如果读者碰到问题，请在评论区留言。 3.6 Asynchronous Channel Groups为了知识的完整性，有必要对 group 进行介绍，其实也就是介绍 AsynchronousChannelGroup 这个类。之前我们说过，异步 IO 一定存在一个线程池，这个线程池负责接收任务、处理 IO 事件、回调等。这个线程池就在 group 内部，group 一旦关闭，那么相应的线程池就会关闭。 AsynchronousServerSocketChannels 和 AsynchronousSocketChannels 是属于 group 的，当我们调用 AsynchronousServerSocketChannel 或 AsynchronousSocketChannel 的 open() 方法的时候，相应的 channel 就属于默认的 group，这个 group 由 JVM 自动构造并管理。 如果我们想要配置这个默认的 group，可以在 JVM 启动参数中指定以下系统变量： 1234// 此系统变量用于设置 ThreadFactory，它应该是 java.util.concurrent.ThreadFactory 实现类的全限定类名。一旦我们指定了这个 ThreadFactory 以后，group 中的线程就会使用该类产生。java.nio.channels.DefaultThreadPool.threadFactory// 用于设置线程池的初始大小。java.nio.channels.DefaultThreadPool.initialSize 可能你会想要使用自己定义的 group，这样可以对其中的线程进行更多的控制，使用以下几个方法即可： AsynchronousChannelGroup.withCachedThreadPool(ExecutorService executor, int initialSize) AsynchronousChannelGroup.withFixedThreadPool(int nThreads, ThreadFactory threadFactory) AsynchronousChannelGroup.withThreadPool(ExecutorService executor) 熟悉线程池的读者对这些方法应该很好理解，它们都是 AsynchronousChannelGroup 中的静态方法。 至于 group 的使用就很简单了，代码一看就懂： 1234AsynchronousChannelGroup group = AsynchronousChannelGroup .withFixedThreadPool(10, Executors.defaultThreadFactory());AsynchronousServerSocketChannel server = AsynchronousServerSocketChannel.open(group);AsynchronousSocketChannel client = AsynchronousSocketChannel.open(group); AsynchronousFileChannels 不属于 group。但是它们也是关联到一个线程池的，如果不指定，会使用系统默认的线程池，如果想要使用指定的线程池，可以在实例化的时候使用以下方法： 123456public static AsynchronousFileChannel open(Path file, Set&lt;? extends OpenOption&gt; options, ExecutorService executor, FileAttribute&lt;?&gt;... attrs) &#123; ...&#125; 到这里，异步 IO 就算介绍完成了。","categories":[{"name":"Java","slug":"Java","permalink":"https://utinner.gitee.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://utinner.gitee.io/tags/Java/"},{"name":"IO","slug":"IO","permalink":"https://utinner.gitee.io/tags/IO/"}]},{"title":"HTTPS原理","slug":"HTTPS原理","date":"2021-07-20T09:43:45.000Z","updated":"2021-12-06T09:23:00.722Z","comments":true,"path":"2021/07/20/HTTPS原理/","link":"","permalink":"https://utinner.gitee.io/2021/07/20/HTTPS%E5%8E%9F%E7%90%86/","excerpt":"HTTP请求都是明文传输的，所谓的明文指的是没有经过加密的信息，如果HTTP请求被黑客拦截，并且里面含有银行卡密码等敏感数据的话，会非常危险。为了解决这个问题，Netscape 公司制定了HTTPS协议，HTTPS可以将数据加密传输，也就是传输的是密文，即便黑客在传输过程中拦截到数据也无法破译，这就保证了网络通信的安全。 一.密码学基础明文明文指的是未被加密过的原始数据 密文明文被某种加密算法加密之后，会变成密文，从而确保原始数据的安全。密文也可以被解密，得到原始的明文。 密钥密钥是一种参数，它是在明文转换为密文或将密文转换为明文的算法中输入的参数。密钥分为对称密钥与非对称密钥，分别应用在对称加密和非对称加密上。 对称加密对称加密又叫做私钥加密，即信息的发送方和接收方使用同一个密钥去加密和解密数据。对称加密的特点是算法公开、加密和解密速度快，适合于对大数据量进行加密，常见的对称加密算法有DES、3DES、TDEA、Blowfish、RC5和IDEA。 加密：明文+加密算法+私钥—&gt;密文 解密：密文+解密算法+私钥—&gt;明文","text":"HTTP请求都是明文传输的，所谓的明文指的是没有经过加密的信息，如果HTTP请求被黑客拦截，并且里面含有银行卡密码等敏感数据的话，会非常危险。为了解决这个问题，Netscape 公司制定了HTTPS协议，HTTPS可以将数据加密传输，也就是传输的是密文，即便黑客在传输过程中拦截到数据也无法破译，这就保证了网络通信的安全。 一.密码学基础明文明文指的是未被加密过的原始数据 密文明文被某种加密算法加密之后，会变成密文，从而确保原始数据的安全。密文也可以被解密，得到原始的明文。 密钥密钥是一种参数，它是在明文转换为密文或将密文转换为明文的算法中输入的参数。密钥分为对称密钥与非对称密钥，分别应用在对称加密和非对称加密上。 对称加密对称加密又叫做私钥加密，即信息的发送方和接收方使用同一个密钥去加密和解密数据。对称加密的特点是算法公开、加密和解密速度快，适合于对大数据量进行加密，常见的对称加密算法有DES、3DES、TDEA、Blowfish、RC5和IDEA。 加密：明文+加密算法+私钥—&gt;密文 解密：密文+解密算法+私钥—&gt;明文 其加密过程中的私钥与解密过程中用到的私钥是同一个密钥，这也是称加密之所以称之为“对称”的原因。由于对称加密的算法是公开的，所以一旦私钥被泄露，那么密文就很容易被破解，所以对称加密的缺点是密钥安全管理困难。 非对称加密非对称加密也叫做公钥加密。非对称加密与对称加密相比，其安全性更好。对称加密的通信双方使用相同的密钥，如果一方的密钥遭泄露，那么整个通信就会被破解。而非对称加密使用一对密钥，即公钥和私钥，且二者成对出现。 私钥被自己保存，不能对外泄露。公钥指的是公共的密钥，任何人都可以获得该密钥。用公钥或私钥中的任何一个进行加密，用另一个进行解密。公钥和私钥是一一对应的被公钥加密过的密文只能被私钥解密，过程如下： 明文 + 加密算法 + 公钥 —&gt; 密文， 密文 + 解密算法 + 私钥 —&gt; 明文 被私钥加密过的密文只能被公钥解密，过程如下： 明文 + 加密算法 + 私钥 —&gt; 密文， 密文 + 解密算法 + 公钥 —&gt; 明文 由于加密和解密使用了两个不同的密钥，这就是非对称加密“非对称”的原因。非对称加密的缺点是加密和解密花费时间长、速度慢，只适合对少量数据进行加密。在非对称加密中使用的主要算法有：RSA、Elgamal、Rabin、D-H、ECC（椭圆曲线加密算法）等。 二.HTTPS通信过程HTTPS协议 = HTTP协议 + SSL/TLS协议，在HTTPS数据传输的过程中，需要用SSL/TLS对数据进行加密和解密，需要用HTTP对加密后的数据进行传输，由此可以看出HTTPS是由HTTP和SSL/TLS一起合作完成的。 SSL的全称是Secure Sockets Layer，即安全套接层协议，是为网络通信提供安全及数据完整性的一种安全协议。SSL协议在1994年被Netscape发明，后来各个浏览器均支持SSL，其最新的版本是3.0 TLS的全称是Transport Layer Security，即安全传输层协议，最新版本的TLS（Transport Layer Security，传输层安全协议）是IETF（Internet Engineering Task Force，Internet工程任务组）制定的一种新的协议，它建立在SSL 3.0协议规范之上，是SSL 3.0的后续版本。在TLS与SSL3.0之间存在着显著的差别，主要是它们所支持的加密算法不同，所以TLS与SSL3.0不能互操作。虽然TLS与SSL3.0在加密算法上不同，但是在我们理解HTTPS的过程中，我们可以把SSL和TLS看做是同一个协议。 HTTPS为了兼顾安全与效率，同时使用了对称加密和非对称加密。数据是被对称加密传输的，对称加密过程需要客户端的一个密钥，为了确保能把该密钥安全传输到服务器端，采用非对称加密对该密钥进行加密传输，总的来说，对数据进行对称加密，对称加密所要使用的密钥通过非对称加密传输。 HTTPS在传输的过程中会涉及到三个密钥： 服务器端的公钥和私钥，用来进行非对称加密 客户端生成的随机密钥，用来进行对称加密 一个HTTPS请求实际上包含了两次HTTP传输，可以细分为8步： 客户端向服务器发起HTTPS请求，连接到服务器的443端口 服务器端有一个密钥对，即公钥和私钥，是用来进行非对称加密使用的，服务器端保存着私钥，不能将其泄露，公钥可以发送给任何人。 服务器将自己的公钥发送给客户端。 客户端收到服务器端的证书之后，会对证书进行检查，验证其合法性，如果发现发现证书有问题，那么HTTPS传输就无法继续。严格的说，这里应该是验证服务器发送的数字证书的合法性。如果公钥合格，那么客户端会生成一个随机值，这个随机值就是用于进行对称加密的密钥，我们将该密钥称之为client key，即客户端密钥。然后用服务器的公钥对客户端密钥进行非对称加密，这样客户端密钥就变成密文了，至此，HTTPS中的第一次HTTP请求结束。 客户端会发起HTTPS中的第二个HTTP请求，将加密之后的客户端密钥发送给服务器。 服务器接收到客户端发来的密文之后，会用自己的私钥对其进行非对称解密，解密之后的明文就是客户端密钥，然后用客户端密钥对数据进行对称加密，这样数据就变成了密文。 然后服务器将加密后的密文发送给客户端。 客户端收到服务器发送来的密文，用客户端密钥对其进行对称解密，得到服务器发送的数据。这样HTTPS中的第二个HTTP请求结束，整个HTTPS传输完成。 三.CACA是Certification Authority的缩写，它代表世界上那些权威的证书颁发机构。 1.CA需要做什么CA 要验证这个域名真的是你的：通常就是通过 DNS 记录或者就是你在指定 URI 下放置一个特殊文件，让 CA 可以在外网环境下访问到它。CA 是一个非常关键的角色，因为它签出来的任何证书都是被信任的，所以这要求每个 CA 都不能乱来。 Let’s Encrypt 机构提供了免费的证书，那有什么区别呢？Let’s Encrypt 它只验证了这个域名是你的，然后就可以给你免费签发证书，这个证书的有效期是 3 个月，到期要自己去更新。因为它只验证了你的域名，所以这类证书又称为 DV 证书（Domain Validation）。 而一些收费的 CA 可以签发 OV 证书（Organization Validation）或 EV 证书（Extended Validation），他们不仅会验证这个域名真的是你的，还会人工验证你的公司是否符合他们的各项签发标准，所以收费也比较贵。通常这些证书的有效期是 1 年。 对于浏览器来说，通常会根据你的证书是 DV 还是 OV，来呈现不同的样式，所以有一种花钱的证书更香的感觉。 但是从技术上来说，它们都是提供一样的保护级别的，在最新的 Chrome 上，它没有区别对待，一律显示一个锁。 2.证书申请首先我们要生成一个 CSR，它的全称是 Certificate Signing Request，这个文件包含了你要申请的证书的各种信息，这和在某个 CA 的后台填写一个申请表单是一个意思，只是这样可以规范所有 CA 遵守一致的规则。这里我们需要使用一个叫 openssl 的软件，执行下面的命令： 1openssl req -new -newkey rsa:2048 -nodes -keyout jinping.xyz.key -out jinping.xyz.csr 进入交互界面后，需要你填写国家、城市、公司名字、部门名字、申请的域名、邮箱地址。有些 CA 支持中文，大部分不支持，这里建议都是用英文字符。 然后我们就会得到两个文本文件： 12jinping.xyz.csr jinping.xyz.key 其中一个是 CSR 文件，用来发给 CA 申请证书的，另一个是私钥。私钥需要好好保存，等证书申请完成以后要用。从域名的角度，证书分为单域名、通配符域名、多域名证书。以单域名 jinping.xyz 为例子，通配符和多域名也很好理解，在填写域名的时候按照格式填就可以了。生成出来的 jinping.xyz.csr 文件，它的内容是这样的 123456789101112131415161718-----BEGIN CERTIFICATE REQUEST-----MIIC+TCCAeECAQAwgYkxCzAJBgNVBAYTAmNuMRAwDgYDVQQIDAdiZWlqaW5nMQ4wDAYDVQQHDAVjaGluYTEQMA4GA1UECgwHeW9uZ2h1aTEQMA4GA1UECwwHc2VjdGlvbjEQMA4GA1UEAwwHamlucGluZzEiMCAGCSqGSIb3DQEJARYTamlucGluZzA5ODJAMTYzLmNvbTCCASIwDQYJKoZIhvcNAQEBBQADggEPADCCAQoCggEBANC5kvprdmFmgk+W0Fw1Co+kj2h97jj5ibZtoytUyq3nlHEXdrXMqnsz1sR4mBa3J8qbQZ2FkEB4ShU7gynTS+zlI7Vq7tU29TC1vZGhNUo3TlhSj412VXxjImlCvh+gAhQbHkkFsMlvn3YNphdlI/Du36jYcecJ1J4CznY6RYdPstbqBeltVuREFZL6gr34n8WDRlU333pIjONMnwFa8JVmQO/6TOvJn7xfc9HMdq7Uvz7RLk0mOdCY8NfW5603/IoFxQ5YaLGhULb9v0omprxGiTm+keC0m6LB3Y0JFZdkOwyGkznEsLJ+vZ7NA11YGKKb4zmLjNg1pQp1aavWxBECAwEAAaAqMBEGCSqGSIb3DQEJAjEEDAJ5aDAVBgkqhkiG9w0BCQcxCAwGMDUwNDAxMA0GCSqGSIb3DQEBCwUAA4IBAQBvL6QvPB+weRBudlPTEYv4GEY3I5JxhdxAB57wWzDmn96xRuChlPMyRHd6XiMXM2nnv02GCNDyPP6Zx6C80rQFbNvzqa9298wGhFX2jRFXVW/Z1zsdn1sXk2B3Pa7dW0FEgAN+uc+CbV2HALdtRvAiFxvcenWm9aMShhk2rpl0NPZ1Xa5bY0zM+Ew3Qq/W0zCuJVLuV+7Rf8CRP1RNZD7FoESTmiKvBTE0fG0WAjdPmXznAfbraP/cljdMk+Ccn9tQ+SgCfa5aedXPAFxgs1KW1LJ3vi6X5Jvoz0BhABNPz3xVYGqOV82/UR+MP5PVZvbXO6lWLghmXj2twSwH4pXy-----END CERTIFICATE REQUEST----- 进入 https://decoder.link/result 进行 decode，可以得到： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546Certificate Request: Data: Version: 1 (0x0) Subject: C = cn, ST = beijing, L = china, O = yonghui, OU = section, CN = jinping, emailAddress = jinping0982@163.com Subject Public Key Info: Public Key Algorithm: rsaEncryption Public-Key: (2048 bit) Modulus: 00:d0:b9:92:fa:6b:76:61:66:82:4f:96:d0:5c:35: 0a:8f:a4:8f:68:7d:ee:38:f9:89:b6:6d:a3:2b:54: ca:ad:e7:94:71:17:76:b5:cc:aa:7b:33:d6:c4:78: 98:16:b7:27:ca:9b:41:9d:85:90:40:78:4a:15:3b: 83:29:d3:4b:ec:e5:23:b5:6a:ee:d5:36:f5:30:b5: bd:91:a1:35:4a:37:4e:58:52:8f:8d:76:55:7c:63: 22:69:42:be:1f:a0:02:14:1b:1e:49:05:b0:c9:6f: 9f:76:0d:a6:17:65:23:f0:ee:df:a8:d8:71:e7:09: d4:9e:02:ce:76:3a:45:87:4f:b2:d6:ea:05:e9:6d: 56:e4:44:15:92:fa:82:bd:f8:9f:c5:83:46:55:37: df:7a:48:8c:e3:4c:9f:01:5a:f0:95:66:40:ef:fa: 4c:eb:c9:9f:bc:5f:73:d1:cc:76:ae:d4:bf:3e:d1: 2e:4d:26:39:d0:98:f0:d7:d6:e7:ad:37:fc:8a:05: c5:0e:58:68:b1:a1:50:b6:fd:bf:4a:26:a6:bc:46: 89:39:be:91:e0:b4:9b:a2:c1:dd:8d:09:15:97:64: 3b:0c:86:93:39:c4:b0:b2:7e:bd:9e:cd:03:5d:58: 18:a2:9b:e3:39:8b:8c:d8:35:a5:0a:75:69:ab:d6: c4:11 Exponent: 65537 (0x10001) Attributes: unstructuredName :yh challengePassword :050401 Signature Algorithm: sha256WithRSAEncryption 6f:2f:a4:2f:3c:1f:b0:79:10:6e:76:53:d3:11:8b:f8:18:46: 37:23:92:71:85:dc:40:07:9e:f0:5b:30:e6:9f:de:b1:46:e0: a1:94:f3:32:44:77:7a:5e:23:17:33:69:e7:bf:4d:86:08:d0: f2:3c:fe:99:c7:a0:bc:d2:b4:05:6c:db:f3:a9:af:76:f7:cc: 06:84:55:f6:8d:11:57:55:6f:d9:d7:3b:1d:9f:5b:17:93:60: 77:3d:ae:dd:5b:41:44:80:03:7e:b9:cf:82:6d:5d:87:00:b7: 6d:46:f0:22:17:1b:dc:7a:75:a6:f5:a3:12:86:19:36:ae:99: 74:34:f6:75:5d:ae:5b:63:4c:cc:f8:4c:37:42:af:d6:d3:30: ae:25:52:ee:57:ee:d1:7f:c0:91:3f:54:4d:64:3e:c5:a0:44: 93:9a:22:af:05:31:34:7c:6d:16:02:37:4f:99:7c:e7:01:f6: eb:68:ff:dc:96:37:4c:93:e0:9c:9f:db:50:f9:28:02:7d:ae: 5a:79:d5:cf:00:5c:60:b3:52:96:d4:b2:77:be:2e:97:e4:9b: e8:cf:40:61:00:13:4f:cf:7c:55:60:6a:8e:57:cd:bf:51:1f: 8c:3f:93:d5:66:f6:d7:3b:a9:56:2e:08:66:5e:3d:ad:c1:2c: 07:e2:95:f2 主要包含三部分： 第一部分：Subject 中是我填写的域名的基本信息，这里面，我们只需要关注 CN 字段就行：jinping。CN 是 Common Name 的缩写。 第二部分：Subject Public Key Info 是公钥部分，这里指定了服务器使用的加密算法是 RSA，公钥长度是 2048 位。 第三部分：签名，使用了 sha256WithRSAEncryption 算法。也就是说首先将上面的所有信息进行 sha256 散列得到 hash 值，然后使用 RSA 算法对 hash 值进行加密，而加密的秘钥就是之前生成的私钥。 为什么这里要加第三部分的签名？其实就是为了防止你的 CSR 文件在发给 CA 的过程中被中间人拦截，然后修改了里面的信息再发给 CA。CA 的校验过程是：利用里面的公钥将签名进行解密得到里面的散列值，然后 CA 也会利用 CSR 里面的信息计算一遍散列值，如果两者相等，那么说明证书没有被中间人修改过，反之就是被修改过 3.证书组成CA 收到我们的 CSR 文件以后，CA 会进行审核，前面说过了，审核这个域名是不是你的，如果需要，还有人工审核公司信息。审核通过后，它就会发给我们证书文件了，每家 CA 出来的文件名可能略有不同，但是表达的信息是一样的。 主要有以下几个文件： 域名证书：jinping.xyz.pem 或叫 cert.pem证书链：fullchain.pem这些文件可能是 .pem 也可能是 .crt 后缀，但都是文本文件，可以直接打开查看它们的信息： 域名证书的文件内容通常是这样的： 1234567-----BEGIN CERTIFICATE-----MIIFTzCCBDegAwIBAgISAy4b8ie6L/ACCJt/V7x/OR0iMA0GCSqGSIb3DQEBCwUAMEoxCzAJBgNVBAYTAlVTMRYwFAYDVQQKEw1MZXQncyBFbmNyeXB0MSMwIQYDVQQD......Ecbqh4AoB33mZhp9ptJb1N1RSlZREI0FlbX0kUd6VowKUPhH8Iex6jxQpJHwRkpqYJaWKrUxGWuJurOcN7b3HXn6yw==-----END CERTIFICATE----- 证书链文件通常是这样的：(证书链文件的第一部分，和证书文件的内容是一模一样的。) 1234567891011121314-----BEGIN CERTIFICATE-----MIIFTzCCBDegAwIBAgISAy4b8ie6L/ACCJt/V7x/OR0iMA0GCSqGSIb3DQEBCwUAMEoxCzAJBgNVBAYTAlVTMRYwFAYDVQQKEw1MZXQncyBFbmNyeXB0MSMwIQYDVQQD.......Ecbqh4AoB33mZhp9ptJb1N1RSlZREI0FlbX0kUd6VowKUPhH8Iex6jxQpJHwRkpqYJaWKrUxGWuJurOcN7b3HXn6yw==-----END CERTIFICATE----------BEGIN CERTIFICATE-----MIIEkjCCA3qgAwIBAgIQCgFBQgAAAVOFc2oLheynCDANBgkqhkiG9w0BAQsFADA/MSQwIgYDVQQKExtEaWdpdGFsIFNpZ25hdHVyZSBUcnVzdCBDby4xFzAVBgNVBAMT.......PfZ+G6Z6h7mjem0Y+iWlkYcV4PIWL1iwBi8saCbGS5jN2p8M+X+Q7UNKEkROb3N6KOqkqm57TH2H3eDJAkSnh6/DNFu0Qg==-----END CERTIFICATE----- 如果 CA 还给你发了 chain.pem 文件，其实它的内容肯定就是证书链文件内容裁减掉第一部分的证书内容而已。 我们需要的其实就是一个证书链。CA 给我们颁发的证书，其实就是一个证书链文件 4.文件内容decode后的结果： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465Certificate: Data: Version: 3 (0x2) Serial Number: 02:ac:5c:26:6a:0b:40:9b:8f:0b:79:f2:ae:46:25:77 Signature Algorithm: sha1WithRSAEncryption //证书颁发机构 Issuer: C = US, O = DigiCert Inc, OU = www.digicert.com, CN = DigiCert High Assurance EV Root CA //证书有效期 Validity Not Before: Nov 10 00:00:00 2006 GMT Not After : Nov 10 00:00:00 2031 GMT // 证书申请信息 Subject: C = US, O = DigiCert Inc, OU = www.digicert.com, CN = DigiCert High Assurance EV Root CA // 公钥 Subject Public Key Info: Public Key Algorithm: rsaEncryption Public-Key: (2048 bit) Modulus: 00:c6:cc:e5:73:e6:fb:d4:bb:e5:2d:2d:32:a6:df: e5:81:3f:c9:cd:25:49:b6:71:2a:c3:d5:94:34:67: a2:0a:1c:b0:5f:69:a6:40:b1:c4:b7:b2:8f:d0:98: a4:a9:41:59:3a:d3:dc:94:d6:3c:db:74:38:a4:4a: cc:4d:25:82:f7:4a:a5:53:12:38:ee:f3:49:6d:71: 91:7e:63:b6:ab:a6:5f:c3:a4:84:f8:4f:62:51:be: f8:c5:ec:db:38:92:e3:06:e5:08:91:0c:c4:28:41: 55:fb:cb:5a:89:15:7e:71:e8:35:bf:4d:72:09:3d: be:3a:38:50:5b:77:31:1b:8d:b3:c7:24:45:9a:a7: ac:6d:00:14:5a:04:b7:ba:13:eb:51:0a:98:41:41: 22:4e:65:61:87:81:41:50:a6:79:5c:89:de:19:4a: 57:d5:2e:e6:5d:1c:53:2c:7e:98:cd:1a:06:16:a4: 68:73:d0:34:04:13:5c:a1:71:d3:5a:7c:55:db:5e: 64:e1:37:87:30:56:04:e5:11:b4:29:80:12:f1:79: 39:88:a2:02:11:7c:27:66:b7:88:b7:78:f2:ca:0a: a8:38:ab:0a:64:c2:bf:66:5d:95:84:c1:a1:25:1e: 87:5d:1a:50:0b:20:12:cc:41:bb:6e:0b:51:38:b8: 4b:cb Exponent: 65537 (0x10001) // 这部分内容我们忽略 X509v3 extensions: X509v3 Key Usage: critical Digital Signature, Certificate Sign, CRL Sign X509v3 Basic Constraints: critical CA:TRUE X509v3 Subject Key Identifier: B1:3E:C3:69:03:F8:BF:47:01:D4:98:26:1A:08:02:EF:63:64:2B:C3 X509v3 Authority Key Identifier: keyid:B1:3E:C3:69:03:F8:BF:47:01:D4:98:26:1A:08:02:EF:63:64:2B:C3 // 签名 Signature Algorithm: sha1WithRSAEncryption 1c:1a:06:97:dc:d7:9c:9f:3c:88:66:06:08:57:21:db:21:47: f8:2a:67:aa:bf:18:32:76:40:10:57:c1:8a:f3:7a:d9:11:65: 8e:35:fa:9e:fc:45:b5:9e:d9:4c:31:4b:b8:91:e8:43:2c:8e: b3:78:ce:db:e3:53:79:71:d6:e5:21:94:01:da:55:87:9a:24: 64:f6:8a:66:cc:de:9c:37:cd:a8:34:b1:69:9b:23:c8:9e:78: 22:2b:70:43:e3:55:47:31:61:19:ef:58:c5:85:2f:4e:30:f6: a0:31:16:23:c8:e7:e2:65:16:33:cb:bf:1a:1b:a0:3d:f8:ca: 5e:8b:31:8b:60:08:89:2d:0c:06:5c:52:b7:c4:f9:0a:98:d1: 15:5f:9f:12:be:7c:36:63:38:bd:44:a4:7f:e4:26:2b:0a:c4: 97:69:0d:e9:8c:e2:c0:10:57:b8:c8:76:12:91:55:f2:48:69: d8:bc:2a:02:5b:0f:44:d4:20:31:db:f4:ba:70:26:5d:90:60: 9e:bc:4b:17:09:2f:b4:cb:1e:43:68:c9:07:27:c1:d2:5c:f7: ea:21:b9:68:12:9c:3c:9c:bf:9e:fc:80:5c:9b:63:cd:ec:47: aa:25:27:67:a0:37:f3:00:82:7d:54:d7:a9:f8:e9:2e:13:a3: 77:e8:1f:4a 证书中主要包含： 证书颁发机构：用于寻找链中的下一个验证节点 证书的有效期：比如浏览器要根据这个值来判断证书是否已过期 证书申请信息：比如浏览器要判断改证书是否可用于当前访问的域名 公钥：用于后续和服务端通信的秘钥，这个公钥和当初生成 CSR 时的公钥是一个东西，因为只有它是和服务器的私钥是一对的 签名：用于验证证书内容没有被篡改 这里简单说一说这个证书里面的公钥和签名： 前面在介绍生成 CSR 的时候，我们说过了，签名部分，是服务器使用私钥加密 hash 值得到的，同时在 CSR 中包含了公钥，这样 CA 在收到这个文件后，可以用 CSR 文件中的公钥来解密签名，进而做校验。而这里不一样，这个证书是 CA 给我们的，自然这个签名也是 CA 使用它自己的私钥进行加密的，但是这里的公钥是我们服务器的公钥，显然不能用于解密签名。那对于用户浏览器来说，在收到这个证书以后，怎么校验这个证书的签名呢？显然浏览器需要得到 CA 的公钥。下一节我们就将详细描述这个过程。 四.HTTPS验证过程下面将使用 jinping.xyz 这个域名的证书来分析。 首先，我们可以看到，这个证书链由 3 个证书组成。jinping.xyz 证书由中间证书 R3 签发，中间证书由 DST Root CA X3 签发，而 DST Root CA X3 是一个受信任的根证书。 流程如下： 用户访问 https://jinping.xyz，服务器返回 CA 给的证书链，其中包含了 jinping.xyz 证书以及中间证书； 浏览器首先需要判断 jinping.xyz 的证书是不是可信的，关键的一步就是要解密证书的签名部分。因为证书是由中间证书签发的，所以要用中间证书里面的公钥来进行解密； 第 2 步初步判断了 jinping.xyz 的证书是合法的，但是，这个是基于中间证书合法的基础上来的，所以接下来要判断中间证书是否是合法的； 根据中间证书里面的信息，可以知道它是由 DST Root CA X3 签发的，由于证书链只有两个节点，所以要到操作系统的根证书库中查找，由于这个证书是一个使用非常广泛的根证书，所以在系统中可以找到它。然后利用根证书的公钥来解密中间证书的签名部分，进而判断中间证书是否合法，如果合法，整个流程就通了 我们思考一下： 这个系统要工作好，关键就是最终一定要走到本地根证书库，一环验证一环，实现整个链路证书的可信任； 中间证书有多少层都可以，只要能一直传递到根证书就行； 本地的根证书是由操作系统内置的，如果你的使用场景中，根证书不在系统预装里面，需要手动导入根证书； 另外，我这里使用了操作系统内置这个说法，其实也不准确吧，各大浏览器厂商可以自己内置这个根证书库，这样我想信任谁就信任谁，而不是听 Microsoft、Apple… 这些操作系统厂商的。 脑洞大开一下，如果你想开一家 CA 公司，技术上是没什么成本的，但是你要说服各大操作系统、浏览器厂商，把你家的根证书内置到里面，这就有点难了。当然，还有另一条路可以走，那就是不要搞根证书，基于某个 CA 搞个中间证书，然后用这个中间证书去签发证书就可以了。","categories":[{"name":"计算机基础","slug":"计算机基础","permalink":"https://utinner.gitee.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"网络","slug":"网络","permalink":"https://utinner.gitee.io/tags/%E7%BD%91%E7%BB%9C/"},{"name":"http，ssl","slug":"http，ssl","permalink":"https://utinner.gitee.io/tags/http%EF%BC%8Cssl/"}]},{"title":"Java类加载机制","slug":"Java类加载机制","date":"2021-07-20T07:28:25.000Z","updated":"2021-12-06T09:23:00.732Z","comments":true,"path":"2021/07/20/Java类加载机制/","link":"","permalink":"https://utinner.gitee.io/2021/07/20/Java%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/","excerpt":"一.对象的创建当Java虚拟机遇到一条字节码new指令的时候，首先将去检查这个指令的参数是否能在常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否已被加载、解析和初始化过。如果没有，那必须先执行相应的类加载过程。","text":"一.对象的创建当Java虚拟机遇到一条字节码new指令的时候，首先将去检查这个指令的参数是否能在常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否已被加载、解析和初始化过。如果没有，那必须先执行相应的类加载过程。 二.类加载的时机一个类型从被加载到虚拟机内存中开始，到卸载出内存为止，它的整个生命周期将会经历加载（loading）、验证（Verfication）、准备（Preparation）、解析（Resolution）、初始化（Initialization）、使用（Using）、卸载（Unloading）七个阶段，其中验证、准备、解析三个部分统称为连接（Linking）。 加载、验证、准备、初始化和卸载这五个阶段的顺序是确定的，类型加载过程必须按照这种顺序按部就班地开始，而解析阶段则不一定：它在某些情况下可以在初始化阶段之后再开始，这是为了支持Java语言的运行时绑定特性（也称为动态绑定或晚期绑定）。这些阶段通常都是互相交叉地混合进行的，会在一个阶段执行的过程中调用、激活另一个阶段。 对于初始化阶段，有且只有六种情况必须立即对类进行“初始化”（而加载、验证、准备自然需要在此之前开始）： 遇到new、getstatic、putstatic或invokestatic这四条字节码指令时，如果类型没有进行过初始化，则需要先触发其初始化阶段。能够生成这四条指令的典型Java代码有： 使用new关键字实例化对象的时候 读取或设置一个类型的静态字段（被final修饰、已在编译期把结果放入常量池的静态字段除外）的时候 调用一个类型的静态方法的时候 使用java.lang.reflect包的方法对类型进行反射调用的时候，如果类型没有进行过初始化，则需要先触发其初始化 当初始化类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化 当虚拟机启动时，用户需要制定一个要执行的主类（包含main()方法的那个类），虚拟机会先初始化这个主类 当使用JDK7新加入的动态语言支持时，如果一个java.lang.invoke.MethodHandle实例最后的解析结果为REF_getStatic、REF_putStatic、REF_invokeStatic、REF_newInvokeSpecial四种类型的方法句柄，并且这个方法句柄对应的类没有进行过初始化，则需要先触发其初始化 当一个接口中定义JDK8新加入的默认方法（被default关键字修饰的接口方法）时，如果有这个接口的实现类发生了初始化，那该接口要在其之前被初始化 对于这六种会触发类型进行初始化的场景，这六种场景的行为称为对一个类型进行主动引用。除此之外，所有引用类型的方式都不会触发初始化，被称为被动引用。 接口与类的区别接口与类真正有所区别的是前面讲述的六种“有且仅有”需要触发初始化场景中的第三种：当一个类在初始化时，要求其父类全部都已经初始化过了，但是一个接口在初始化时，并不要求其父接口全部都完成了初始化，只有在真正使用到父接口（如引用接口中定义的常量）的时候才会初始化。 三.类加载的过程加载在加载阶段，Java虚拟机需要完成以下三件事情： 通过一个类的全限定名来获取定义此类的二进制字节流 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构 在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口 对于数组类而言，情况有所不同，数组类本身不通过类加载器创建，它是由Java虚拟机直接在内存中动态构造出来的。一个数组类（下面简称为C）创建过程中遵循以下规则： 如果数组的组件类型（Component Type，指的是数组去掉一个纬度的类型）是引用类型，那就递归采用默认的加载过程去加载这个组件类型，数组C将被标识在加载该组件类型的类加载器的类名称空间上（一个类型必须与类加载器一起确定唯一性）。 如果数组的组件类型不是引用类型，Java虚拟机将会把数组C标记为与引导类加载器关联。 数组类的可访问性与它的组件类型的可访问性一致，如果组件类型不是引用类型，它的数组类的可访问性将默认为public，可被所有的类和接口访问 加载阶段与连接阶段的部分动作（如一部分字节码文件格式验证动作）是交叉进行的，加载阶段尚未完成，连接阶段可能已经开始，但这些夹在加载阶段之中进行的动作，仍然属于连接阶段的一部分，这两个阶段的开始时间仍然保持着固定的先后顺序。 验证验证是连接阶段的第一步，这一阶段的目的是确保Class文件的字节流中包含的信息符合《Java虚拟机规范》的全部约束要求，保证这些信息被当作代码运行后不会危害虚拟机自身的安全。 验证阶段主要包括： 文件格式验证，验证字节流是否符合Class文件格式的规范，并且能被当前版本的虚拟机处理 元数据验证，对字节码描述的信息进行语义分析 字节码验证，通过数据流分析和控制流分析，确定程序语义是合法的、符合逻辑的。 符号引用验证，最后一个阶段的校验行为发生在虚拟机将符号引用转化为直接引用的时候，这个转化动作将在解析阶段中发生。 在生产环境的实施阶段可以考虑使用-Xverify:none参数来关闭大部分的类验证措施，以缩短虚拟机类加载的时间 准备准备阶段是正式为类中定义的变量（即静态变量，被static修饰的变量）分配内存并设置类变量初始值的阶段。 这个阶段仅对类变量，不包括实例变量，实例变量将会在对象实例化时随着对象一起分配在Java堆中。 初始值都是各种基础数据类型的默认值，而非程序员声明时的赋值。 解析解析阶段是Java虚拟机将常量池内的符号引用替换为直接引用的过程 类或接口的解析 字段解析 方法解析 初始化类的初始化阶段是类加载过程的最后一个步骤。 在准备阶段时，变量已经赋过一次系统要求的初始零值，而在初始化阶段，则会根据程序员通过程序编码制定的主观计划去初始化类变量和其他资源。 4.类加载器类与类加载器类加载器虽然只用于实现类的加载动作，但是它在Java程序中起到的作用却远超类加载阶段。对于任意一个类，都必须由加载它的类加载器和这个类本身一起共同确立其在Java虚拟机中的唯一性，每一个类加载器，都有一个唯一独立的类名称空间。比较两个类是否“相等”，只有在这两个类是由同一个类加载器加载的前提下才有意义，否则，即使这两个类来源于同一个Class文件，被同一个Java虚拟机加载，只要加载它们的类加载器不同，那么这两个类就必不相等。 双亲委派模型站在Java虚拟机的角度来看，只存在两种不同的类加载器： 启动类加载器（Bootstrap ClassLoader），这个类加载器使用C++语言实现，是虚拟机自身的一部分 其他所有的类加载器，这些类加载器都由Java语言实现，独立存在于虚拟机外部，并且全部继承于抽象类java.lang.ClassLoader 绝大多数的Java程序都会使用以下三个系统提供的类加载器来进行加载： 启动类加载器（Bootstrap ClassLoader）：这个类加载器负责加载存放在/lib目录，或者被-Xbootclasspath参数所指定的路径中存放的，而且是Java虚拟机能够识别的（按照文件名识别，如rt.jar、tools.jar，名字不符合的类库即使放在lib目录中也不会被加载）类库加载到虚拟机的内存中。启动类加载器无法被Java程序直接引用，用户在编写自定义类加载器时，如果需要把加载请求委派给引导类加载器去处理，那直接使用null替代即可。 扩展类加载器（Extension Class Loader）:这个类加载器是在类sun.misc.Launcher$ExtClassLoader中以Java代码的形式实现的。它负责加载/lib/ext目录中，或者被java.ext.dirs系统变量所指定的路径中所有的类库。这是一种Java系统类库的扩展机制。 应用程序类加载器（Application Class Loader）：这个类加载器由sun.misc.Launcher$AppClassLoader来实现。由于应用程序类加载器是ClassLoader类中的getSystemClassLoader()方法的返回值，所以有些场合中也称它为“系统类加载器”。它负责加载用户类路径（ClassPath）上所有的类库，开发者同样可以直接在代码中使用这个类加载器。 双亲委派模型要求除了顶层的启动类加载器外，其余的类加载器都应该有自己的父类加载器。不过这里类加载器之间的父子关系一般不是以继承的关系来实现的，而是通常使用组合关系来复用父加载器的代码。 双亲委派模型的工作过程如果一个类加载器收到了类加载器的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的类加载器都是如此，因此所有的加载请求最终都应该传送到最顶层的启动类加载器中，只有当父类加载器反馈自己无法完成这个加载请求时，子加载器才会尝试自己去完成加载。 精确到代码： 先检查请求加载的类型是否已被加载过，若没有则调用父加载器的loadClass()当法，若父加载器为空则默认使用启动类加载器作为父加载器。假如父加载器加载失败，抛出ClassNotFoundException异常的话，才调用自己的findClass()方法尝试进行加载。 双亲委派模型的好处一个显而易见的好处就是Java中的类随着它的类加载器一起具备了一种带有优先级的层次关系。例如类Object，被存放在rt.jar中，无论哪一个类加载器要加载这个类，最终都是委派给处于模型最顶端的启动类加载器进行加载，因此Object类在程序的各种类加载器环境中都能够保证是同一个类。 双亲委派模型对于保证Java程序的稳定运作极为重要。","categories":[{"name":"Java","slug":"Java","permalink":"https://utinner.gitee.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://utinner.gitee.io/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://utinner.gitee.io/tags/JVM/"}]},{"title":"HopSpot虚拟机对象","slug":"HopSpot虚拟机对象","date":"2021-07-20T07:22:01.000Z","updated":"2021-12-06T09:23:00.723Z","comments":true,"path":"2021/07/20/HopSpot虚拟机对象/","link":"","permalink":"https://utinner.gitee.io/2021/07/20/HopSpot%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%AF%B9%E8%B1%A1/","excerpt":"一.对象的创建虚拟机遇到new指令，先检查这个指令的参数是否能在常量池中定位到这个类的符号引用，并检查这个符号引用代表的类是否已经被加载、解析和初始化过。如果没有，那必须先执行相应的类加载过程。 1.分配内存类加载检查通过后，接下来虚拟机将为新生对象分配内存。对象所需内存的大小在类加载完成后便可以完全确定。","text":"一.对象的创建虚拟机遇到new指令，先检查这个指令的参数是否能在常量池中定位到这个类的符号引用，并检查这个符号引用代表的类是否已经被加载、解析和初始化过。如果没有，那必须先执行相应的类加载过程。 1.分配内存类加载检查通过后，接下来虚拟机将为新生对象分配内存。对象所需内存的大小在类加载完成后便可以完全确定。 2.内存分配方式 指针碰撞：如果Java堆中的内存规整，用过的内存放在一边，空闲的放在另外一边，中间放一个指针作为分界点的指示器。分配内存就是把指针向空闲空间挪动一段与对象大小相等的距离。 空闲列表：如果Java堆中的内存不规整，无法使用指针碰撞的方法，需要维护一个表，记录哪些内存块是可用的，在分配时从列表中找到一块足够大的内存块来划分给对象实例，然后更新列表记录。选择哪种分配方式由Java堆是否规整决定，而Java堆是否规整由所采用的垃圾收集器是否带有压缩整理功能决定。 3.并发问题创建对象是很频繁的行为，虚拟机采用如下两种方式来保证线程安全： CAS配上失败重试：CAS是乐观锁的一种实现方式。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。虚拟机采用 CAS 配上失败重试的方式保证更新操作的原子性。 TLAB： 将内存分配安排在每个线程独有的空间进行，每个线程首先在堆内存中分配一小块内存，称为本地分配缓存(TLAB : Thread Local Allocation Buffer)。分配内存时，只需要在自己的分配缓存中分配即可，由于这个内存区域是线程私有的，所以不会出现并发问题。当对象大于TLAB中的剩余内存或TLAB的内存已用尽时，再采用上述的CAS进行内存分配。虚拟机是否使用TLAB，可以通过-XX:+/-UseTLAB参数来设定。 4.初始化零值内存分配完成后，虚拟机将分配到的内存空间初始化为零值（不包括对象头），这一步保证了对象的实例字段在Java代码中可以不赋初始值就使用。 5.对象头设置初始化零值完成之后，虚拟机要对对象进行必要的设置，例如这个对象是那个类的实例、如何才能找到类的元数据信息、对象的哈希吗、对象的 GC 分代年龄等信息。 这些信息存放在对象头中。 另外，根据虚拟机当前运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。 6.执行init方法从虚拟机的视角来看，一个新的对象已经产生了，但从 Java 程序的视角来看，对象创建才刚开始，init 方法还没有执行，所有的字段都还为零。所以一般来说，执行 new 指令之后会接着执行 init 方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来。 二.对象的内存布局在 Hotspot 虚拟机中，对象在内存中的布局可以分为3块区域： 对象头 实例数据 对齐填充 Hotspot虚拟机的对象头包括两部分信息 第一部分用于存储对象自身的自身运行时数据（哈希码、GC分代年龄、锁状态标志等等） 另一部分是类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是那个类的实例。 实例数据部分是对象真正存储的有效信息，也是在程序中所定义的各种类型的字段内容。包括父类继承的内容和子类中定义的内容。 对齐填充部分不是必然存在的，也没有什么特别的含义，仅仅起占位作用。如果对象实例数据部分没有对齐的话，就需要通过对齐填充来补全。 三.对象的访问定位Java程序通过栈上的reference数据操作堆上的具体对象。主流的访问方式由使用句柄和直接指针两种。 句柄：如果使用句柄的话，那么Java堆中将会划分出一块内存来作为句柄池，reference 中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自的具体地址信息。 直接指针： 如果使用直接指针访问，那么 Java 堆对象的布局中就必须考虑如何放置访问类型数据的相关信息，而reference 中存储的直接就是对象的地址。 这两种对象访问方式各有优势： 使用句柄来访问的最大好处是 reference 中存储的是稳定的句柄地址，在对象被移动时只会改变句柄中的实例数据指针，而 reference 本身不需要修改 使用直接指针访问方式最大的好处就是速度快，它节省了一次指针定位的时间开销。（大部分是使用第二种方法来访问的） HotSpot使用直接指针的方式进行对象访问。","categories":[{"name":"Java","slug":"Java","permalink":"https://utinner.gitee.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://utinner.gitee.io/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://utinner.gitee.io/tags/JVM/"}]},{"title":"Java内存区域","slug":"Java内存区域","date":"2021-07-19T07:43:18.000Z","updated":"2021-12-06T09:23:00.723Z","comments":true,"path":"2021/07/19/Java内存区域/","link":"","permalink":"https://utinner.gitee.io/2021/07/19/Java%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F/","excerpt":"Java虚拟机在执行Java程序的过程中会把它管理的内存分为若干个不同的数据区域。这些区域有着各自的用途，一级创建和销毁的时间，有的区域随着虚拟机进程的启动而存在，有些区域则依赖用户线程的启动和结束而建立和销毁。根据《Java虚拟机规范》中规定，jvm所管理的内存大致包括以下几个运行时数据区域，如图所示：","text":"Java虚拟机在执行Java程序的过程中会把它管理的内存分为若干个不同的数据区域。这些区域有着各自的用途，一级创建和销毁的时间，有的区域随着虚拟机进程的启动而存在，有些区域则依赖用户线程的启动和结束而建立和销毁。根据《Java虚拟机规范》中规定，jvm所管理的内存大致包括以下几个运行时数据区域，如图所示： 一.线程私有的1.程序计数器占据一块较小的内存空间，可以看做当前线程所执行的字节码的行号指示器。在虚拟机概念模型里，字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支，循环，跳转，异常处理，线程恢复等基础功能都需要依赖这个计数器来完成。 由于jvm的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，在任何一个确定的时刻，一个处理器都只会执行一条线程中的指令。因此未来线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各条线程之间计数器互不影响，独立存储，我们成这类内存区域为“线程私有”的内存。 如果线程正在执行的是一个Java方法，这个计数器记录的则是正在执行的虚拟机字节码指令的地址； 如果正在执行的是Native方法，这个计数器则为空（undefined）。 此内存区域是唯一一个在Java虚拟机规范中没有规定任何OutOfMemoryError情况的区域。 2.Java虚拟机栈线程私有，生命周期和线程相同，虚拟机栈描述的是Java方法执行的内存模型，每个方法在执行的同时都会创建一个栈帧 用于存储局部变量表，操作数栈，动态链接，方法出口等信息。每一个方法从调用直至完成的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程。 局部变量表存放了编译期可知的各种基本类型数据（boolean、byte、char、short、int、float、long、double）、对象引用、returnAddress类型（指向了一条字节码指令的地址）。 其中64位长度的long和double类型的数据会占用2个局部变量表空间（slot），其余的数据类型只占用1个。局部变量表所需的内存空间在编译期完成分配，当进入一个方法时，这个方法所需要在栈帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。(大小指的是变量槽的数量) 在Java虚拟机规范中，对此区域规定了两种异常状况： 如果线程请求的栈深度大于虚拟机所允许的深度，将会抛出Stack OverflowError异常； 如果虚拟机栈可以动态扩展时无法申请到足够的内存，就会抛出OutOfMemoryError异常。 3.本地方法栈本地方法栈与虚拟机栈所发挥的作用非常相似，他们之间的区别不过是虚拟机栈为虚拟机执行Java方法（字节码）服务，而本地方法栈则为虚拟机中使用到的native方法服务。在虚拟机规范中对本地方法栈中方法使用的语言、使用方式与数据结构并没有强制规定，因此具体的虚拟机可以自由实现它。甚至有的虚拟机直接把本地方法栈和虚拟机栈合二为一， 与虚拟机栈一样也会抛出Stack OverflowError异常和OutOfMemoryError异常。 二.线程共享的1.Java堆对于大多数应用来说，堆空间是jvm内存中最大的一块。Java堆是被所有线程共享，虚拟机启动时创建，此内存区域唯一的目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。这一点在Java虚拟机规范中的描述是：所有的对象实例以及数组都要在堆上分配，但是随着JIT编译器的发展和逃逸分析技术逐渐成熟，栈上分配，标量替换优化技术将会导致一些微妙的变化发生，所有的对象都分配在堆上也就变得不那么绝对了。 Java堆是垃圾收集器管理的主要区域，因此很多时候也被称为“GC堆”。从内存回收角度看，由于现在收集器基本都采用分代收集算法，所以Java堆还可以细分为：新生代和老年代；再细致一点的有Eden空间，From Survivor空间，To Survivor空间等。从内存分配的角度来看，线程共享的Java堆中可能划分出多个线程私有的分配缓冲区。不过无论如何划分，都与存放内容无关，无论哪个区域，存储的都仍然是对象实例，进一步划分的目的是为了更好的回收内存，或者更快的分配内存。（如果在堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出OutOfMemoryError异常。） 2.方法区（永久代）和堆一样所有线程共享，主要用于存储已被jvm加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。也叫“非堆”。 （在JDK1.7发布的HotSpot中，已经把字符串常量池移除方法区了。） 这个区域的内存回收目标主要是针对常量池的回收和对类型的卸载。 如果方法区无法满足新的内存分配需求时，将抛出OutOfMemoryError异常。 3.常量池运行时常量池是方法区的一部分。Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息是常量池，用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后进入方法区的运行时常量池中存放。 Java虚拟机对class文件每一部分的格式都有严格规定，每一个字节用于存储哪种数据都必须符合规范才会被jvm认可。但对于运行时常量池，Java虚拟机规范没做任何细节要求。 运行时常量池有个重要特性是动态性，Java语言不要求常量一定只在编译期才能产生，也就是并非预置入class文件中常量池的内容才能进入方法区的运行时常量池，运行期间也有可能将新的常量放入池中，这种特性使用最多的是String类的intern()方法。 既然运行时常量池是方法区的一部分，自然受到方法区内存的限制。当常量池无法再申请到内存时会抛出outOfMemeryError异常。 4.直接内存直接内存并不是虚拟机运行时数据区的一部分。但是这部分也被经常访问，而且也可能导致OOM异常。 在jdk1.4中新加入了NIO类，引入了一种基于通道（Channel）与缓冲区（Buffer）的I/O方式，它可以使用Native函数直接分配堆外内存，然后通过一个存储在Java堆里面的DirectByteBuffer对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了在Java堆和Native堆中来回复制数据。","categories":[{"name":"Java","slug":"Java","permalink":"https://utinner.gitee.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://utinner.gitee.io/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://utinner.gitee.io/tags/JVM/"}]},{"title":"Java内存模型与线程","slug":"Java内存模型与线程","date":"2021-04-04T10:00:46.000Z","updated":"2021-12-06T09:23:00.725Z","comments":true,"path":"2021/04/04/Java内存模型与线程/","link":"","permalink":"https://utinner.gitee.io/2021/04/04/Java%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/","excerpt":"一、物理机中的效率与一致性1. 高速缓存（Cache）的引入“让计算机并发执行若干个运算任务”与“更充分地利用计算机处理器的性能”之间的因果关系，看起来利索当然，实际上他们之间的关系并没有想象中那么简单，其中一个重要的复杂性的来源是绝大多数的运算任务都不可能只靠处理器“计算”就能完成。 处理器只要要与内存交互，如读取运算数据、存储计算结果等，这个IO操作就是很难消除的（无法仅靠寄存器来完成所有运算任务）。 由于计算机的存储设备与处理器的运算速度有着几个数量级的差距，所以现代计算机系统都不得不加入一层或多层读写速度尽可能接近处理器运算速度的高速缓存（Cache）来作为内存与处理器之间的缓冲： 将运算需要使用的数据复制到内存中，让运算能快速进行，当运算结束后再从缓存同步到内存之中，这样就无需等待缓慢的内存读写了。","text":"一、物理机中的效率与一致性1. 高速缓存（Cache）的引入“让计算机并发执行若干个运算任务”与“更充分地利用计算机处理器的性能”之间的因果关系，看起来利索当然，实际上他们之间的关系并没有想象中那么简单，其中一个重要的复杂性的来源是绝大多数的运算任务都不可能只靠处理器“计算”就能完成。 处理器只要要与内存交互，如读取运算数据、存储计算结果等，这个IO操作就是很难消除的（无法仅靠寄存器来完成所有运算任务）。 由于计算机的存储设备与处理器的运算速度有着几个数量级的差距，所以现代计算机系统都不得不加入一层或多层读写速度尽可能接近处理器运算速度的高速缓存（Cache）来作为内存与处理器之间的缓冲： 将运算需要使用的数据复制到内存中，让运算能快速进行，当运算结束后再从缓存同步到内存之中，这样就无需等待缓慢的内存读写了。 2. 缓存一致性问题在多路处理器系统中，每个处理器都有自己的高速缓存，而他们又共享同一主内存（Main Memory），这种系统称为共享内存多核系统。当多个处理器的运算任务都涉及同一块主内存区域时，将可能导致各自的缓存数据不一致。 为了解决缓存数据一致性的问题，需要各个处理器访问缓存时都遵循一些协议，在读写时要根据协议来操作。比如：MSI、MESI、MOSI等。 3.乱序执行优化除了增加高速缓存之外，为了使处理器内部的运算单元能尽量被充分利用，处理器可能会对输入代码进行乱序执行（Out-Of-Order Execution）优化，处理器会在计算之后将乱序执行的结果重组，保证该结果与顺序执行的结果是一致的，但并不保证程序中各个语句计算的先后顺序与输入代码中的顺序一致。 与处理器的乱序执行优化类似，Java虚拟机的即使编译器中也有指令重排序优化。 二、Java内存模型1.主内存与工作内存","categories":[{"name":"Java","slug":"Java","permalink":"https://utinner.gitee.io/categories/Java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://utinner.gitee.io/tags/JVM/"},{"name":"多线程","slug":"多线程","permalink":"https://utinner.gitee.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"内存模型","slug":"内存模型","permalink":"https://utinner.gitee.io/tags/%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/"}]},{"title":"Docker(六)DockerCompose","slug":"Docker-六-DockerCompose","date":"2021-02-15T11:05:39.000Z","updated":"2021-12-06T09:23:00.680Z","comments":true,"path":"2021/02/15/Docker-六-DockerCompose/","link":"","permalink":"https://utinner.gitee.io/2021/02/15/Docker-%E5%85%AD-DockerCompose/","excerpt":"前言：构建一个wordpress1.创建MySQL的container1docker run -d --name mysql -v mysql-data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=root -e MYSQL_DATABASE=wordpress mysql 声明了我的root用户密码为root，同时创建了一个wordpress的数据库，因为我的mysql是在内部使用的不用对提供服务他们使用的是同一个网络，所以不用做端口映射 2.创建wordpress1docker run -d -e WORDPRESS_DB_HOST=mysql:3306 --link mysql -p 8080:80 wordpress -e 需要去指定我们的数据库的host，指定我刚刚启动的mysql的容器， –link 就是link到我们的mysql里面 -p就是将容器中的80端口映射到我们本地的8080端口 这个过程就比较复杂，像有些应用有好多个模块我们可能就需要构建好多个container，对它的创建、管理、启动、停止等操作比较繁琐。我们希望可以将多个容器定义成一个组，对这个组进行统一的管理，于是DockerCompose就出现了，DockerCompose就是为了解决这一问题而诞生的。","text":"前言：构建一个wordpress1.创建MySQL的container1docker run -d --name mysql -v mysql-data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=root -e MYSQL_DATABASE=wordpress mysql 声明了我的root用户密码为root，同时创建了一个wordpress的数据库，因为我的mysql是在内部使用的不用对提供服务他们使用的是同一个网络，所以不用做端口映射 2.创建wordpress1docker run -d -e WORDPRESS_DB_HOST=mysql:3306 --link mysql -p 8080:80 wordpress -e 需要去指定我们的数据库的host，指定我刚刚启动的mysql的容器， –link 就是link到我们的mysql里面 -p就是将容器中的80端口映射到我们本地的8080端口 这个过程就比较复杂，像有些应用有好多个模块我们可能就需要构建好多个container，对它的创建、管理、启动、停止等操作比较繁琐。我们希望可以将多个容器定义成一个组，对这个组进行统一的管理，于是DockerCompose就出现了，DockerCompose就是为了解决这一问题而诞生的。 DockerCompose DockerCompose建议用于本地开发去部署 DockerCompose是一个工具 这个工具可以通过一个yml文件定义多容器的docker应用 通过一条命令就可以根据yml文件的定义去创建或管理这多个容器 现在有三个版本，推荐使用version3，不同的版本文件格式是不一样的，2跟3的区别不是很大，但是2跟3最大的区别就是version2只能用于单机，version3可以用于多机 service一个service代表一个container，这个container可以从dockerhub的image来创建，或者从本地的Dockerfilebuild出来的image来创建 service的启动类似docker run，我们可以给其指定network和volume，所以可以给service指定network和volume的引用 示例123456789101112131415161718192021222324252627282930version: &#x27;3&#x27;services: wordpress: image: wordpress ports: - 8080:80 environment: WORDPRESS_DB_HOST: mysql WORDPRESS_DB_PASSWORD: root networks: - my-bridge mysql: image: mysql environment: MYSQL_ROOT_PASSWORD: root MYSQL_DATABASE: wordpress volumes: - mysql-data:/var/lib/mysql networks: - my-bridgevolumes: mysql-data:networks: my-bridge: driver: bridge 解释 第一行声明version的版本是3 在service中定义了两个服务，一个WordPress，一个mysql image属性定义了我们的image port做了端口映射 environment声明了两个环境变量 networks指定了我们连接的网络是下面自定义的bridge， 在mysql服务中我引用了自定义mysql-data的volume Dockercompose的安装如果使用mac或者windows系统，在安装完docker会默认安装上DockerCompose，但是如果是linux系统就需要独立安装 下载dockercompose的可执行文件然到/usr/local/bin/docker-compose目录下面，命名为docker-compose 1sudo curl -L &quot;https://github.com/docker/compose/releases/download/1.28.2/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-compose 下载完之后给它一个可执行的权限 1sudo chmod +x /usr/local/bin/docker-compose 下载完成之后就可以根据默认docker-compose命名的yml文件去进行构建了 1docker-compose up 如果文件不是按照docker-compose.yml命名的，也可以指定yml文件的名称 1docker-compose &lt;yml文件名&gt; up 查看服务ps，可以看到有两个服务在运行中 停止服务： 1docker-compose stop 也可以进行start启动服务 1docker-compose start 如果用down命令，则不仅会停止服务，而且会删除里面的所有container 当我们启动的时候，也可以指定参数-d让其后台启动，不会输出大量的log 1docker-compose up -d 列举我们compose所定义的image 1docker-compose images 先build再up，docker-compose build命令可以预先根据dockerfile进行构建，并不会启动，但docker-compose up会在启动之前先构建，构建完成再启动 1docker-compose build 进入container的bash中 1docker-compose exec mysql bash 扩展我们根据docker-compose所创建出来的服务只有一个，我们可以通过scale去进行扩展，比我们可以通过scale可以将对应的服务从一个扩展成三个。 1docker-compose up --help 对应的命令为：（web应用就是通过redis统计pv访问量的） 1docker-compose up --scale web=3 -d 当我们访问的时候，会进行轮询，内部是通过lb进行负载均衡的，有兴趣的可以看看HAProxyscale不仅可以支持扩容，还支持缩容， 我们可以控制scale的数量对其进行控制服务实例的数量。","categories":[{"name":"运维","slug":"运维","permalink":"https://utinner.gitee.io/categories/%E8%BF%90%E7%BB%B4/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://utinner.gitee.io/tags/Docker/"}]},{"title":"Docker(五)-Docker的文件存储和数据共享","slug":"Docker-五-Docker的文件存储和数据共享","date":"2021-02-11T19:59:13.000Z","updated":"2021-12-06T09:23:00.674Z","comments":true,"path":"2021/02/12/Docker-五-Docker的文件存储和数据共享/","link":"","permalink":"https://utinner.gitee.io/2021/02/12/Docker-%E4%BA%94-Docker%E7%9A%84%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E5%92%8C%E6%95%B0%E6%8D%AE%E5%85%B1%E4%BA%AB/","excerpt":"问题 当我创建了一个容器，在这个容器中我有个mysql服务，在这个mysql里面我有各种各样的数据。但是有一天我一不小心删除了这个容器，那么这个容器中的相关服务以及数据也都没有了。这个时候就出问题了。 我们需要一种数据持久化机制来实现我们容器中数据的存储。 默认情况下docker数据是写在了container里面的，当我们将容器删除掉之后是找不到这个容器里面的文件及恢复的，那么我们可以用一种机制类似于mock的方式去将容器中的数据保存在我们的磁盘上，这样就跟容器隔离开了，进而实现数据持久化。","text":"问题 当我创建了一个容器，在这个容器中我有个mysql服务，在这个mysql里面我有各种各样的数据。但是有一天我一不小心删除了这个容器，那么这个容器中的相关服务以及数据也都没有了。这个时候就出问题了。 我们需要一种数据持久化机制来实现我们容器中数据的存储。 默认情况下docker数据是写在了container里面的，当我们将容器删除掉之后是找不到这个容器里面的文件及恢复的，那么我们可以用一种机制类似于mock的方式去将容器中的数据保存在我们的磁盘上，这样就跟容器隔离开了，进而实现数据持久化。 Docker持久化数据的两种方案 基于本地文件系统的Volume。可以在执行Docker create或Docker run时，通过-v参数将主机的目录作为容器的数据卷。这部分功能便是基于本地文件系统的volume管理。 基于plugin的Volume，支持第三方的存储方案，比如NAS、aws Volume的类型 受管理的data Volome，由docker后台自动创建 绑定挂载的Volome，具体挂载的位置可以由用户指定 小插曲我需要从我本地拷贝几份文件到vagrant的虚拟机中，需要安装vagrant的scp插件vagrant plugin install scp。 将本地文件拷贝到虚拟机指定目录中1vagrant scp &lt;目标文件夹路径&gt; vmName:&lt;虚拟机内文件夹路径&gt; 注意：&lt;虚拟机内文件夹路径&gt;需要预先开通777权限1sudo chmod 777 &lt;虚拟机内文件夹路径&gt; Data Volume1.进入虚拟机，查看volume： 2.创建一个不需要密码登录的mysql应用 1sudo docker run -d --name mysql1 -e MYSQL_ALLOW_EMPTY_PASSWORD=true mysql 3.查看volume相关信息 可以看到它这个volume映射到了虚拟机内部的路径上去 4.再去创建另一个mysql 1sudo docker run -d --name mysql2 -e MYSQL_ALLOW_EMPTY_PASSWORD=true mysql 再去查看volume可以看到多了一个 5.现在我去停止并且remove掉两个容器 1docker rm -f mysql1 mysql2 可以发现但是他们的volume还在 但是又有第二个问题，我们的volume的名字并不是特别友好， 我可以给volume起个别名 6.删除这两个volume 1docker volume rm &lt;id&gt; 7.重新创建，指定别名为mysql 1sudo docker run -d -v mysql:/var/lib/mysql --name mysql1 -e MYSQL_ALLOW_EMPTY_PASSWORD=true mysql 可以看到有一个mysql的volume 我们的数据都会同步到这个volume里面去 验证 进入到mysql1中 1234sudo docker exec -it mysql1 /bin/bashmysql -u rootcreate database docker;show databases; 然后退出容器 强制删除mysql1 创建mysql3，使用这个volume 1sudo docker run -d -v mysql:/var/lib/mysql --name mysql3 -e MYSQL_ALLOW_EMPTY_PASSWORD=true mysql 进入容器，可以看到mysql3中有docker这个数据库 bind Mounting做地址映射只需要在运行容器的时候去指定我们本地的目录和容器的目录的一一对应关系，通过这种方式可以去同步，让我们本地的目录文件和容器的目录文件是同步的。本质是同一个文件同一个目录做映射。 我这里有个脚本文件Dockerfile 123456789101112# this same shows how we can extend/change an existing official image from Docker HubFROM nginx:latest# highly recommend you always pin versions for anything beyond dev/learnWORKDIR /usr/share/nginx/html# change working directory to root of nginx webhost# using WORKDIR is prefered to using &#x27;RUN cd /some/path&#x27;COPY index.html index.html# I don&#x27;t have to specify EXPOSE or CMD because they&#x27;re in my FROM 其实就是创建一个nginx服务，然后将我自定义的index.html覆盖到nginx中构建： 1docker build -t tinner/mynginx . 做端口映射： 1docker run -d -p 80:80 --name web tinner/mynginx 然后curl 127.0.0.1可以看到首页就是我写的index.html 12345678910111213&lt;!doctype html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;title&gt;hello&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;Hello Docker! &lt;/h1&gt;&lt;/body&gt;&lt;/html&gt; 在本地输入(我的虚拟机ip)：http://192.168.205.10/，同样也能看到自定义页面 然后删除这个容器 1docker rm -f web 用bind Mounting进行映射1docker run -d -v $(pwd):/usr/share/nginx/html -p 80:80 --name web tinner/mynginx 主要是-v参数，$(pwd)就是我当前虚拟机的目录，冒号后面就是我创建出来的容器的指定目录要与$(pwd)目录进行映射。 然后进入容器 12docker exec -it web /bin/bashtouch docker.txt 退出容器，可以看到在虚拟机内部也生成了一个docker.txt文件，同时在我本地也有一份 这是因为我在构建vagrant的时候指定了 12345678910111213141516171819202122232425262728293031Vagrant.require_version &quot;&gt;= 1.6.0&quot;boxes = [ &#123; :name =&gt; &quot;docker-host&quot;, :eth1 =&gt; &quot;192.168.205.31&quot;, :mem =&gt; &quot;1024&quot;, :cpu =&gt; &quot;1&quot; &#125;]Vagrant.configure(2) do |config| config.vm.box = &quot;centos/7&quot; boxes.each do |opts| config.vm.define opts[:name] do |config| config.vm.hostname = opts[:name] config.vm.provider &quot;vmware_fusion&quot; do |v| v.vmx[&quot;memsize&quot;] = opts[:mem] v.vmx[&quot;numvcpus&quot;] = opts[:cpu] end config.vm.provider &quot;virtualbox&quot; do |v| v.customize [&quot;modifyvm&quot;, :id, &quot;--memory&quot;, opts[:mem]] v.customize [&quot;modifyvm&quot;, :id, &quot;--cpus&quot;, opts[:cpu]] end config.vm.network :private_network, ip: opts[:eth1] end end config.vm.synced_folder &quot;./labs&quot;, &quot;/home/vagrant/labs&quot; config.vm.provision &quot;shell&quot;, privileged: true, path: &quot;./setup.sh&quot;end 在倒数第三行，进行了文件的映射，将本地的labs文件夹映射到了我构建出来的虚拟机的”/home/vagrant/labs”目录下，同时，在虚拟机中构建nginx容器的时候，也指定了文件映射，这三处地方实现了映射，进而实现了数据的存储 1config.vm.synced_folder &quot;./labs&quot;, &quot;/home/vagrant/labs&quot; 同时，用这种方式可以实现在我们开发过程中同步查看一些改动","categories":[{"name":"运维","slug":"运维","permalink":"https://utinner.gitee.io/categories/%E8%BF%90%E7%BB%B4/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://utinner.gitee.io/tags/Docker/"}]},{"title":"Docker(四)Docker的网络空间","slug":"Docker-四-Docker的网络空间","date":"2021-01-16T17:43:20.000Z","updated":"2021-12-06T09:23:00.690Z","comments":true,"path":"2021/01/17/Docker-四-Docker的网络空间/","link":"","permalink":"https://utinner.gitee.io/2021/01/17/Docker-%E5%9B%9B-Docker%E7%9A%84%E7%BD%91%E7%BB%9C%E7%A9%BA%E9%97%B4/","excerpt":"在一台linux机器上，不管创建多少个docker容器，他们都有属于自己的ip地址，并且可以相互ping通访问。 为什么会ping通？其中的原理是什么？","text":"在一台linux机器上，不管创建多少个docker容器，他们都有属于自己的ip地址，并且可以相互ping通访问。 为什么会ping通？其中的原理是什么？ 预备工作 创建一个基于busybox的容器1sudo docker run -d --name test1 busybox /bin/sh -c &quot;while true; do sleep 3600; done&quot; 输入ip -a 命令即可查看当前容器下的网络ip地址和命名空间 通过实现linux的network namespace实现两个namespace相通 创建两个network namespace123sudo ip netns add test1sudo ip netns add test2sudo ip link add veth-test1 type veth peer name veth-test2 linux下查看network namespace1ip link 可以看到多了两个命名空间，但是只有mac地址，没有ip地址，而且他们现在的状态都是down的 将veth-test1接口添加到test1上去，同时将veth-test2接口添加到test2上去1sudo ip link set veth-test1 netns test1 然后可以看到本地的network namespace少了一个同时在test1的命名空间里，多了一个 test2同理1sudo ip link set veth-test2 netns test2 此时两者的状态还是没有ip地址，只有mac地址 分配ip地址12sudo ip netns exec test1 ip addr add 192.168.1.1/24 dev veth-test1sudo ip netns exec test2 ip addr add 192.168.1.2/24 dev veth-test2 将两个veth-test端口启动12sudo ip netns exec test1 ip link set dev veth-test1 upsudo ip netns exec test2 ip link set dev veth-test2 up 查看两个namespace的ip及状态 可以看到都有了ip地址，状态都为up。 可以看到test1能够ping通test2的ip地址 这个实验与docker的container网络实现的原理类似。我们创建一个容器，随之也会创建属于这个容器的network namespace Docker的网络实现我现在有一个容器，基于busybox的一个微型image构建的容器 查看docker的network 查看docker的network的详细信息 1docker network inspect a11a8b74c466(network的id) 在输出的信息里面会看到关于test1的相关信息 我们可以知道test1的container连接到了bridge的网络上面。 查看本机的ip信息 再来查看test1的container的ip相关信息 给结论：test1的eth0@if6与本机的veth821ee0b@if5相对应，container最终要映射到本机的docker0的network namespace上去 验证安装bridge-utils1sudo yum install bridge-utils 运行命令：brctl show 可以看到我们的veth821ee0b接口连接到了docker0的namespace上 现在我们再创建一个容器：1sudo docker run -d --name test2 busybox /bin/sh -c &quot;while true; do sleep 3600; done&quot; 再次查看网络信息，可以看到多了一个接口 然后看到bridge可以对应到两个container 再来运行命令：brctl show 可以看到我们的veth821ee0b接口以及vethbbbd3b9都连接到了docker0的namespace上 实现原理的拓扑图 两个容器分别是两个不同的network namespace，两者通过docker0进行连接。 单个容器如何访问外网？通过本机的docker0的network namespace 容器之间的link在实际项目中我们不能总是依赖于ip地址，如果容器之间需要相互访问还可以通过另外一种方式:link 1sudo docker run -d --name test2 --link test1 busybox /bin/sh -c &quot;while true; do sleep 3600; done&quot; 在我们创建容器的时候加参数：--link [容器名]即可在我们的容器中不仅可以通过ip地址访问我们想要访问的ip，还可以通过容器名访问我们在容器创建的时候就已经指定了对应的容器了。反过来，在test1里面，如果想访问test2的话是不行的，link是单向的，不是双向的link用的其实并不多。 让容器不连接bridge，连接自定义的network namespace重新构建test2容器 新建network1sudo docker network create -d bridge my-bridge 可以看到多了一个my-bridge 新建容器指定连接我自定义的network1sudo docker run -d --name test3 --network my-bridge busybox /bin/sh -c &quot;while true; do sleep 3600; done&quot; 可以看到有了interface，在创建test3之前是没有interface的 修改test1和test2连接的network1sudo docker network connect my-bridge test2 查看my-bridge的信息查看bridge的信息可以看到test2既连接到了bridge上，又连接到了my-bridge上 在test2上既可以通过ip地址访问test3，又可以通过test3的名称访问test3，这是因为在用户自定义的bridge上的所有容器之间都是默认加了link去进行相互之间的访问的，而且是双向的。这就是系统默认的bridge和用户自定义bridge的区别，在系统默认的bridge上的container默认是不支持link连接的。 容器的端口映射创建一个nginx容器1sudo docker run --name web -d nginx 查看ngingx的ip地址1sudo docker network inspect bridge 为172.17.0.4 访问nginx 可以访问到 如何让我的docker-node1对外提供nginx服务呢？就是端口映射 停止并删除web（nginx）容器12sudo docker stop websudo docker rm web 重新构建，但是要加参数1sudo docker run --name web -d -p 80:80 nginx 由于我在构建的时候指定了我的docker-node1的ip地址为192.168.205.10，所以在我本地的浏览器中访问http://192.168.205.10/，即可 none network新建一个连接到none的network的容器1sudo docker run -d --name none-test --network none busybox /bin/sh -c &quot;while true;do sleep 3600;done&quot; 查看none的状态1sudo docker network inspect none 可以看到没有任何的mac的地址和IP地址 进入容器12sudo docker exec -it none-test /bin/ship a 没有任何接口和地址 它的作用？可能是在存储一些密码等敏感信息的时候出于安全性考虑只有在容器内部才能进行访问的时候才用这种模式（只是猜测）。对外提供不了服务 host方式新建一个连接到none的network的容器1sudo docker run -d --name host-test --network host busybox /bin/sh -c &quot;while true;do sleep 3600;done&quot; 查看none的状态1sudo docker network inspect host 同样，也没有任何ip地址和mac地址 进入容器12sudo docker exec -it none-test /bin/ship a 可以看到与容器的ip状态是一致的 这个容器没有自己的独立的network namespace，它是与我的主机所在的network namespace共享一套。 通过这种方式构建的容器带来的问题：由于是与容器主机共享的network namespace，意味着端口可能会冲突。比如创建两个nginx的container，都绑定到host的network上去，就会出问题 构建复杂app创建一个redis容器1docker run -d --name redis redis 为什么没有指定端口映射？ 是因为我这个redis不是对外提供服务的，而是在我的容器内部进行访问的，没必要暴露到外面 启动服务1sudo docker run -d --link redis -p 5000:5000 --name fast-redis -e REDIS_HOST=redis jinping/flask-redis 进入服务，可以看到环境变量12docker exec -it fast-redis /bin/shenv -e 是设置环境变量的 在我们当前容器的内部，是能够ping通redis的 所以当我们执行curl 127.0.0.1:5000时，可以输出相应的pv 当我回到我的vagrant时,由于在容器中指定了端口映射，所以一样可以输出pv 推荐：一个模块一个容器，只要搞清楚他们之间的部署关系就可以了 处于不同的linux机器间的docker通信 VXLAN的方式分布式存储：etcdhttps://github.com/docker/labs/blob/master/networking/concepts/06-overlay-networks.md","categories":[{"name":"运维","slug":"运维","permalink":"https://utinner.gitee.io/categories/%E8%BF%90%E7%BB%B4/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://utinner.gitee.io/tags/Docker/"}]},{"title":"Java中的hashcode和equals","slug":"Java中的hashcode和equals","date":"2020-12-23T16:18:34.000Z","updated":"2021-12-06T09:23:00.723Z","comments":true,"path":"2020/12/24/Java中的hashcode和equals/","link":"","permalink":"https://utinner.gitee.io/2020/12/24/Java%E4%B8%AD%E7%9A%84hashcode%E5%92%8Cequals/","excerpt":"关于hashcode1、hashcode的存在主要是用于查找的快捷性，如Hashtable、HashMap等，hashcode是用来在散列存储结构中确定对象的存储地址的。 2、如果两个对象相同，就是适用于equals(java.lang.Object)方法，那么这两个对象的hashcode方法一定要相同。 3、如果对象的equals方法被重写，那么对象的hashcode方法也尽量重写，并且产生hashcode使用的对象，一定要和equals方法中使用的一致，否则就会违反上面提到的第2点。 4、两个对象的hashcode相同，并不一定表示两个对象就相同，也就是不一定适用于equals(java.lang.Object)方法，只能够说明这两个对象在散列存储结构中，如Hashtable，他们“存放在一个篮子中”。","text":"关于hashcode1、hashcode的存在主要是用于查找的快捷性，如Hashtable、HashMap等，hashcode是用来在散列存储结构中确定对象的存储地址的。 2、如果两个对象相同，就是适用于equals(java.lang.Object)方法，那么这两个对象的hashcode方法一定要相同。 3、如果对象的equals方法被重写，那么对象的hashcode方法也尽量重写，并且产生hashcode使用的对象，一定要和equals方法中使用的一致，否则就会违反上面提到的第2点。 4、两个对象的hashcode相同，并不一定表示两个对象就相同，也就是不一定适用于equals(java.lang.Object)方法，只能够说明这两个对象在散列存储结构中，如Hashtable，他们“存放在一个篮子中”。 再次归纳一下就是hashCode是用于查找使用的，而equals是用于比较两个对象是否相等的 关于equals1、equals和== ==用于比较引用和比较基本数据类型时具有不同的功能： 比较基本数据类型，如果两个值相同，则结果为true； 而在比较引用时，如果引用指向内存中的同一对象，结果为true。 2、equals作为方法，实现对象的比较。由于==运算符不允许我们进行覆盖，也就是说它限制了我们的表达，因此我们复写equals()方法，达到比较对象内容是否相同的目的。而这些通过==运算符是做不到的。 3、Object类的equals()方法的比较规则为：如果两个对象的类型一致，并且内容一致，则返回true。","categories":[{"name":"Java","slug":"Java","permalink":"https://utinner.gitee.io/categories/Java/"}],"tags":[{"name":"Java基础","slug":"Java基础","permalink":"https://utinner.gitee.io/tags/Java%E5%9F%BA%E7%A1%80/"}]},{"title":"mongo分片集","slug":"mongo分片集","date":"2020-12-18T08:21:51.000Z","updated":"2021-12-06T09:23:00.860Z","comments":true,"path":"2020/12/18/mongo分片集/","link":"","permalink":"https://utinner.gitee.io/2020/12/18/mongo%E5%88%86%E7%89%87%E9%9B%86/","excerpt":"","text":"分片集的架构说明 名称 解释 作用 Shard 分片集存储实例 用于存储实际的数据块，实际生产环境中一个shard server角色可由几台机器组个一个replica set承担，防止单机节点故障 config server 分片集配置器 存储了整个ClusterMetadata，其中包括 chunk信息 mongos 分片集路由器 客户端由此接入，且让整个集群看上去像单一数据库，前端应用可以透明使用 为什么要使用分片集？一般有如下几个原因： 数据容量日益增大，副本集维护吃力 增加集群的吞吐量 单库数据超过10TB 地理容灾 使用分片集的优劣势 优势 劣势 1.海量数据存储有方案 2.增加数据库的访问并发和集群的iops 3.跨机房灾备 4.单库数据量有限 1.成本高昂，一个高可用的分片集至少需要3台configServer，2个shardServer，每个shardServer都是为副本集，至少2个mongos组成。2.分片集本身结构复杂，运维复杂。 1.如何进行分片？1.1 分片的基本标准 1.数据角度:数据量不超过3TB，尽可能保持在2TB一个分片 2.索引角度:常用的索引必须能容纳进系统内存之中 1.2 分片的预估标准A=(所需存储量/单服务可挂载容量)B=(工作集大小/服务器内存MongoDB可用内存率)C=(并发量总数/单服务器损耗系数)分片的数量=max(A,B,C)举个例子：A=30TB/2TB=15B=1TB/(64G0.6)=27C=200000/(80000.7)=36分片数量=36 1.3 分片的基本概念 名称 解释 分片键 shardkey 文档中的一个字段 文档doc 包含分片键的一行数据 块chunk 包含N个文档 分片shard 包含N个chunk 分片集群Cluster 包含N个分片shard 1.4 选择合适的分片键基于范围的分片MongoDB按照片键的值的范围将数据拆分为不同的块（chunk），每个块包含了一段范围内的数据。 优点： mongos可以快速定位请求需要的数据，并将请求转发到相应的Shard节点中。 缺点： 可能导致数据在Shard节点上分布不均衡，容易造成读写热点，且不具备写分散性。 适用场景： 片键的值不是单调递增或单调递减、片键的值基数大且重复的频率低、需要范围查询等业务场景。 基于hash值的分片MongoDB计算单个字段的哈希值作为索引值，并以哈希值的范围将数据拆分为不同的块。 优点：可以将数据更加均衡地分布在各Shard节点中，具备写分散性。 缺点：不适合进行范围查询，进行范围查询时，需要将读请求分发到所有的Shard节点。 适用场景： 片键的值存在单调递增或递减、片键的值基数大且重复的频率低、需要写入的数据随机分发、数据读取随机性较大等业务场景。 注意 在4.0之前片键一经设置，不可修改，不可删除。在4.2之后可以对分片完的Collection进行修改分片键 执行了数据分片操作后，均衡器会对满足条件的数据进行拆分，这将占用实例的资源，请在业务低峰期操作。 1.5 分片操作1&gt;确认使用的实例为分片集群（执行sh.status()）2&gt;切换数据库（执行 use 数据库名&gt;3&gt;允许此库进行分片(执行 sh.enableSharding(“数据库名”))4&gt;创建或使用已有的collection5&gt;对collection中已创建索引的字段进行分片 1sh.shardCollection(&quot;数据库名.表名&quot;,&#123;&quot;_id&quot;:1&#125;) 6.经过一段时间查看一下数据在每个节点的分布 1db.stats()","categories":[{"name":"数据库","slug":"数据库","permalink":"https://utinner.gitee.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MongoDB","slug":"MongoDB","permalink":"https://utinner.gitee.io/tags/MongoDB/"}]},{"title":"mongo服务","slug":"mongo服务","date":"2020-12-18T07:51:14.000Z","updated":"2021-12-06T09:23:00.861Z","comments":true,"path":"2020/12/18/mongo服务/","link":"","permalink":"https://utinner.gitee.io/2020/12/18/mongo%E6%9C%8D%E5%8A%A1/","excerpt":"前言本文以MongoDB 4.0版本为准，介绍服务器端、客户端的关键技术，以及使用中的注意事项。 服务器（Server）部署方式1.单机部署方式适用场景:开发、测试","text":"前言本文以MongoDB 4.0版本为准，介绍服务器端、客户端的关键技术，以及使用中的注意事项。 服务器（Server）部署方式1.单机部署方式适用场景:开发、测试 2.副本集部署方式适用场景：数据的高可用性， 保证数据的安全性，可恢复性 特性： N个节点的集群 任何节点都可以作为主节点 所有写入操作都在主节点上 自动故障转移 自动恢复 原理： 主节点记录在其上的所有操作oplog，从节点定期轮询主节点获取这些操作，然后对自己的数据副本执行这些操作，从而保证从节点的数据与主节点一致。 3.分片集部署方式适用场景：高增长的大量数据 特性： 包含副本集的特点 支持数据分片存储 一般来说每个shard都有自己的副本集 名称 解释 作用 Shard 分片集存储实例 用于存储实际的数据块，实际生产环境中一个shard server角色可由几台机器组个一个replica set承担，防止单机节点故障 config server 分片集配置器 存储了整个ClusterMetadata，其中包括 chunk信息 mongos 分片集路由器 客户端由此接入，且让整个集群看上去像单一数据库，前端应用可以透明使用 存储引擎MMAP(3.0后有一个改进版本MMAPv1)早期的mongoDB存储引擎，存在一些问题: 锁粒度为库级别锁 耗费过多的磁盘空间 内存无限制，有多少用多少 集合和索引都混合存储在数据库文件中，即使删掉了某个集合或者索引，占用的磁盘空间也很难及时自动回收 文档按照写入顺序排列存储。如果文档更新后长度变长且原有存储位置后面没有足够的空间放下增长部分的数据，那么文档就要移动到文件中的其他位置。这种因更新导致的文档位置移动会严重降低写性能，因为一旦文档发生移动，集合中的所有索引都要同步修改文档新的存储位置 WiredTiger目前默认的存储引擎，有以下的特点： 通过MVCC实现文档级别的并发控制，即文档级别锁。这在提升数据库读写性能的同时，大大提高了系统的并发处理能力。 支持对所有集合和索引进行Block压缩和前缀压缩（如果数据库启用了journal，journal文件一样会压缩）。 集合和索引分开文件存储 支持内存使用容量配置 RocksDB插件式引擎引入的第三方引擎: K/V式的存储引擎 用自己的方式实现了大部分引擎的功能 集合的数据删除后，存储空间并不是立即回收，RocksDB 要通过后台压缩来逐步回收空间 mongorcks 对 oplog 空间的删除机制是在用户请求路径里进行的，这样可能导致写入的延迟上升，应像 wiredtiger 这样当 oplog 空间超出时，后台线程来回收。 RocksDB 缺乏批量日志提交的机制，无法将多次并发的写log进行合并，来提升效率。 索引支持普通索引、唯一索引、全文索引。 客户端（client）写策略（WriteConcern选项）MongoDB支持的WriteConcern选项如下： w: 数据写入到number个节点才向用客户端确认 {w: 0} 对客户端的写入不需要发送任何确认，适用于性能要求高，但不关注正确性的场景 {w: 1} 默认的writeConcern，数据写入到Primary就向客户端发送确认 {w: “majority”} 数据写入到副本集大多数成员后向客户端发送确认，适用于对数据安全性要求比较高的场景，该选项会降低写入性能 {w:-1} 忽略网络错误 {w:2} 要求以写入到副本集的主服务器和一个备用服务器 j: 写入操作的journal持久化后才向客户端确认 默认为：{j: false}，如果要求Primary写入持久化了才向客户端确认，则指定该选项为true wtimeout: 写入超时时间，仅w的值大于1时有效。 当指定{w: }时，数据需要成功写入number个节点才算成功，如果写入过程中有节点故障，可能导致这个条件一直不能满足，从而一直不能向客户端发送确认结果，针对这种情况，客户端可设置wtimeout选项来指定超时时间，当写入过程持续超过该时间仍未结束，则认为写入失败。 {w: “majority”}解析{w: 1}、{j: true}等writeConcern选项很好理解，Primary等待条件满足发送确认；但{w: “majority”}则相对复杂些，需要确认数据成功写入到大多数节点才算成功，而MongoDB的复制是通过Secondary不断拉取oplog并重放来实现的，并不是Primary主动将写入同步给Secondary。 那么Primary是如何确认数据已成功写入到大多数节点的？ Client向Primary发起请求，指定writeConcern为{w: “majority”}，Primary收到请求，本地写入并记录写请求到oplog，然后等待大多数节点都同步了这条/批oplog（Secondary应用完oplog会向主报告最新进度)。 Secondary拉取到Primary上新写入的oplog，本地重放并记录oplog。为了让Secondary能在第一时间内拉取到主上的oplog，find命令支持一个awaitData的选项，当find没有任何符合条件的文档时，并不立即返回，而是等待最多maxTimeMS(默认为2s)时间看是否有新的符合条件的数据，如果有就返回；所以当新写入oplog时，备立马能获取到新的oplog。 Secondary上有单独的线程，当oplog的最新时间戳发生更新时，就会向Primary发送replSetUpdatePosition命令更新自己的oplog时间戳。 当Primary发现有足够多的节点oplog时间戳已经满足条件了，向客户端发送确认。 writeConcern总结1、write concern用于控制写入安全的级别，可以分为应答式写入以及非应答式写入2、write concern是一个性能和数据强一致性的权衡，应根据业务场景进行设定3、对于强一致性场景，建议w&gt;1或者等于majority，以及journal为true，否则w=04、在副本集的情形下，建议通过配置文件来修改w以及设置wtimeout，以避免由于某个节点挂起导致无法应答 writeConcern 和getLastError 的关系mongodb有一个write concern的设置，作用是保障write operation的可靠性。一般是在client driver里设置的，和db.getLastError()方法关系很大一般来说，所有的mongo driver，在执行一个写操作（insert、update、delete）之后，都会立刻调用db.getLastError()方法。这样才有机会知道刚才的写操作是否成功，如果捕获到错误，就可以进行相应的处理。处理逻辑也是完全由client决定的，比如写入日志、抛出错误、等待一段时间再次尝试写入等。作为mongodb server并不关心，server只负责通知client发生了错误 这里有3点需要注意： db.getLastError()方法是由driver负责调用的，所以业务代码不需要去显式调用。这点后面还会专门提到。 driver一定会调用db.getLastError()函数，但是并不一定能捕获到错误。这主要取决于write concern的设置级别。 写安全机制 实际上就是在 安全性跟性能之间做权衡。 读策略(ReadConcern和ReadPreference)ReadConcern级别以及作用 ReadPreference设置参数","categories":[{"name":"数据库","slug":"数据库","permalink":"https://utinner.gitee.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MongoDB","slug":"MongoDB","permalink":"https://utinner.gitee.io/tags/MongoDB/"}]},{"title":"Mysql(二)Mysql的数据目录","slug":"Mysql-二-Mysql的数据目录","date":"2020-12-07T15:33:43.000Z","updated":"2021-12-06T09:23:00.736Z","comments":true,"path":"2020/12/07/Mysql-二-Mysql的数据目录/","link":"","permalink":"https://utinner.gitee.io/2020/12/07/Mysql-%E4%BA%8C-Mysql%E7%9A%84%E6%95%B0%E6%8D%AE%E7%9B%AE%E5%BD%95/","excerpt":"数据库和文件系统的关系像InnoDB、MyISAM这样的存储引擎都是把数据存储在文件系统中上。当我们想读取数据的时候，这些存储引擎会从文件系统中把数据读出来返回给我们；当我们想写入数据的时候，这些存储引擎会把这些数据又写回操作系统。","text":"数据库和文件系统的关系像InnoDB、MyISAM这样的存储引擎都是把数据存储在文件系统中上。当我们想读取数据的时候，这些存储引擎会从文件系统中把数据读出来返回给我们；当我们想写入数据的时候，这些存储引擎会把这些数据又写回操作系统。 Mysql数据目录Mysql服务器程序在启动时，会到文件系统的某个目录下加载一些数据，之后在运行过程中产生的数据也会存储到这个目录下的某些文件中。这个目录就称为数据目录。 确定Mysql中的数据目录运行如下命令： 1234567mysql&gt; SHOW VARIABLES LIKE &#x27;datadir&#x27;;+---------------+-----------------------+| Variable_name | Value |+---------------+-----------------------+| datadir | /usr/local/var/mysql/ |+---------------+-----------------------+1 row in set (0.00 sec) 即可看到数据目录在我们计算机中的位置 创建数据库的时候都发生了什么在我们使用“CREATE DATABASE 数据库名”语句创建一个数据库的时候，会在文件系统中发生： 在数据目录下创建一个与数据库名同名的子目录（或者说是文件夹） 在与该数据库名同名的子目录下创建一个名为db.opt的文件。这个文件中包含了该数据库的一些属性，比如该数据库的字符集和比较规则 数据库的文件表示我先来查看我当前拥有的数据库 12345678910111213mysql&gt; SHOW DATABASES;+--------------------+| Database |+--------------------+| information_schema || gateway_config || mysql || nacos_config || performance_schema || sys || tinner |+--------------------+7 rows in set (0.00 sec) 可以看到，当前在我的计算机上有7个数据库，其中gateway_config、nacos_config和tinner是我自定义的，其余4个数据库都是Mysql自带的系统数据库 再来看看我的目录结构 自己看会发现，除了information_schema这个系统数据库外，其他数据库在数据目录下都有对应的子目录 表在文件系统中的表示我们的数据其实都是以记录的形式插入到表中的。每个表的信息可以分为两种： 表结构的定义 表中的数据 MyISAM和InooDB都在数据目录下对应的数据库子目录创建了一个专门用于描述表结构的文件，文件名是表名.frm，以二进制格式存储。 而在数据存入文件上MyISAM和InooDB产生了分歧： &lt;1&gt;InnoDB： InnoDB使用页为基本单位来管理存储空间的，默认的页大小为16KB 对于InnoDB存储引擎来说，每个索引都对应着一棵B+树，该树的每个节点都是一个数据页。数据页之间没有必要是物理连续的，因为数据页之间有双向链表来维护这些页的顺序 InnoDB的聚簇索引的叶子节点存储了完整的用户记录，也就是“索引即数据，数据即索引” 1.系统表空间 在默认情况下，InnoDB会在数据目录下创建爱你一个名为ibdata1、大小为12MB的文件，这个文件就是对应的系统表空间在文件系统上的表示。这个文件是自扩展文件，当不够用的时候它会自己增加文件大小 在一个Mysql服务器中，系统表空间只有一份。从Mysql5.5.7到Mysql5.6.5之间的各个版本中，表中的数据都会被默认存储到这个系统表空间。 2.独立表空间 在Mysql5.6.6以及之后的版本中，InnoDB会为每个表建立一个独立表空间。在存储表数据时，会在该表所属数据库对应的子目录下创建一个表示该独立表空间的文件，该文件为表名.ibd。 假如我在tinner库下创建了s1表，那么在对应的tinner目录下回生成两个文件： s1.frm s1.ibd 其中ibd文件用来存储表中的数据 当我们想刻意将表数据都存储到系统表空间时，在配置文件中修改： 12[server]innodb_file_per_table:0 当innodb_file_per_table为0时，代表使用系统表空间，为1时使用独立表空间。不过只对新增的表有效 将已经存储到系统表空间中的表转移到独立表空间： 1ALTER TABLE 表名 TABLESPACE innodb_file_per_table; 将已经存储到独立表空间的表转移到系统表空间: 1ALTER TABLE 表名 TABLESPACE innodb_system; 3其他类型的表空间通用表空间、undo表空间、临时表空间等 &lt;2&gt;MyISAM：MyISAM中的索引相当于全部都是二级索引，该存储引擎的数据和索引是分开存放的。没有表空间一说。在创建爱你表之后会创建如下三个文件： 表名.frm 表名.MYD 表名.MYI 其中，表名.MYD表示表的数据文件，表名MYI表示表的索引文件。 其他文件除了上面说的这些童虎自己存储的数据以外，数据目录下还包含了一些确保程序更好运行的额外文件，主要包括： 服务器进程文件：每运行一个mysql服务器程序，都意味着启动一个进程。mysql服务器会把自己的进程ID写到这个文件中 服务器日志文件 ssl和rsa证书与秘钥文件：主要是为了客户端和服务器安全通信而创建的一些文件 文件系统对数据库的影响 数据库名称和表名不得超过文件系统所允许的最大长度 特殊字符的问题：比如创建‘test?’表，则生成了‘&#116;&#x65;&#115;&#116;&#64;&#48;&#48;&#51;&#x66;&#46;&#102;&#114;&#109;‘文件 文件长度受文件系统最大长度限制 Mysql系统数据库简介在前文看到除了我自定义的3个数据库，还有4个数据库，属于系统自带的数据库 mysql：存储了Mysql的用户账户和权限信息、一些存储过程和事件的定义信息、一些运行过程中产生的日志信息、一些帮助信息以及时区信息等 information_schema：存放元数据信息，保存着服务器维护的所有其他数据库的信息（表、视图、触发器、列、索引等） performance_schema：存放运行过程中的状态信息，算是对Mysql服务器的一个性能监控 sys：通过视图的形式将information_schema和performance_schema结合起来","categories":[{"name":"数据库","slug":"数据库","permalink":"https://utinner.gitee.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://utinner.gitee.io/tags/Mysql/"}]},{"title":"Docker(三)Image概述","slug":"Docker-三-Image概述","date":"2020-12-07T07:11:14.000Z","updated":"2021-12-06T09:23:00.669Z","comments":true,"path":"2020/12/07/Docker-三-Image概述/","link":"","permalink":"https://utinner.gitee.io/2020/12/07/Docker-%E4%B8%89-Image%E6%A6%82%E8%BF%B0/","excerpt":"什么是Image 文件和meta data的集合（root filesystem） 分层的，并且每一层都可以添加改变删除文件，成为一个新的image 不同的image可以共享相同的layer Image本身是read-only的","text":"什么是Image 文件和meta data的集合（root filesystem） 分层的，并且每一层都可以添加改变删除文件，成为一个新的image 不同的image可以共享相同的layer Image本身是read-only的 Image的获取 通过Dockerfile构建 从docker Registry获取 创建一个helloword-Image先安装编译C语言的相关环境，然后在当前目录下，创建helloWorld文件夹，然后新建hello.c文件 1234sudo yum install -y vimsudo yum install -y gccsudo yum install glibc-staticvim hello.c 然后在hello.c中，编写c语言程序 1234567891011sudo yum install glib-static#include&lt;stdio.h&gt;int main()&#123;int i = 0;for(;i&lt; 10; i ++) &#123; printf(&quot;hello-docker!\\n&quot;); &#125;&#125; 然后编译：gcc -static hello.c -o hello,，可以在当前目录下看到多了一个hello的可执行文件 之后编辑Dockerfile文件 123FROM scratchADD hello /CMD [&quot;/hello&quot;] 然后进行build，运行 12sudo docker build -t tinner/hello-world .sudo docker run tinner/hello-world 即可看到输出：","categories":[{"name":"运维","slug":"运维","permalink":"https://utinner.gitee.io/categories/%E8%BF%90%E7%BB%B4/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://utinner.gitee.io/tags/Docker/"}]},{"title":"Docker(二)Docker架构及底层技术","slug":"Docker-二-Docker架构及底层技术","date":"2020-12-07T06:44:55.000Z","updated":"2021-12-06T09:23:00.673Z","comments":true,"path":"2020/12/07/Docker-二-Docker架构及底层技术/","link":"","permalink":"https://utinner.gitee.io/2020/12/07/Docker-%E4%BA%8C-Docker%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%BA%95%E5%B1%82%E6%8A%80%E6%9C%AF/","excerpt":"Docker PlatformDocker提供了一个开发、打包、运行app的平台 它将app和底层infrastructure隔离开来","text":"Docker PlatformDocker提供了一个开发、打包、运行app的平台 它将app和底层infrastructure隔离开来 Docker EngineDocker Engine 是一个 client-server 应用，它主要有以下几个部分构成： 后台进程（dockerd）它是一个长期运行的程序，称之为 daemon process。 REST API server：程序可以通过这些 API 与 daemon 进行通信和指示 daemon 要做什么。 CLI接口（docker）：docker 指令。 CLI 使用 Docker REST API，然后直接通过脚本或者 CLI 命令来控制或者与 Docker daemon 进行交互。 Docker daemon 用于创建和管理 Docker 对象，如 images、containers、networks 以及 volumes。 底层技术支持Namespaces：做隔离pid、net、ipc、mnt、uts Control groups：做资源限制 Union file systems：Container和image的分层","categories":[{"name":"运维","slug":"运维","permalink":"https://utinner.gitee.io/categories/%E8%BF%90%E7%BB%B4/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://utinner.gitee.io/tags/Docker/"}]},{"title":"Mysql(一)InnoDB存储引擎","slug":"Mysql-一-InnoDB存储引擎","date":"2020-12-06T13:25:56.000Z","updated":"2021-12-06T09:23:00.734Z","comments":true,"path":"2020/12/06/Mysql-一-InnoDB存储引擎/","link":"","permalink":"https://utinner.gitee.io/2020/12/06/Mysql-%E4%B8%80-InnoDB%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/","excerpt":"InnoDB页简介InnoDB是一个将表中的数据存储到磁盘上的存储引擎。它将数据划分为若干个页，以页作为磁盘和内存之间交互的基本单位。InnoDB中页的大小一般为16KB。也就是说在一般情况下，一次至少从磁盘中读取16KB的内容到内存中，一次至少把内存中的16KB的内容刷新到磁盘中。 系统变量innodb_page_size表明了InnoDB存储引擎中的页大小，默认为16384（单位是字节，也就是16KB）。这个变量只能在第一次初始化的Mysql数据目录时指定，之后就再也不能更改了。","text":"InnoDB页简介InnoDB是一个将表中的数据存储到磁盘上的存储引擎。它将数据划分为若干个页，以页作为磁盘和内存之间交互的基本单位。InnoDB中页的大小一般为16KB。也就是说在一般情况下，一次至少从磁盘中读取16KB的内容到内存中，一次至少把内存中的16KB的内容刷新到磁盘中。 系统变量innodb_page_size表明了InnoDB存储引擎中的页大小，默认为16384（单位是字节，也就是16KB）。这个变量只能在第一次初始化的Mysql数据目录时指定，之后就再也不能更改了。 InnoDB行格式我们平时都是以记录为单位向表中插入数据的，这些记录在磁盘上的存放形式也被成为行格式或者记录格式。 大体上目前有4种行格式： compact redundant dynamic compressed 在创建表或修改表结构时指定行格式的语法： 12CREATE 表名(列的信息......) ROW_FORMAT=行格式名称;ALTER TABLE 表名 ROW_FORMAT=行格式名称; compact行格式 1.记录的额外信息这部分信息是服务器为了更高地管理记录而不得不额外添加的一些信息，这些额外信息分为三个部分，分别是变长字段长度列表、NULL值和记录头信息 （1）变长字段长度列表（被定义为VARCHAR(M)、各种TEXT类型、各种BLOB类型） 变长字段占用的存储空间分为两部分: 真正的数据内容 该数据占用的字节数 变长字段长度的数据特点： 各变长字段的真实数据占用的字节数按照列的顺序逆序存放 如果该变长字段允许存储的最大字节数（varchar(M)中的M*SHOW CHARSET结果中的Maxlen列[每个字符集都不相同]W的值）超过255个字节，并且真实数据占用的字节数（L）超过127字节，则使用2字节来表示真实数据占用的字节数，否则使用1字节 变长字段长度列表中只存储值为非NULL的列的长度，不存放值为NULL的内容长度 如果表中所有的列都不是变长的数据类型或者所有列的值都是NULL的话，就不需要有变长字段长度列表 （2）NULL值列表 compact行格式把一条记录中值为NULL的列统一管理起来，存储到NULL值列表中。处理的流程如下： 首先统计表中允许存储NULL的列有哪些 如果表中没有允许存储NULL的列，则NULL值列表就不存在，否则将每个允许存储NULL的列对应一个二进制位，二进制位按照列的顺序逆序排列（二进制位的值为1时，代表该列的值为NULL；为0时不为NULL） Mysql规定NULL值列表必须用整数个字节的位表示，如果使用的二进制位个数不是整数个字节，则在字节的高位补0 （3）记录头信息 记录头信息由固定的5个字节组成（40个二进制位） 名称 大小（位） 描述 预留位1 1 没有使用 预留位2 1 没有使用 delete_flag 1 标记该记录是否被删除 min_rec_flag 1 B+树的每层非叶子节点中最小的目录项记录都会添加该标记 n_owned 4 一个页面中的记录会被分成若干个组，每个组中有一个记录是“带头大哥”，记录的n_owned值代表组中所有的记录条数。其余的都是小弟，记录的为0 heap_no 13 表示当前记录在页面堆中的相对位置 record_type 3 表示当前记录的类型：0-普通记录；1-B+树非叶子节点的目录项记录；2-Infimum记录；3-Supremum记录 next_record 16 表示下一条记录的相对位置 2.记录的真实数据对于我们定义的数据列来说，对于每个记录mysql都会默认地添加一些隐藏列： 列名 是否必需 占用空间 描述 row_id 否 6个字节 行ID，唯一标识一条记录 trx_id 是 6个字节 事务ID roll_pointer 是 7个字节 回滚指针 InnoDB的主键生成策略优先使用用户自定义的主键作为主键；如果用户没有定义主键，则选取一个不允许为null值的UNIQUE键作为主键；以上两种条件都没有，则会默认添加一个名为row_id的隐藏列作为主键 隐藏列和真实数据的排列 在实际存储中，隐藏列会按照row_id、trx_id、roll_pointer的顺序排列在最前面 紧接着就会按照创建表的字段顺序依次排列在三个隐藏列的后面（NULL值不会冗余存储） 3.CHAR(M)列的存储格式在mysql中有如下字符集： ascii采用固定的一个字节来编码一个字符，是一个定长的编码字符集 gbk表示一个字符需要1~2个字节 utf8表示一个字符需要1~3个字节 对于CHAR(M)类型的列来讲： 采用定长的编码字符集，该列占用的字节数不会被加到变长字段长度列表中 采用变长的编码字符集，该列占用的字节数会被加到变长字段长度列表中 另外当采用变长的字符集编码格式的时候对于CHAR(M)还规定：CHAR(M)至少要求占用M个字节。比如utf8格式的话，定义CHAR(10)，长度就是10~30字节，即使存储空字符串也会占用十个字节。这主要是希望未来在更新该列时，在新值的字节长度大于旧值的字节长度但不大于10个字节时，可以在该记录处直接更新而不用重新分配空间 redundant行格式在5.0之前在使用的一种格式，很古老,比较原始的行格式，是非紧凑的，比其他三种占用的存储空间多 溢出列在compact和redundant行格式中，对于占用存储空间非常多的列，在记录的真实数据处只会存储该列的一部分数据，而把剩余的数据分散存储到其他的页中，然后在记录的真实数据处用20字节存储指向这些页的地址，从而可以找到剩余数据所在的页（剩余数据的多个页面使用链表连接起来） 如果一条记录的某个列中存储的数据占用的字节数非常多时，该列就可能成为溢出列 dynamic行格式和compressed行格式5.7默认的行格式是dynamic 共同点： 他们都是继承于compact行格式 在处理溢出页的时候不会在记录的真实数据处存储该溢出列的真实数据的前n个字节的数据，而是将该列的所有真实数据都存储到溢出页中，只在记录的真实数据处存储20个字节大小的指向溢出页的地址（当然，这20字节还包括真实数据占用的字节数） 不同点： compressed行格式会采用压缩算法对页面进行压缩，以节省空间。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://utinner.gitee.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://utinner.gitee.io/tags/Mysql/"}]},{"title":"Docker(一)构建Docker","slug":"Docker-一-构建Docker","date":"2020-12-02T09:53:41.000Z","updated":"2021-12-06T09:23:00.644Z","comments":true,"path":"2020/12/02/Docker-一-构建Docker/","link":"","permalink":"https://utinner.gitee.io/2020/12/02/Docker-%E4%B8%80-%E6%9E%84%E5%BB%BADocker/","excerpt":"一、安装虚拟机安装vagrant安装vagrant 根据自己的电脑操作系统选择最新版本进行安装即可 安装virtualbox安装virtualbox vagrant用于构建虚拟机，virtualbox相当于是一个虚拟机管理工具","text":"一、安装虚拟机安装vagrant安装vagrant 根据自己的电脑操作系统选择最新版本进行安装即可 安装virtualbox安装virtualbox vagrant用于构建虚拟机，virtualbox相当于是一个虚拟机管理工具 相关命令依次执行如下命令： 123cd localmkdir centos7vagrant init centos/7 即可在当前目录下看到有一个Vagrantfile文件生成 然后运行vagrant up命令进行构建虚拟机（需要有点耐心） 构建完毕会在当前目录下生成一个文件夹： 然后在virtualbox程序中，会有相应的虚拟机生成： 二、安装Docker参考官方文档：Docker官方文档 命令在当前文件夹下，使用命令vagrant ssh进入构建出来的虚拟机，然后执行如下命令构建Docker： 12345sudo yum remove docker docker-client docker-client-latest docker-common docker-latest docker-latest-logrotate docker-logrotate docker-enginesudo yum install -y yum-utilssudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.reposudo yum install docker-ce docker-ce-cli containerd.iosudo systemctl start docker 到此为止，docker就创建成功并且启动了运行命令: 1sudo docker run hello-world 可以看到如下信息 将vagrant添加到docker用户组中 1234sudo groupadd dockersudo gpasswd -a vagrant dockersudo service docker restartexit 重启之后，再次vagrant ssh进入虚拟机，运行docker命令就不必加sudo了 三、vagrant相关命令 命令 含义 vagrant init 初始化 vagrant up 启动虚拟机 vagrant halt 关闭虚拟机 vagrant reload 重启虚拟机 vagrant ssh SSH至虚拟机 vagrant suspend 挂起虚拟机 vagrant resume 唤醒虚拟机 vagrant status 查看虚拟机运行状态 vagrant destroy 销毁当前虚拟机 vagrant box list 查看本地box列表 vagrant box add 添加box到列表 vagrant box remove 从box列表移除 四、彩蛋在我们运行vagrant init centos/7之后，就可以看到在当前目录下生成了Vagrantfile文件 我们可以在运行vagrant up的时候即可让虚拟机构建出一个Docker环境，需要修改Vagrantfile文件如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677# -*- mode: ruby -*-# vi: set ft=ruby :# All Vagrant configuration is done below. The &quot;2&quot; in Vagrant.configure# configures the configuration version (we support older styles for# backwards compatibility). Please don&#x27;t change it unless you know what# you&#x27;re doing.Vagrant.configure(&quot;2&quot;) do |config| # The most common configuration options are documented and commented below. # For a complete reference, please see the online documentation at # https://docs.vagrantup.com. # Every Vagrant development environment requires a box. You can search for # boxes at https://vagrantcloud.com/search. config.vm.box = &quot;centos/7&quot; # Disable automatic box update checking. If you disable this, then # boxes will only be checked for updates when the user runs # `vagrant box outdated`. This is not recommended. # config.vm.box_check_update = false # Create a forwarded port mapping which allows access to a specific port # within the machine from a port on the host machine. In the example below, # accessing &quot;localhost:8080&quot; will access port 80 on the guest machine. # NOTE: This will enable public access to the opened port # config.vm.network &quot;forwarded_port&quot;, guest: 80, host: 8080 # Create a forwarded port mapping which allows access to a specific port # within the machine from a port on the host machine and only allow access # via 127.0.0.1 to disable public access # config.vm.network &quot;forwarded_port&quot;, guest: 80, host: 8080, host_ip: &quot;127.0.0.1&quot; # Create a private network, which allows host-only access to the machine # using a specific IP. # config.vm.network &quot;private_network&quot;, ip: &quot;192.168.33.10&quot; # Create a public network, which generally matched to bridged network. # Bridged networks make the machine appear as another physical device on # your network. # config.vm.network &quot;public_network&quot; # Share an additional folder to the guest VM. The first argument is # the path on the host to the actual folder. The second argument is # the path on the guest to mount the folder. And the optional third # argument is a set of non-required options. # config.vm.synced_folder &quot;../data&quot;, &quot;/vagrant_data&quot; # Provider-specific configuration so you can fine-tune various # backing providers for Vagrant. These expose provider-specific options. # Example for VirtualBox: # # config.vm.provider &quot;virtualbox&quot; do |vb| # # Display the VirtualBox GUI when booting the machine # vb.gui = true # # # Customize the amount of memory on the VM: # vb.memory = &quot;1024&quot; # end # # View the documentation for the provider you are using for more # information on available options. # Enable provisioning with a shell script. Additional provisioners such as # Ansible, Chef, Docker, Puppet and Salt are also available. Please see the # documentation for more information about their specific syntax and use. # config.vm.provision &quot;shell&quot;, inline: &lt;&lt;-SHELL # apt-get update # apt-get install -y apache2 config.vm.provision &quot;shell&quot;, inline: &lt;&lt;-SHELL sudo yum remove docker docker-client docker-client-latest docker-common docker-latest docker-latest-logrotate docker-logrotate docker-engine sudo yum install -y yum-utils sudo yum-config-manager -y --add-repo https://download.docker.com/linux/centos/docker-ce.repo sudo yum -y install docker-ce docker-ce-cli containerd.io sudo systemctl start docker SHELLend","categories":[{"name":"运维","slug":"运维","permalink":"https://utinner.gitee.io/categories/%E8%BF%90%E7%BB%B4/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://utinner.gitee.io/tags/Docker/"}]},{"title":"redis源码从哪里读起","slug":"redis源码从哪里读起","date":"2020-11-26T09:58:38.000Z","updated":"2021-12-06T09:23:00.883Z","comments":true,"path":"2020/11/26/redis源码从哪里读起/","link":"","permalink":"https://utinner.gitee.io/2020/11/26/redis%E6%BA%90%E7%A0%81%E4%BB%8E%E5%93%AA%E9%87%8C%E8%AF%BB%E8%B5%B7/","excerpt":"Redis是用C语言实现的，首先，你当然应该从main函数开始读起。但我们在读的时候应该抓住一条主线，也就是当我们向Redis输入一条命令的时候，代码是如何一步步执行的。这样我们就可以先从外部观察，尝试执行一些命令，在了解了这些命令执行的外部表现之后，再钻进去看对应的源码是如何实现的。要想读懂这些代码，首先我们需要理解Redis的事件机制。而且，一旦理解了Redis的事件循环(Event Loop)的机制，我们还会搞明白一个有趣的问题：为什么Redis是单线程执行却能同时处理多个请求？（当然严格来说Redis运行起来并非只有一个线程，但除了主线程之外，Redis的其它线程只是起辅助作用，它们是一些在后台运行做异步耗时任务的线程） 从main函数开始，沿着代码执行路径，实际上我们可以一直追下去。 本文按照如下思路进行： 先概括地介绍整个代码初始化流程（从main函数开始）和事件循环的结构； 再概括地介绍对于Redis命令请求的处理流程； 重点介绍事件机制； 对于前面介绍的各个代码处理流程，给出详细的代码调用关系，方便随时查阅； 注：本文的分析基于Redis源码的5.0分支。","text":"Redis是用C语言实现的，首先，你当然应该从main函数开始读起。但我们在读的时候应该抓住一条主线，也就是当我们向Redis输入一条命令的时候，代码是如何一步步执行的。这样我们就可以先从外部观察，尝试执行一些命令，在了解了这些命令执行的外部表现之后，再钻进去看对应的源码是如何实现的。要想读懂这些代码，首先我们需要理解Redis的事件机制。而且，一旦理解了Redis的事件循环(Event Loop)的机制，我们还会搞明白一个有趣的问题：为什么Redis是单线程执行却能同时处理多个请求？（当然严格来说Redis运行起来并非只有一个线程，但除了主线程之外，Redis的其它线程只是起辅助作用，它们是一些在后台运行做异步耗时任务的线程） 从main函数开始，沿着代码执行路径，实际上我们可以一直追下去。 本文按照如下思路进行： 先概括地介绍整个代码初始化流程（从main函数开始）和事件循环的结构； 再概括地介绍对于Redis命令请求的处理流程； 重点介绍事件机制； 对于前面介绍的各个代码处理流程，给出详细的代码调用关系，方便随时查阅； 注：本文的分析基于Redis源码的5.0分支。 初始化流程和事件循环概述Redis源码的main函数在源文件server.c中。main函数开始执行后的逻辑可以分为两个阶段： 各种初始化（包括事件循环的初始化）； 执行事件循环。 这两个执行阶段可以用下面的流程图来表达： 首先，我们看一下初始化阶段中的各个步骤： 配置加载和初始化。这一步表示Redis服务器基本数据结构和各种参数的初始化。在Redis源码中，Redis服务器是用一个叫做redisServer的struct来表达的，里面定义了Redis服务器赖以运行的各种参数，比如监听的端口号和文件描述符、当前连接的各个client端、Redis命令表(command table)配置、持久化相关的各种参数，等等，以及后面马上会讨论的事件循环结构。Redis服务器在运行时就是由一个redisServer类型的全局变量来表示的（变量名就叫server），这一步的初始化主要就是对于这个全局变量进行初始化。在整个初始化过程中，有一个需要特别关注的函数：populateCommandTable。它初始化了Redis命令表，通过它可以由任意一个Redis命令的名字查找该命令的配置信息（比如该命令接收的命令参数个数、执行函数入口等）。在本文的第二部分，我们将会一起来看一看如何从接收一个Redis命令的请求开始，一步步执行到来查阅这个命令表，从而找到该命令的执行入口。另外，这一步中还有一个值得一提的地方：在对全局的redisServer结构进行了初始化之后，还需要从配置文件（redis.conf）中加载配置。这个过程可能覆盖掉之前初始化过的redisServer结构中的某些参数。换句话说，就是先经过一轮初始化，保证Redis的各个内部数据结构以及参数都有缺省值，然后再从配置文件中加载自定义的配置。 创建事件循环。在Redis中，事件循环是用一个叫aeEventLoop的struct来表示的。「创建事件循环」这一步主要就是创建一个aeEventLoop结构，并存储到server全局变量（即前面提到的redisServer类型的结构）中。另外，事件循环的执行依赖系统底层的I/O多路复用机制(I/O multiplexing)，比如Linux系统上的epoll机制[1]。因此，这一步也包含对于底层I/O多路复用机制的初始化（调用系统API）。 开始socket监听。服务器程序需要监听才能收到请求。根据配置，这一步可能会打开两种监听：对于TCP连接的监听和对于Unix domain socket[2]的监听。「Unix domain socket」是一种高效的进程间通信(IPC[3])机制，在POSIX规范[4]中也有明确的定义[5]，用于在同一台主机上的两个不同进程之间进行通信，比使用TCP协议性能更高（因为省去了协议栈的开销）。当使用Redis客户端连接同一台机器上的Redis服务器时，可以选择使用「Unix domain socket」进行连接。但不管是哪一种监听，程序都会获得文件描述符，并存储到server全局变量中。对于TCP的监听来说，由于监听的IP地址和端口可以绑定多个，因此获得的用于监听TCP连接的文件描述符也可以包含多个。后面，程序就可以拿这一步获得的文件描述符去注册I/O事件回调了。 注册timer事件回调。Redis作为一个单线程(single-threaded)的程序，它如果想调度一些异步执行的任务，比如周期性地执行过期key的回收动作，除了依赖事件循环机制，没有其它的办法。这一步就是向前面刚刚创建好的事件循环中注册一个timer事件，并配置成可以周期性地执行一个回调函数：serverCron。由于Redis只有一个主线程，因此这个函数周期性的执行也是在这个线程内，它由事件循环来驱动（即在合适的时机调用），但不影响同一个线程上其它逻辑的执行（相当于按时间分片了）。serverCron函数到底做了什么呢？实际上，它除了周期性地执行过期key的回收动作，还执行了很多其它任务，比如主从重连、Cluster节点间的重连、BGSAVE和AOF rewrite的触发执行，等等。这个不是本文的重点，这里就不展开描述了。 注册I/O事件回调。Redis服务端最主要的工作就是监听I/O事件，从中分析出来自客户端的命令请求，执行命令，然后返回响应结果。对于I/O事件的监听，自然也是依赖事件循环。前面提到过，Redis可以打开两种监听：对于TCP连接的监听和对于Unix domain socket的监听。因此，这里就包含对于这两种I/O事件的回调的注册，两个回调函数分别是acceptTcpHandler和acceptUnixHandler。对于来自Redis客户端的请求的处理，就会走到这两个函数中去。我们在下一部分就会讨论到这个处理过程。另外，其实Redis在这里还会注册一个I/O事件，用于通过管道(pipe[6])机制与module进行双向通信。这个也不是本文的重点，我们暂时忽略它。 初始化后台线程。Redis会创建一些额外的线程，在后台运行，专门用于处理一些耗时的并且可以被延迟执行的任务（一般是一些清理工作）。在Redis里面这些后台线程被称为bio(Background I/O service)。它们负责的任务包括：可以延迟执行的文件关闭操作(比如unlink命令的执行)，AOF的持久化写库操作(即fsync调用，但注意只有可以被延迟执行的fsync操作才在后台线程执行)，还有一些大key的清除操作(比如flushdb async命令的执行)。可见bio这个名字有点名不副实，它做的事情不一定跟I/O有关。对于这些后台线程，我们可能还会产生一个疑问：前面的初始化过程，已经注册了一个timer事件回调，即serverCron函数，按说后台线程执行的这些任务似乎也可以放在serverCron中去执行。因为serverCron函数也是可以用来执行后台任务的。实际上这样做是不行的。前面我们已经提到过，serverCron由事件循环来驱动，执行还是在Redis主线程上，相当于和主线程上执行的其它操作（主要是对于命令请求的执行）按时间进行分片了。这样的话，serverCron里面就不能执行过于耗时的操作，否则它就会影响Redis执行命令的响应时间。因此，对于耗时的、并且可以被延迟执行的任务，就只能放到单独的线程中去执行了。 启动事件循环。前面创建好了事件循环的结构，但还没有真正进入循环的逻辑。过了这一步，事件循环就运行起来，驱动前面注册的timer事件回调和I/O事件回调不断执行。 注意：Redis服务器的初始化其实还要完成很多很多事，比如加载数据到内存，Cluster集群的初始化，module的初始化，等等。但为了简化，上面讨论的初始化流程，只列出了我们当前关注的步骤。本文关注的是由事件驱动的整个运行机制以及跟命令执行直接相关的部分，因此我们暂时忽略掉其它不太相关的步骤。 现在，我们继续去讨论上面流程图中的第二个阶段：事件循环。 我们先想一下为什么这里需要一个循环。 一个程序启动后，如果没有循环，那么它从第一条指令一直执行到最后一条指令，然后就只能退出了。而Redis作为一个服务端程序，是要等着客户端不停地发来请求然后做相应的处理，不能自己执行完就退出了。因此，Redis启动后必定要进入一个无限循环。显然，程序在每一次的循环执行中，如果有事件（包括客户端请求的I/O事件）发生，就会去处理这些事件。但如果没有事件发生呢？程序显然也不应该空转，而是应该等待，把整个循环阻塞住。这里的等待，就是上面流程图里的「等待事件发生」这个步骤。那么，当整个循环被阻塞住之后，什么时候再恢复执行呢？自然是等待的事件发生的时候，程序被重新唤醒，循环继续下去。这里需要的等待和唤醒操作，怎么实现呢？它们都需要依赖系统的能力才能做到（我们在文章第三部分会详细介绍）。 实际上，这种事件循环机制，对于开发过手机客户端的同学来说，是非常常见且基础的机制。比如跑在iOS/Android上面的App，这些程序都有一个消息循环，负责等待各种UI事件（点击、滑动等）的发生，然后进行处理。同理，对应到服务端，这个循环的原理可以认为差不多，只是等待和处理的事件变成是I/O事件了。另外，除了I/O事件，整个系统在运行过程中肯定还需要根据时间来调度执行一些任务，比如延迟100毫秒再执行某个操作，或者周期性地每隔1秒执行某个任务，这就需要等待和处理另外一种事件——timer事件。 timer事件和I/O事件是两种截然不同的事件，如何由事件循环来统一调度呢？假设事件循环在空闲的时候去等待I/O事件的发生，那么有可能一个timer事件先发生了，这时事件循环就没有被及时唤醒（仍在等待I/O事件）；反之，如果事件循环在等待timer事件，而一个I/O事件先发生了，那么同样没能够被及时唤醒。因此，我们必须有一种机制能够同时等待这两种事件的发生。而恰好，一些系统的API可以做到这一点（比如我们前面提到的epoll机制）。 前面流程图的第二阶段已经比较清楚地表达出了事件循环的执行流程。在这里我们对于其中一些步骤需要关注的地方做一些补充说明： 查找最近的timer事件。如前所述，事件循环需要等待timer和I/O两种事件。对于I/O事件，只需要明确要等待的是哪些文件描述符就可以了；而对于timer事件，还需要经过一番比较，明确在当前这一轮循环中需要等待多长时间。由于系统运行过程中可能注册多个timer事件回调，比如先要求在100毫秒后执行一个回调，同时又要求在200毫秒后执行另一个回调，这就要求事件循环在它的每一轮执行之前，首先要找出最近需要执行的那次timer事件。这样事件循环在接下来的等待中就知道该等待多长时间（在这个例子中，我们需要等待100毫秒）。 等待事件发生。这一步我们需要能够同时等待timer和I/O两种事件的发生。要做到这一点，我们依赖系统底层的I/O多路复用机制(I/O multiplexing)。这种机制一般是这样设计的：它允许我们针对多个文件描述符来等待对应的I/O事件发生，并同时可以指定一个最长的阻塞超时时间。如果在这段阻塞时间内，有I/O事件发生，那么程序会被唤醒继续执行；如果一直没有I/O事件发生，而是指定的时间先超时了，那么程序也会被唤醒。对于timer事件的等待，就是依靠这里的超时机制。当然，这里的超时时间也可以指定成无限长，这就相当于只等待I/O事件。我们再看一下上一步查找最近的timer事件，查找完之后可能有三种结果，因此这一步等待也可能出现三种对应的情况： 第一种情况，查找到了一个最近的timer事件，它要求在未来某一个时刻触发。那么，这一步只需要把这个未来时刻转换成阻塞超时时间即可。 第二种情况，查找到了一个最近的timer事件，但它要求的时刻已经过去了。那么，这时候它应该立刻被触发，而不应该再有任何等待。当然，在实现的时候还是调用了事件等待的API，只是把超时事件设置成0就可以达到这个效果。 第三种情况，没有查找到任何注册的timer事件。那么，这时候应该把超时时间设置成无限长。接下来只有I/O事件发生才能唤醒。 判断有I/O事件发生还是超时。这里是程序从上一步（可能的）阻塞状态中恢复后执行的判断逻辑。如果是I/O事件发生了，那么先执行I/O事件回调，然后根据需要把到期的timer事件的回调也执行掉（如果有的话）；如果是超时先发生了，那么表示只有timer事件需要触发（没有I/O事件发生），那么就直接把到期的timer事件的回调执行掉。 执行I/O事件回调。我们前面提到的对于TCP连接的监听和对于Unix domain socket的监听，这两种I/O事件的回调函数acceptTcpHandler和acceptUnixHandler，就是在这一步被调用的。 执行timer事件回调。我们前面提到的周期性的回调函数serverCron，就是在这一步被调用的。一般情况下，一个timer事件被处理后，它就会被从队列中删除，不会再次执行了。但serverCron却是被周期性调用的，这是怎么回事呢？这是因为Redis对于timer事件回调的处理设计了一个小机制：timer事件的回调函数可以返回一个需要下次执行的毫秒数。如果返回值是正常的正值，那么Redis就不会把这个timer事件从事件循环的队列中删除，这样它后面还有机会再次执行。例如，按照默认的设置，serverCron返回值是100，因此它每隔100毫秒会执行一次（当然这个执行频率可以在redis.conf中通过hz变量来调整）。 至此，Redis整个事件循环的轮廓我们就清楚了。Redis主要的处理流程，包括接收请求、执行命令，以及周期性地执行后台任务（serverCron），都是由这个事件循环驱动的。当请求到来时，I/O事件被触发，事件循环被唤醒，根据请求执行命令并返回响应结果；同时，后台异步任务（如回收过期的key）被拆分成若干小段，由timer事件所触发，夹杂在I/O事件处理的间隙来周期性地运行。这种执行方式允许仅仅使用一个线程来处理大量的请求，并能提供快速的响应时间。当然，这种实现方式之所以能够高效运转，除了事件循环的结构之外，还得益于系统提供的异步的I/O多路复用机制(I/O multiplexing)。事件循环使得CPU资源被分时复用了，不同代码块之间并没有「真正的」并发执行，但I/O多路复用机制使得CPU和I/O的执行是真正并发的。而且，使用单线程还有额外的好处：避免了代码的并发执行，在访问各种数据结构的时候都无需考虑线程安全问题，从而大大降低了实现的复杂度。 Redis命令请求的处理流程概述Redis对于来自客户端的请求的处理，都会走到acceptTcpHandler或acceptUnixHandler这两个回调函数中去。实际上，这样描述还过于粗略。 Redis客户端向服务器发送命令，其实可以细分为两个过程： 连接建立。客户端发起连接请求（通过TCP或Unix domain socket），服务器接受连接。 命令发送、执行和响应。连接一旦建立好，客户端就可以在这个新建立的连接上发送命令数据，服务器收到后执行这个命令，并把执行结果返回给客户端。而且，在新建立的连接上，这整个的「命令发送、执行和响应」的过程就可以反复执行。 上述第一个过程，「连接建立」，对应到服务端的代码，就是会走到acceptTcpHandler或acceptUnixHandler这两个回调函数中去。换句话说，Redis服务器每收到一个新的连接请求，就会由事件循环触发一个I/O事件，从而执行到acceptTcpHandler或acceptUnixHandler回调函数的代码。 接下来，从socket编程的角度，服务器应该调用accept系统API[7]来接受连接请求，并为新的连接创建出一个socket。这个新的socket也就对应着一个新的文件描述符。为了在新的连接上能接收到客户端发来的命令，接下来必须在事件循环中为这个新的文件描述符注册一个I/O事件回调。这个过程的流程图如下： 从上面流程图可以看出，新的连接注册了一个I/O事件回调，即readQueryFromClient。也就是说，对应前面讲的第二个过程，「命令发送、执行和响应」，当服务器收到命令数据的时候，也会由事件循环触发一个I/O事件，执行到readQueryFromClient回调。这个函数的实现就是在处理命令的「执行和响应」了。因此，下面我们看一下这个函数的执行流程图： 上述流程图有几个需要注意的点： 从socket中读入数据，是按照流的方式。也就是说，站在应用层的角度，从底层网络层读入的数据，是由一个个字节组成的字节流。而我们需要从这些字节流中解析出完整的Redis命令，才能知道接下来如何处理。但由于网络传输的特点，我们并不能控制一次读入多少个字节。实际上，即使服务器只是收到一个Redis命令的部分数据（哪怕只有一个字节），也有可能触发一次I/O事件回调。这时我们是调用read系统API[8]来读入数据的。虽然调用read时我们可以指定期望读取的字节数，但它并不会保证一定能返回期望长度的数据。比如我们想读100个字节，但可能只能读到80个字节，剩下的20个字节可能还在网络传输中没有到达。这种情况给接收Redis命令的过程造成了很大的麻烦：首先，可能我们读到的数据还不够一个完整的命令，这时我们应该继续等待更多的数据到达。其次，我们可能一次性收到了大量的数据，里面包含不止一个命令，这时我们必须把里面包含的所有命令都解析出来，而且要正确解析到最后一个完整命令的边界。如果最后一个完整命令后面还有多余的数据，那么这些数据应该留在下次有更多数据到达时再处理。这个复杂的过程一般称为「粘包」。 「粘包」处理的第一个表现，就是当尝试解析出一个完整的命令时，如果解析失败了，那么上面的流程就直接退出了。接下来，如果有更多数据到达，事件循环会再次触发I/O事件回调，重新进入上面的流程继续处理。 「粘包」处理的第二个表现，是上面流程图中的大循环。只要暂存输入数据的query buffer中还有数据可以处理，那么就不停地去尝试解析完整命令，直到把里面所有的完整命令都处理完，才退出循环。 查命令表那一步，就是查找本文前面提到的由populateCommandTable初始化的命令表，这个命令表存储在server.c的全局变量redisCommandTable当中。命令表中存有各个Redis命令的执行入口。 对于命令的执行结果，在上面的流程图中只是最后存到了一个输出buffer中，并没有真正输出给客户端。输出给客户端的过程不在这个流程当中，而是由另外一个同样是由事件循环驱动的过程来完成。 事件机制介绍在本文第一部分，我们提到过，我们必须有一种机制能够同时等待I/O和timer这两种事件的发生。这一机制就是系统底层的I/O多路复用机制(I/O multiplexing)。但是，在不同的系统上，存在多种不同的I/O多路复用机制。因此，为了方便上层程序实现，Redis实现了一个简单的事件驱动程序库，即ae.c的代码，它屏蔽了系统底层在事件处理上的差异，并实现了我们前面一直在讨论的事件循环。 在Redis的事件库的实现中，目前它底层支持4种I/O多路复用机制： select系统调用[9]。这应该是最早出现的一种I/O多路复用机制了，于1983年在4.2BSD Unix中被首次使用[10]。它是POSIX规范的一部分。另外，跟select类似的还有一个poll系统调用[11]，它是1986年在SVR3 Unix系统中首次使用的[10]，也遵循- POSIX规范。只要是遵循POSIX规范的操作系统，它就能支持select和poll机制，因此在目前我们常见的系统中这两种I/O事件机制一般都是支持的。 epoll机制[1]。epoll是比select更新的一种I/O多路复用机制，最早出现在Linux内核的2.5.44版本中[12]。它被设计出来是为了代替旧的select和poll，提供一种更高效的I/O机制。注意，epoll是Linux系统所特有的，它不属于POSIX规范。 kqueue机制[13]。kqueue最早是2000年在FreeBSD 4.1上被设计出来的，后来也支持NetBSD、OpenBSD、DragonflyBSD和macOS系统[14]。它和Linux系统上的epoll是类似的。 event ports。这是在illumos系统[15]上特有的一种I/O事件机制。 既然在不同系统上有不同的事件机制，那么Redis在不同系统上编译时采用的是哪个机制呢？由于在上面四种机制中，后三种是更现代，也是比select和poll更高效的方案，因此Redis优先选择使用后三种机制。 通过上面对各种I/O机制所适用的操作系统的总结，我们很容易看出，如果你在macOS上编译Redis，那么它底层会选用kqueue；而如果在Linux上编译则会选择epoll，这也是Redis在实际运行中比较常见的情况。 需要注意的是，这里所依赖的I/O事件机制，与如何实现高并发的网络服务关系密切。很多技术同学应该都听说过C10K问题[16]。随着硬件和网络的发展，单机支撑10000个连接，甚至单机支撑百万个连接，都成为可能[17]。高性能网络编程与这些底层机制息息相关。 现在我们回过头来再看一下底层的这些I/O事件机制是如何支持了Redis的事件循环的（下面的描述是对本文前面第一部分中事件循环流程的细化）： 首先，向事件循环中注册I/O事件回调的时候，需要指定哪个回调函数注册到哪个事件上（事件用文件描述符来表示）。事件和回调函数的对应关系，由Redis上层封装的事件驱动程序库来维护。具体参见函数aeCreateFileEvent的代码。 类似地，向事件循环中注册timer事件回调的时候，需要指定多长时间之后执行哪个回调函数。这里需要记录哪个回调函数预期在哪个时刻被调用，这也是由Redis上层封装的事件驱动程序库来维护的。具体参见函数aeCreateTimeEvent的代码。 底层的各种事件机制都会提供一个等待事件的操作，比如epoll提供的epoll_wait API。这个等待操作一般可以指定预期等待的事件列表（事件用文件描述符来表示），并同时可以指定一个超时时间（即最大等待多长时间）。在事件循环中需要等待事件发生的时候，就调用这个等待操作，传入之前注册过的所有I/O事件，并把最近的timer事件所对应的时刻转换成这里需要的超时时间。具体参见函数aeProcessEvents的代码。 从上一步的等待操作中唤醒，有两种情况：如果是I/O事件发生了，那么就根据触发的事件查到I/O回调函数，进行调用；如果是超时了，那么检查所有注册过的timer事件，对于预期调用时刻超过当前时间的回调函数都进行调用。 最后，关于事件机制，还有一些信息值得关注：业界已经有一些比较成熟的开源的事件库了，典型的比如libevent[20]和libev[21]。一般来说，这些开源库屏蔽了非常复杂的底层系统细节，并对不同的系统版本实现做了兼容，是非常有价值的。 为什么还要自己实现一套呢？ 原因大致总结起来就是： 不想引入太大的外部依赖。比如libevent太大了，比Redis的代码库还大。 方便做一些定制化的开发。 第三方库有时候会出现一些意想不到的bug。 代码调用关系对于本文前面分析的各个代码处理流程，包括初始化、事件循环、接收命令请求、执行命令、返回响应结果等等，为了方便大家查阅，下面用一个树型图展示了部分关键函数的调用关系（图比较大，点击可以看大图）。再次提醒：下面的调用关系图基于Redis源码的5.0分支，未来很可能随着Redis代码库的迭代而有所变化。 这个树型结构的含义，首先介绍一下： 树型每次向右的分支，表示函数调用深入了一层（调用栈压栈）。 向右走到末端分支，表示没有更多函数调用了（调用栈开始退栈，把控制权交还给事件循环）。 图中一共有6棵独立的树，除了最开始main函数入口之外，其它5棵树都是由事件循环触发的新的调用流程。左侧树根是流程入口。 这个树型图并没有把所有函数调用关系都表达出来，只是列出了跟本文相关的调用流程。 关键路径代码调用关系图 上图中添加了部分注释，应该可以很清楚地和本文前面介绍过的一些流程对应上。另外，图中一些可能需要注意的细节，如下列出： 初始化过程增加了aeSetBeforeSleepProc和aeSetAfterSleepProc，注册了两个回调函数，这在本文前面没有提到过。一个用于在事件循环每轮开始时调用，另一个会在每轮事件循环的阻塞等待后（即aeApiPoll返回后）调用。图中下面第5个调用流程的入口beforeSleep，就是由这里的aeSetBeforeSleepProc来注册到事件循环中的。 前文提到的serverCron周期性地执行，就是指的在processTimeEvents这个调用分支中调用的timeProc这个函数。 在数据接收处理的流程readQueryFromClient中，通过lookupCommand来查询Redis命令表，这个命令表也就是前面初始化时由populateCommandTable初始化的redisCommandTable全局结构。查找命令入口后，调用server.c的call函数来执行命令。图中call函数的下一层，就是调用各个命令的入口函数（图中只列出了几个例子）。以get命令的入口函数getCommand为例，它执行完的执行结果，最终会调用addReply存入到输出buffer中，即client结构的buf或reply字段中（根据执行结果的大小不同）。需要注意的是，就像前面「Redis命令请求的处理流程」最后讨论的一样，这里只是把执行结果存到了一个输出buffer中，并没有真正输出给客户端。真正把响应结果发送给客户端的执行逻辑，在后面的beforeSleep和sendReplyToClient流程中。 最后将命令执行结果发送给客户端的过程，由beforeSleep来触发。它检查输出buffe中有没有需要发送给客户端的执行结果数据，如果有的话，会调用writeToClient尝试进行发送。如果一次性没有把数据发送完毕，那么还需要再向事件循环中注册一个写I/O事件回调sendReplyToClient，在恰当的时机再次调用writeToClient来尝试发送。如果还是有剩余数据没有发送完毕，那么后面会由beforeSleep回调来再次触发这个流程。 简单总结一下，本文系统地记录了如下几个执行流程： 从main函数启动后的初始化过程； 事件循环的执行逻辑和原理； 一个Redis命令从请求接收，到命令的解析和执行，再到执行结果返回的完整过程。 要顺利读懂Redis源码，需要掌握一些在Linux下进行C语言编程的经验，也需要掌握一些Linux系统层面的知识。对于很多人来说，这些可能会是一种障碍。 抛开本文的很多细节，也许你至少可以记住Redis的命令表这个全局变量：redisCommandTable，它就定义在server.c源文件的开头。这里面记录了每一种Redis命令的执行入口。","categories":[{"name":"中间件","slug":"中间件","permalink":"https://utinner.gitee.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://utinner.gitee.io/tags/redis/"}]},{"title":"redis内部数据结构(7)-intset","slug":"redis内部数据结构-7-intset","date":"2020-11-26T09:43:03.000Z","updated":"2021-12-06T09:23:00.881Z","comments":true,"path":"2020/11/26/redis内部数据结构-7-intset/","link":"","permalink":"https://utinner.gitee.io/2020/11/26/redis%E5%86%85%E9%83%A8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-7-intset/","excerpt":"Redis里面使用intset是为了实现集合(set)这种对外的数据结构。set结构类似于数学上的集合的概念，它包含的元素无序，且不能重复。Redis里的set结构还实现了基础的集合并、交、差的操作。与Redis对外暴露的其它数据结构类似，set的底层实现，随着元素类型是否是整型以及添加的元素的数目多少，而有所变化。概括来讲，当set中添加的元素都是整型且元素数目较少时，set使用intset作为底层数据结构，否则，set使用dict作为底层数据结构。 在本文中我们将大体分成三个部分进行介绍： 集中介绍intset数据结构。 讨论set是如何在intset和dict基础上构建起来的。 集中讨论set的并、交、差的算法实现以及时间复杂度。注意，其中差集的计算在Redis中实现了两种算法。","text":"Redis里面使用intset是为了实现集合(set)这种对外的数据结构。set结构类似于数学上的集合的概念，它包含的元素无序，且不能重复。Redis里的set结构还实现了基础的集合并、交、差的操作。与Redis对外暴露的其它数据结构类似，set的底层实现，随着元素类型是否是整型以及添加的元素的数目多少，而有所变化。概括来讲，当set中添加的元素都是整型且元素数目较少时，set使用intset作为底层数据结构，否则，set使用dict作为底层数据结构。 在本文中我们将大体分成三个部分进行介绍： 集中介绍intset数据结构。 讨论set是如何在intset和dict基础上构建起来的。 集中讨论set的并、交、差的算法实现以及时间复杂度。注意，其中差集的计算在Redis中实现了两种算法。 我们在讨论中还会涉及到一个Redis配置（在redis.conf中的ADVANCED CONFIG部分）： 1set-max-intset-entries 512 注：本文讨论的代码实现基于Redis源码的3.2分支。 intset数据结构简介intset顾名思义，是由整数组成的集合。实际上，intset是一个由整数组成的有序集合，从而便于在上面进行二分查找，用于快速地判断一个元素是否属于这个集合。它在内存分配上与ziplist有些类似，是连续的一整块内存空间，而且对于大整数和小整数（按绝对值）采取了不同的编码，尽量对内存的使用进行了优化。 intset的数据结构定义如下（出自intset.h和intset.c） 123456789typedef struct intset &#123; uint32_t encoding; uint32_t length; int8_t contents[];&#125; intset;#define INTSET_ENC_INT16 (sizeof(int16_t))#define INTSET_ENC_INT32 (sizeof(int32_t))#define INTSET_ENC_INT64 (sizeof(int64_t)) 各个字段含义如下： encoding: 数据编码，表示intset中的每个数据元素用几个字节来存储。它有三种可能的取值：INTSET_ENC_INT16表示每个元素用2个字节存储，INTSET_ENC_INT32表示每个元素用4个字节存储，INTSET_ENC_INT64表示每个元素用8个字节存储。因此，intset中存储的整数最多只能占用64bit。 length: 表示intset中的元素个数。encoding和length两个字段构成了intset的头部（header）。 contents: 是一个柔性数组（flexible array member），表示intset的header后面紧跟着数据元素。这个数组的总长度（即总字节数）等于encoding * length。柔性数组在Redis的很多数据结构的定义中都出现过（例如sds, quicklist, skiplist），用于表达一个偏移量。contents需要单独为其分配空间，这部分内存不包含在intset结构当中。 其中需要注意的是，intset可能会随着数据的添加而改变它的数据编码： 最开始，新创建的intset使用占内存最小的INTSET_ENC_INT16（值为2）作为数据编码。 每添加一个新元素，则根据元素大小决定是否对数据编码进行升级。 下图给出了一个添加数据的具体例子。 在上图中： 新创建的intset只有一个header，总共8个字节。其中encoding = 2, length = 0。 添加13, 5两个元素之后，因为它们是比较小的整数，都能使用2个字节表示，所以encoding不变，值还是2。 当添加32768的时候，它不再能用2个字节来表示了（2个字节能表达的数据范围是-215~215-1，而32768等于215，超出范围了），因此encoding必须升级到INTSET_ENC_INT32（值为4），即用4个字节表示一个元素。 在添加每个元素的过程中，intset始终保持从小到大有序。 与ziplist类似，intset也是按小端（little endian）模式存储的（参见维基百科词条Endianness）。比如，在上图中intset添加完所有数据之后，表示encoding字段的4个字节应该解释成0x00000004，而第5个数据应该解释成0x000186A0 = 100000。 intset与ziplist相比： ziplist可以存储任意二进制串，而intset只能存储整数。 ziplist是无序的，而intset是从小到大有序的。因此，在ziplist上查找只能遍历，而在intset上可以进行二分查找，性能更高。 ziplist可以对每个数据项进行不同的变长编码（每个数据项前面都有数据长度字段len），而intset只能整体使用一个统一的编码（encoding）。 intset的查找和添加操作要理解intset的一些实现细节，只需要关注intset的两个关键操作基本就可以了：查找（intsetFind）和添加（intsetAdd）元素。 intsetFind的关键代码如下所示（出自intset.c）： 123456789101112131415161718192021222324252627282930313233343536373839404142434445uint8_t intsetFind(intset *is, int64_t value) &#123; uint8_t valenc = _intsetValueEncoding(value); return valenc &lt;= intrev32ifbe(is-&gt;encoding) &amp;&amp; intsetSearch(is,value,NULL);&#125;static uint8_t intsetSearch(intset *is, int64_t value, uint32_t *pos) &#123; int min = 0, max = intrev32ifbe(is-&gt;length)-1, mid = -1; int64_t cur = -1; /* The value can never be found when the set is empty */ if (intrev32ifbe(is-&gt;length) == 0) &#123; if (pos) *pos = 0; return 0; &#125; else &#123; /* Check for the case where we know we cannot find the value, * but do know the insert position. */ if (value &gt; _intsetGet(is,intrev32ifbe(is-&gt;length)-1)) &#123; if (pos) *pos = intrev32ifbe(is-&gt;length); return 0; &#125; else if (value &lt; _intsetGet(is,0)) &#123; if (pos) *pos = 0; return 0; &#125; &#125; while(max &gt;= min) &#123; mid = ((unsigned int)min + (unsigned int)max) &gt;&gt; 1; cur = _intsetGet(is,mid); if (value &gt; cur) &#123; min = mid+1; &#125; else if (value &lt; cur) &#123; max = mid-1; &#125; else &#123; break; &#125; &#125; if (value == cur) &#123; if (pos) *pos = mid; return 1; &#125; else &#123; if (pos) *pos = min; return 0; &#125;&#125; 关于以上代码，我们需要注意的地方包括： intsetFind在指定的intset中查找指定的元素value，找到返回1，没找到返回0。 _intsetValueEncoding函数会根据要查找的value落在哪个范围而计算出相应的数据编码（即它应该用几个字节来存储）。 如果value所需的数据编码比当前intset的编码要大，则它肯定在当前intset所能存储的数据范围之外（特别大或特别小），所以这时会直接返回0；否则调用intsetSearch执行一个二分查找算法。 intsetSearch在指定的intset中查找指定的元素value，如果找到，则返回1并且将参数pos指向找到的元素位置；如果没找到，则返回0并且将参数pos指向能插入该元素的位置。 intsetSearch是对于二分查找算法的一个实现，它大致分为三个部分： 特殊处理intset为空的情况。 特殊处理两个边界情况：当要查找的value比最后一个元素还要大或者比第一个元素还要小的时候。实际上，这两部分的特殊处理，在二分查找中并不是必须的，但它们在这里提供了特殊情况下快速失败的可能。 真正执行二分查找过程。注意：如果最后没找到，插入位置在min指定的位置。 代码中出现的intrev32ifbe是为了在需要的时候做大小端转换的。前面我们提到过，intset里的数据是按小端（little endian）模式存储的，因此在大端（big endian）机器上运行时，这里的intrev32ifbe会做相应的转换。 这个查找算法的总的时间复杂度为O(log n)。 而intsetAdd的关键代码如下所示（出自intset.c）： 12345678910111213141516171819202122232425262728intset *intsetAdd(intset *is, int64_t value, uint8_t *success) &#123; uint8_t valenc = _intsetValueEncoding(value); uint32_t pos; if (success) *success = 1; /* Upgrade encoding if necessary. If we need to upgrade, we know that * this value should be either appended (if &gt; 0) or prepended (if &lt; 0), * because it lies outside the range of existing values. */ if (valenc &gt; intrev32ifbe(is-&gt;encoding)) &#123; /* This always succeeds, so we don&#x27;t need to curry *success. */ return intsetUpgradeAndAdd(is,value); &#125; else &#123; /* Abort if the value is already present in the set. * This call will populate &quot;pos&quot; with the right position to insert * the value when it cannot be found. */ if (intsetSearch(is,value,&amp;pos)) &#123; if (success) *success = 0; return is; &#125; is = intsetResize(is,intrev32ifbe(is-&gt;length)+1); if (pos &lt; intrev32ifbe(is-&gt;length)) intsetMoveTail(is,pos,pos+1); &#125; _intsetSet(is,pos,value); is-&gt;length = intrev32ifbe(intrev32ifbe(is-&gt;length)+1); return is;&#125; 关于以上代码，我们需要注意的地方包括： intsetAdd在intset中添加新元素value。如果value在添加前已经存在，则不会重复添加，这时参数success被置为0；如果value在原来intset中不存在，则将value插入到适当位置，这时参数success被置为0。 如果要添加的元素value所需的数据编码比当前intset的编码要大，那么则调用intsetUpgradeAndAdd将intset的编码进行升级后再插入value。 调用intsetSearch，如果能查到，则不会重复添加。 如果没查到，则调用intsetResize对intset进行内存扩充，使得它能够容纳新添加的元素。因为intset是一块连续空间，因此这个操作会引发内存的realloc（参见http://man.cx/realloc）。这有可能带来一次数据拷贝。同时调用intsetMoveTail将待插入位置后面的元素统一向后移动1个位置，这也涉及到一次数据拷贝。值得注意的是，在intsetMoveTail中是调用memmove完成这次数据拷贝的。memmove保证了在拷贝过程中不会造成数据重叠或覆盖，具体参见http://man.cx/memmove。 intsetUpgradeAndAdd的实现中也会调用intsetResize来完成内存扩充。在进行编码升级时，intsetUpgradeAndAdd的实现会把原来intset中的每个元素取出来，再用新的编码重新写入新的位置。 注意一下intsetAdd的返回值，它返回一个新的intset指针。它可能与传入的intset指针is相同，也可能不同。调用方必须用这里返回的新的intset，替换之前传进来的旧的intset变量。类似这种接口使用模式，在Redis的实现代码中是很常见的，比如我们之前在介绍sds和ziplist的时候都碰到过类似的情况。 显然，这个intsetAdd算法总的时间复杂度为O(n)。 Redis的set为了更好地理解Redis对外暴露的set数据结构，我们先看一下set的一些关键的命令。下面是一些命令举例： 上面这些命令的含义： sadd用于分别向集合s1和s2中添加元素。添加的元素既有数字，也有非数字（”a”和”b”）。 sismember用于判断指定的元素是否在集合内存在。 sinter, sunion和sdiff分别用于计算集合的交集、并集和差集。 set的底层实现，随着元素类型是否是整型以及添加的元素的数目多少，而有所变化。例如，具体到上述命令的执行过程中，集合s1的底层数据结构会发生如下变化： 在开始执行完sadd s1 13 5之后，由于添加的都是比较小的整数，所以s1底层是一个intset，其数据编码encoding = 2。 在执行完sadd s1 32768 10 100000之后，s1底层仍然是一个intset，但其数据编码encoding从2升级到了4。 在执行完sadd s1 a b之后，由于添加的元素不再是数字，s1底层的实现会转成一个dict。 dict是一个用于维护key和value映射关系的数据结构，那么当set底层用dict表示的时候，它的key和value分别是什么呢？实际上，key就是要添加的集合元素，而value是NULL。 除了前面提到的由于添加非数字元素造成集合底层由intset转成dict之外，还有两种情况可能造成这种转换： 添加了一个数字，但它无法用64bit的有符号数来表达。intset能够表达的最大的整数范围为-264~264-1，因此，如果添加的数字超出了这个范围，这也会导致intset转成dict。 添加的集合元素个数超过了set-max-intset-entries配置的值的时候，也会导致intset转成dict（具体的触发条件参见t_set.c中的setTypeAdd相关代码）。 对于小集合使用intset来存储，主要的原因是节省内存。特别是当存储的元素个数较少的时候，dict所带来的内存开销要大得多（包含两个哈希表、链表指针以及大量的其它元数据）。所以，当存储大量的小集合而且集合元素都是数字的时候，用intset能节省下一笔可观的内存空间。 实际上，从时间复杂度上比较，intset的平均情况是没有dict性能高的。以查找为例，intset是O(log n)的，而dict可以认为是O(1)的。但是，由于使用intset的时候集合元素个数比较少，所以这个影响不大。 Redis set的并、交、差算法Redis set的并、交、差算法的实现代码，在t_set.c中。其中计算交集调用的是sinterGenericCommand，计算并集和差集调用的是sunionDiffGenericCommand。它们都能同时对多个（可以多于2个）集合进行运算。当对多个集合进行差集运算时，它表达的含义是：用第一个集合与第二个集合做差集，所得结果再与第三个集合做差集，依次向后类推。 交集计算交集的过程大概可以分为三部分： 检查各个集合，对于不存在的集合当做空集来处理。一旦出现空集，则不用继续计算了，最终的交集就是空集。 对各个集合按照元素个数由少到多进行排序。这个排序有利于后面计算的时候从最小的集合开始，需要处理的元素个数较少。 对排序后第一个集合（也就是最小集合）进行遍历，对于它的每一个元素，依次在后面的所有集合中进行查找。只有在所有集合中都能找到的元素，才加入到最后的结果集合中。 需要注意的是，上述第3步在集合中进行查找，对于intset和dict的存储来说时间复杂度分别是O(log n)和O(1)。但由于只有小集合才使用intset，所以可以粗略地认为intset的查找也是常数时间复杂度的。因此，如Redis官方文档上所说（http://redis.io/commands/sinter），sinter命令的时间复杂度为： O(N*M) worst case where N is the cardinality of the smallest set and M is the number of sets. 并集计算并集最简单，只需要遍历所有集合，将每一个元素都添加到最后的结果集合中。向集合中添加元素会自动去重。 由于要遍历所有集合的每个元素，所以Redis官方文档给出的sunion命令的时间复杂度为（http://redis.io/commands/sunion）： O(N) where N is the total number of elements in all given sets. 注意，这里同前面讨论交集计算一样，将元素插入到结果集合的过程，忽略intset的情况，认为时间复杂度为O(1)。 差集计算差集有两种可能的算法，它们的时间复杂度有所区别。 第一种算法： 对第一个集合进行遍历，对于它的每一个元素，依次在后面的所有集合中进行查找。只有在所有集合中都找不到的元素，才加入到最后的结果集合中。 这种算法的时间复杂度为*O(NM)**，其中N是第一个集合的元素个数，M是集合数目。 第二种算法： 将第一个集合的所有元素都加入到一个中间集合中。 遍历后面所有的集合，对于碰到的每一个元素，从中间集合中删掉它。 最后中间集合剩下的元素就构成了差集。 这种算法的时间复杂度为**O(N)**，其中N是所有集合的元素个数总和。 在计算差集的开始部分，会先分别估算一下两种算法预期的时间复杂度，然后选择复杂度低的算法来进行运算。还有两点需要注意： 在一定程度上优先选择第一种算法，因为它涉及到的操作比较少，只用添加，而第二种算法要先添加再删除。 如果选择了第一种算法，那么在执行该算法之前，Redis的实现中对于第二个集合之后的所有集合，按照元素个数由多到少进行了排序。这个排序有利于以更大的概率查找到元素，从而更快地结束查找。 对于sdiff的时间复杂度，Redis官方文档（http://redis.io/commands/sdiff）只给出了第二种算法的结果，是不准确的。","categories":[{"name":"中间件","slug":"中间件","permalink":"https://utinner.gitee.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://utinner.gitee.io/tags/redis/"}]},{"title":"redis内部数据结构(6)-skiplist","slug":"redis内部数据结构-6-skiplist","date":"2020-11-26T09:01:25.000Z","updated":"2021-12-06T09:23:00.876Z","comments":true,"path":"2020/11/26/redis内部数据结构-6-skiplist/","link":"","permalink":"https://utinner.gitee.io/2020/11/26/redis%E5%86%85%E9%83%A8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-6-skiplist/","excerpt":"Redis里面使用skiplist是为了实现`sorted set`这种对外的数据结构。sorted set提供的操作非常丰富，可以满足非常多的应用场景。 我们将大体分成三个部分进行介绍： 介绍经典的skiplist数据结构，并进行简单的算法分析。这一部分的介绍，与Redis没有直接关系。我会尝试尽量使用通俗易懂的语言进行描述。 讨论Redis里的skiplist的具体实现。为了支持sorted set本身的一些要求，在经典的skiplist基础上，Redis里的相应实现做了若干改动。 讨论sorted set是如何在skiplist, dict和ziplist基础上构建起来的。 我们在讨论中还会涉及到两个Redis配置（在redis.conf中的ADVANCED CONFIG部分）： 12zset-max-ziplist-entries 128zset-max-ziplist-value 64 注：本文讨论的代码实现基于Redis源码的3.2分支。","text":"Redis里面使用skiplist是为了实现`sorted set`这种对外的数据结构。sorted set提供的操作非常丰富，可以满足非常多的应用场景。 我们将大体分成三个部分进行介绍： 介绍经典的skiplist数据结构，并进行简单的算法分析。这一部分的介绍，与Redis没有直接关系。我会尝试尽量使用通俗易懂的语言进行描述。 讨论Redis里的skiplist的具体实现。为了支持sorted set本身的一些要求，在经典的skiplist基础上，Redis里的相应实现做了若干改动。 讨论sorted set是如何在skiplist, dict和ziplist基础上构建起来的。 我们在讨论中还会涉及到两个Redis配置（在redis.conf中的ADVANCED CONFIG部分）： 12zset-max-ziplist-entries 128zset-max-ziplist-value 64 注：本文讨论的代码实现基于Redis源码的3.2分支。 Skip List数据结构简介skiplist本质上也是一种查找结构，用于解决算法中的查找问题（Searching），即根据给定的key，快速查到它所在的位置（或者对应的value）。 一般查找问题的解法分为两个大类：一个是基于各种平衡树，一个是基于哈希表。但skiplist却比较特殊，它没法归属到这两大类里面。 skiplist，顾名思义，首先它是一个list。实际上，它是在有序链表的基础上发展起来的。 我们先来看一个有序链表，如下图（最左侧的灰色节点表示一个空的头结点）： 在这样一个链表中，如果我们要查找某个数据，那么需要从头开始逐个进行比较，直到找到包含数据的那个节点，或者找到第一个比给定数据大的节点为止（没找到）。也就是说，时间复杂度为O(n)。同样，当我们要插入新数据的时候，也要经历同样的查找过程，从而确定插入位置。 假如我们每相邻两个节点增加一个指针，让指针指向下下个节点，如下图： 这样所有新增加的指针连成了一个新的链表，但它包含的节点个数只有原来的一半（上图中是7, 19, 26）。现在当我们想查找数据的时候，可以先沿着这个新链表进行查找。当碰到比待查数据大的节点时，再回到原来的链表中进行查找。比如，我们想查找23，查找的路径是沿着下图中标红的指针所指向的方向进行的： 23首先和7比较，再和19比较，比它们都大，继续向后比较。 但23和26比较的时候，比26要小，因此回到下面的链表（原链表），与22比较。 23比22要大，沿下面的指针继续向后和26比较。23比26小，说明待查数据23在原链表中不存在，而且它的插入位置应该在22和26之间。 在这个查找过程中，由于新增加的指针，我们不再需要与链表中每个节点逐个进行比较了。需要比较的节点数大概只有原来的一半。 利用同样的方式，我们可以在上层新产生的链表上，继续为每相邻的两个节点增加一个指针，从而产生第三层链表。如下图： 在这个新的三层链表结构上，如果我们还是查找23，那么沿着最上层链表首先要比较的是19，发现23比19大，接下来我们就知道只需要到19的后面去继续查找，从而一下子跳过了19前面的所有节点。可以想象，当链表足够长的时候，这种多层链表的查找方式能让我们跳过很多下层节点，大大加快查找的速度。 skiplist正是受这种多层链表的想法的启发而设计出来的。实际上，按照上面生成链表的方式，上面每一层链表的节点个数，是下面一层的节点个数的一半，这样查找过程就非常类似于一个二分查找，使得查找的时间复杂度可以降低到O(log n)。但是，这种方法在插入数据的时候有很大的问题。新插入一个节点之后，就会打乱上下相邻两层链表上节点个数严格的2:1的对应关系。如果要维持这种对应关系，就必须把新插入的节点后面的所有节点（也包括新插入的节点）重新进行调整，这会让时间复杂度重新蜕化成O(n)。删除数据也有同样的问题。 skiplist为了避免这一问题，它不要求上下相邻两层链表之间的节点个数有严格的对应关系，而是为每个节点随机出一个层数(level)。比如，一个节点随机出的层数是3，那么就把它链入到第1层到第3层这三层链表中。为了表达清楚，下图展示了如何通过一步步的插入操作从而形成一个skiplist的过程： 从上面skiplist的创建和插入过程可以看出，每一个节点的层数（level）是随机出来的，而且新插入一个节点不会影响其它节点的层数。因此，插入操作只需要修改插入节点前后的指针，而不需要对很多节点都进行调整。这就降低了插入操作的复杂度。实际上，这是skiplist的一个很重要的特性，这让它在插入性能上明显优于平衡树的方案。这在后面我们还会提到。 根据上图中的skiplist结构，我们很容易理解这种数据结构的名字的由来。skiplist，翻译成中文，可以翻译成“跳表”或“跳跃表”，指的就是除了最下面第1层链表之外，它会产生若干层稀疏的链表，这些链表里面的指针故意跳过了一些节点（而且越高层的链表跳过的节点越多）。这就使得我们在查找数据的时候能够先在高层的链表中进行查找，然后逐层降低，最终降到第1层链表来精确地确定数据位置。在这个过程中，我们跳过了一些节点，从而也就加快了查找速度。 刚刚创建的这个skiplist总共包含4层链表，现在假设我们在它里面依然查找23，下图给出了查找路径： 需要注意的是，前面演示的各个节点的插入过程，实际上在插入之前也要先经历一个类似的查找过程，在确定插入位置后，再完成插入操作。 至此，skiplist的查找和插入操作，我们已经很清楚了。而删除操作与插入操作类似，我们也很容易想象出来。这些操作我们也应该能很容易地用代码实现出来。 当然，实际应用中的skiplist每个节点应该包含key和value两部分。前面的描述中我们没有具体区分key和value，但实际上列表中是按照key进行排序的，查找过程也是根据key在比较。 但是，如果你是第一次接触skiplist，那么一定会产生一个疑问：节点插入时随机出一个层数，仅仅依靠这样一个简单的随机数操作而构建出来的多层链表结构，能保证它有一个良好的查找性能吗？为了回答这个疑问，我们需要分析skiplist的统计性能。 在分析之前，我们还需要着重指出的是，执行插入操作时计算随机数的过程，是一个很关键的过程，它对skiplist的统计特性有着很重要的影响。这并不是一个普通的服从均匀分布的随机数，它的计算过程如下： 首先，每个节点肯定都有第1层指针（每个节点都在第1层链表里）。 如果一个节点有第i层(i&gt;=1)指针（即节点已经在第1层到第i层链表中），那么它有第(i+1)层指针的概率为p。 节点最大的层数不允许超过一个最大值，记为MaxLevel。 这个计算随机层数的伪码如下所示： 123456randomLevel() level := 1 // random()返回一个[0...1)的随机数 while random() &lt; p and level &lt; MaxLevel do level := level + 1 return level randomLevel()的伪码中包含两个参数，一个是p，一个是MaxLevel。在Redis的skiplist实现中，这两个参数的取值为： 12p = 1/4MaxLevel = 32 skiplist的算法性能分析我们先来计算一下每个节点所包含的平均指针数目（概率期望）。节点包含的指针数目，相当于这个算法在空间上的额外开销(overhead)，可以用来度量空间复杂度。 根据前面randomLevel()的伪码，我们很容易看出，产生越高的节点层数，概率越低。定量的分析如下： 节点层数至少为1。而大于1的节点层数，满足一个概率分布。 节点层数恰好等于1的概率为1-p。 节点层数大于等于2的概率为p，而节点层数恰好等于2的概率为p(1-p)。 节点层数大于等于3的概率为p2，而节点层数恰好等于3的概率为p2(1-p)。 节点层数大于等于4的概率为p3，而节点层数恰好等于4的概率为p3(1-p)。 ……因此，一个节点的平均层数（也即包含的平均指针数目），计算如下： 现在很容易计算出： 当p=1/2时，每个节点所包含的平均指针数目为2； 当p=1/4时，每个节点所包含的平均指针数目为1.33。这也是Redis里的skiplist实现在空间上的开销。 接下来，为了分析时间复杂度，我们计算一下skiplist的平均查找长度。查找长度指的是查找路径上跨越的跳数，而查找过程中的比较次数就等于查找长度加1。以前面图中标出的查找23的查找路径为例，从左上角的头结点开始，一直到结点22，查找长度为6。 为了计算查找长度，这里我们需要利用一点小技巧。我们注意到，每个节点插入的时候，它的层数是由随机函数randomLevel()计算出来的，而且随机的计算不依赖于其它节点，每次插入过程都是完全独立的。所以，从统计上来说，一个skiplist结构的形成与节点的插入顺序无关。 这样的话，为了计算查找长度，我们可以将查找过程倒过来看，从右下方第1层上最后到达的那个节点开始，沿着查找路径向左向上回溯，类似于爬楼梯的过程。我们假设当回溯到某个节点的时候，它才被插入，这虽然相当于改变了节点的插入顺序，但从统计上不影响整个skiplist的形成结构。 现在假设我们从一个层数为i的节点x出发，需要向左向上攀爬k层。这时我们有两种可能： 如果节点x有第(i+1)层指针，那么我们需要向上走。这种情况概率为p。 如果节点x没有第(i+1)层指针，那么我们需要向左走。这种情况概率为(1-p)。这两种情形如下图所示： 用C(k)表示向上攀爬k个层级所需要走过的平均查找路径长度（概率期望），那么： 12C(0)=0C(k)=(1-p)×(上图中情况b的查找长度) + p×(上图中情况c的查找长度) 代入，得到一个差分方程并化简： 123C(k)=(1-p)(C(k)+1) + p(C(k-1)+1)C(k)=1/p+C(k-1)C(k)=k/p 这个结果的意思是，我们每爬升1个层级，需要在查找路径上走1/p步。而我们总共需要攀爬的层级数等于整个skiplist的总层数-1。 那么接下来我们需要分析一下当skiplist中有n个节点的时候，它的总层数的概率均值是多少。这个问题直观上比较好理解。根据节点的层数随机算法，容易得出： 第1层链表固定有n个节点； 第2层链表平均有n*p个节点； 第3层链表平均有n*p2个节点； … 所以，从第1层到最高层，各层链表的平均节点数是一个指数递减的等比数列。容易推算出，总层数的均值为log1/pn，而最高层的平均节点数为1/p。 综上，粗略来计算的话，平均查找长度约等于： C(log1/pn-1)=(log1/pn-1)/p即，平均时间复杂度为**O(log n)**。 当然，这里的时间复杂度分析还是比较粗略的。比如，沿着查找路径向左向上回溯的时候，可能先到达左侧头结点，然后沿头结点一路向上；还可能先到达最高层的节点，然后沿着最高层链表一路向左。但这些细节不影响平均时间复杂度的最后结果。另外，这里给出的时间复杂度只是一个概率平均值，但实际上计算一个精细的概率分布也是有可能的 skiplist与平衡树、哈希表的比较 skiplist和各种平衡树（如AVL、红黑树等）的元素是有序排列的，而哈希表不是有序的。因此，在哈希表上只能做单个key的查找，不适宜做范围查找。所谓范围查找，指的是查找那些大小在指定的两个值之间的所有节点。 在做范围查找的时候，平衡树比skiplist操作要复杂。在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。而在skiplist上进行范围查找就非常简单，只需要在找到小值之后，对第1层链表进行若干步的遍历就可以实现。 平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而skiplist的插入和删除只需要修改相邻节点的指针，操作简单又快速。 从内存占用上来说，skiplist比平衡树更灵活一些。一般来说，平衡树每个节点包含2个指针（分别指向左右子树），而skiplist每个节点包含的指针数目平均为1/(1-p)，具体取决于参数p的大小。如果像Redis里的实现一样，取p=1/4，那么平均每个节点包含1.33个指针，比平衡树更有优势。 查找单个key，skiplist和平衡树的时间复杂度都为O(log n)，大体相当；而哈希表在保持较低的哈希值冲突概率的前提下，查找时间复杂度接近O(1)，性能更高一些。所以我们平常使用的各种Map或dictionary结构，大都是基于哈希表实现的。 从算法实现难度上来比较，skiplist比平衡树要简单得多。 Redis中的skiplist实现在Redis中，skiplist被用于实现暴露给外部的一个数据结构：sorted set。准确地说，sorted set底层不仅仅使用了skiplist，还使用了ziplist和dict。这几个数据结构的关系，我们下一章再讨论。现在，我们先花点时间把sorted set的关键命令看一下。这些命令对于Redis里skiplist的实现，有重要的影响。 sorted set是一个有序的数据集合，对于像类似排行榜这样的应用场景特别适合。 现在我们来看一个例子，用sorted set来存储代数课（algebra）的成绩表。原始数据如下： 123456Alice 87.5Bob 89.0Charles 65.5David 78.0Emily 93.5Fred 87.5 这份数据给出了每位同学的名字和分数。下面我们将这份数据存储到sorted set里面去： 对于上面的这些命令，我们需要的注意的地方包括： 前面的6个zadd命令，将6位同学的名字和分数(score)都输入到一个key值为algebra的sorted set里面了。注意Alice和Fred的分数相同，都是87.5分。 zrevrank命令查询Alice的排名（命令中的rev表示按照倒序排列，也就是从大到小），返回3。排在Alice前面的分别是Emily、Bob、Fred，而排名(rank)从0开始计数，所以Alice的排名是3。注意，其实Alice和Fred的分数相同，这种情况下sorted set会把分数相同的元素，按照字典顺序来排列。按照倒序，Fred排在了Alice的前面。 zscore命令查询了Charles对应的分数。 zrevrange命令查询了从大到小排名为0~3的4位同学。 zrevrangebyscore命令查询了分数在80.0和90.0之间的所有同学，并按分数从大到小排列。 总结一下，sorted set中的每个元素主要表现出3个属性： 数据本身（在前面的例子中我们把名字存成了数据）。 每个数据对应一个分数(score)。 根据分数大小和数据本身的字典排序，每个数据会产生一个排名(rank)。可以按正序或倒序。 Redis中skiplist实现的特殊性我们简单分析一下前面出现的几个查询命令： zrevrank由数据查询它对应的排名，这在前面介绍的skiplist中并不支持。 zscore由数据查询它对应的分数，这也不是skiplist所支持的。 zrevrange根据一个排名范围，查询排名在这个范围内的数据。这在前面介绍的skiplist中也不支持。 zrevrangebyscore根据分数区间查询数据集合，是一个skiplist所支持的典型的范围查找（score相当于key）。 实际上，Redis中sorted set的实现是这样的： 当数据较少时，sorted set是由一个ziplist来实现的。 当数据多的时候，sorted set是由一个dict + 一个skiplist来实现的。简单来讲，dict用来查询数据到分数的对应关系，而skiplist用来根据分数查询数据（可能是范围查找）。 这里sorted set的构成我们在下一章还会再详细地讨论。现在我们集中精力来看一下sorted set与skiplist的关系，： zscore的查询，不是由skiplist来提供的，而是由那个dict来提供的。 为了支持排名(rank)，Redis里对skiplist做了扩展，使得根据排名能够快速查到数据，或者根据分数查到数据之后，也同时很容易获得排名。而且，根据排名的查找，时间复杂度也为O(log n)。 zrevrange的查询，是根据排名查数据，由扩展后的skiplist来提供。 zrevrank是先在dict中由数据查到分数，再拿分数到skiplist中去查找，查到后也同时获得了排名。 前述的查询过程，也暗示了各个操作的时间复杂度： zscore只用查询一个dict，所以时间复杂度为O(1) zrevrank, zrevrange, zrevrangebyscore由于要查询skiplist，所以zrevrank的时间复杂度为O(log n)，而zrevrange, zrevrangebyscore的时间复杂度为O(log(n)+M)，其中M是当前查询返回的元素个数。 总结起来，Redis中的skiplist跟前面介绍的经典的skiplist相比，有如下不同： 分数(score)允许重复，即skiplist的key允许重复。这在最开始介绍的经典skiplist中是不允许的。 在比较时，不仅比较分数（相当于skiplist的key），还比较数据本身。在Redis的skiplist实现中，数据本身的内容唯一标识这份数据，而不是由key来唯一标识。另外，当多个元素分数相同的时候，还需要根据数据内容来进字典排序。 第1层链表不是一个单向链表，而是一个双向链表。这是为了方便以倒序方式获取一个范围内的元素。 在skiplist中可以很方便地计算出每个元素的排名(rank)。 skiplist的数据结构定义123456789101112131415161718#define ZSKIPLIST_MAXLEVEL 32#define ZSKIPLIST_P 0.25typedef struct zskiplistNode &#123; robj *obj; double score; struct zskiplistNode *backward; struct zskiplistLevel &#123; struct zskiplistNode *forward; unsigned int span; &#125; level[];&#125; zskiplistNode;typedef struct zskiplist &#123; struct zskiplistNode *header, *tail; unsigned long length; int level;&#125; zskiplist; 这段代码出自server.h，我们来简要分析一下： 开头定义了两个常量，ZSKIPLIST_MAXLEVEL和ZSKIPLIST_P，分别对应我们前面讲到的skiplist的两个参数：一个是MaxLevel，一个是p。 zskiplistNode定义了skiplist的节点结构。 obj字段存放的是节点数据，它的类型是一个string robj。本来一个string robj可能存放的不是sds，而是long型，但zadd命令在将数据插入到skiplist里面之前先进行了解码，所以这里的obj字段里存储的一定是一个sds。这样做的目的应该是为了方便在查找的时候对数据进行字典序的比较，而且，skiplist里的数据部分是数字的可能性也比较小。 score字段是数据对应的分数。 backward字段是指向链表前一个节点的指针（前向指针）。节点只有1个前向指针，所以只有第1层链表是一个双向链表。 level[]存放指向各层链表后一个节点的指针（后向指针）。每层对应1个后向指针，用forward字段表示。另外，每个后向指针还对应了一个span值，它表示当前的指针跨越了多少个节点。span用于计算元素排名(rank)，这正是前面我们提到的Redis对于skiplist所做的一个扩展。需要注意的是，level[]是一个柔性数组（flexible array member），因此它占用的内存不在zskiplistNode结构里面，而需要插入节点的时候单独为它分配。也正因为如此，skiplist的每个节点所包含的指针数目才是不固定的，我们前面分析过的结论——skiplist每个节点包含的指针数目平均为1/(1-p)——才能有意义。 zskiplist定义了真正的skiplist结构，它包含： 头指针header和尾指针tail。 链表长度length，即链表包含的节点总数。注意，新创建的skiplist包含一个空的头指针，这个头指针不包含在length计数中。 level表示skiplist的总层数，即所有节点层数的最大值。 下图以前面插入的代数课成绩表为例，展示了Redis中一个skiplist的可能结构： 注意：图中前向指针上面括号中的数字，表示对应的span的值。即当前指针跨越了多少个节点，这个计数不包括指针的起点节点，但包括指针的终点节点。 假设我们在这个skiplist中查找score=89.0的元素（即Bob的成绩数据），在查找路径中，我们会跨域图中标红的指针，这些指针上面的span值累加起来，就得到了Bob的排名(2+2+1)-1=4（减1是因为rank值以0起始）。需要注意这里算的是从小到大的排名，而如果要算从大到小的排名，只需要用skiplist长度减去查找路径上的span累加值，即6-(2+2+1)=1。 可见，在查找skiplist的过程中，通过累加span值的方式，我们就能很容易算出排名。相反，如果指定排名来查找数据（类似zrange和zrevrange那样），也可以不断累加span并时刻保持累加值不超过指定的排名，通过这种方式就能得到一条O(log n)的查找路径。 Redis中的sorted set我们前面提到过，Redis中的sorted set，是在skiplist, dict和ziplist基础上构建起来的: 当数据较少时，sorted set是由一个ziplist来实现的。 当数据多的时候，sorted set是由一个叫zset的数据结构来实现的，这个zset包含一个dict + 一个skiplist。dict用来查询数据到分数(score)的对应关系，而skiplist用来根据分数查询数据（可能是范围查找）。 在这里我们先来讨论一下前一种情况——基于ziplist实现的sorted set。ziplist就是由很多数据项组成的一大块连续内存。由于sorted set的每一项元素都由数据和score组成，因此，当使用zadd命令插入一个(数据, score)对的时候，底层在相应的ziplist上就插入两个数据项：数据在前，score在后。 ziplist的主要优点是节省内存，但它上面的查找操作只能按顺序查找（可以正序也可以倒序）。因此，sorted set的各个查询操作，就是在ziplist上从前向后（或从后向前）一步步查找，每一步前进两个数据项，跨域一个(数据, score)对。 随着数据的插入，sorted set底层的这个ziplist就可能会转成zset的实现（转换过程详见t_zset.c的zsetConvert）。那么到底插入多少才会转呢？ 还记得本文开头提到的两个Redis配置吗？ 12zset-max-ziplist-entries 128zset-max-ziplist-value 64 这个配置的意思是说，在如下两个条件之一满足的时候，ziplist会转成zset（具体的触发条件参见t_zset.c中的zaddGenericCommand相关代码）： 当sorted set中的元素个数，即(数据, score)对的数目超过128的时候，也就是ziplist数据项超过256的时候。 当sorted set中插入的任意一个数据的长度超过了64的时候。 最后，zset结构的代码定义如下： 1234typedef struct zset &#123; dict *dict; zskiplist *zsl;&#125; zset; Redis为什么用skiplist而不用平衡树？在前面我们对于skiplist和平衡树、哈希表的比较中，其实已经不难看出Redis里使用skiplist而不用平衡树的原因了。现在我们看看，对于这个问题，Redis的作者 @antirez 是怎么说的： There are a few reasons: They are not very memory intensive. It’s up to you basically. Changing parameters about the probability of a node to have a given number of levels will make then less memory intensive than btrees. A sorted set is often target of many ZRANGE or ZREVRANGE operations, that is, traversing the skip list as a linked list. With this operation the cache locality of skip lists is at least as good as with other kind of balanced trees. They are simpler to implement, debug, and so forth. For instance thanks to the skip list simplicity I received a patch (already in Redis master) with augmented skip lists implementing ZRANK in O(log(N)). It required little changes to the code.","categories":[{"name":"中间件","slug":"中间件","permalink":"https://utinner.gitee.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://utinner.gitee.io/tags/redis/"}]},{"title":"redis内部数据结构(5)-quicklist","slug":"redis内部数据结构-5-quicklist","date":"2020-11-26T08:32:40.000Z","updated":"2021-12-06T09:23:00.875Z","comments":true,"path":"2020/11/26/redis内部数据结构-5-quicklist/","link":"","permalink":"https://utinner.gitee.io/2020/11/26/redis%E5%86%85%E9%83%A8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-5-quicklist/","excerpt":"Redis对外暴露的list数据类型，它底层实现所依赖的内部数据结构就是`quicklist`。 我们在讨论中还会涉及到两个Redis配置（在redis.conf中的ADVANCED CONFIG部分）： 12list-max-ziplist-size -2list-compress-depth 0","text":"Redis对外暴露的list数据类型，它底层实现所依赖的内部数据结构就是`quicklist`。 我们在讨论中还会涉及到两个Redis配置（在redis.conf中的ADVANCED CONFIG部分）： 12list-max-ziplist-size -2list-compress-depth 0 注：本文讨论的quicklist实现基于Redis源码的3.2分支。 quicklist概述Redis对外暴露的上层list数据类型，经常被用作队列使用。比如它支持的如下一些操作： lpush: 在左侧（即列表头部）插入数据。 rpop: 在右侧（即列表尾部）删除数据。 rpush: 在右侧（即列表尾部）插入数据。 lpop: 在左侧（即列表头部）删除数据。 这些操作都是O(1)时间复杂度的。 当然，list也支持在任意中间位置的存取操作，比如lindex和linsert，但它们都需要对list进行遍历，所以时间复杂度较高，为O(N)。 概况起来，list具有这样的一些特点：它是一个能维持数据项先后顺序的列表（各个数据项的先后顺序由插入位置决定），便于在表的两端追加和删除数据，而对于中间位置的存取具有O(N)的时间复杂度。这不正是一个双向链表所具有的特点吗？ list的内部实现quicklist正是一个双向链表。在quicklist.c的文件头部注释中，是这样描述quicklist的： A doubly linked list of ziplists 它确实是一个双向链表，而且是一个ziplist的双向链表。quicklist的每个节点都是一个ziplist。 ziplist本身也是一个能维持数据项先后顺序的列表（按插入位置），而且是一个内存紧缩的列表（各个数据项在内存上前后相邻）。比如，一个包含3个节点的quicklist，如果每个节点的ziplist又包含4个数据项，那么对外表现上，这个list就总共包含12个数据项。 quicklist的结构为什么这样设计呢？总结起来，大概又是一个空间和时间的折中： 双向链表便于在表的两端进行push和pop操作，但是它的内存开销比较大。首先，它在每个节点上除了要保存数据之外，还要额外保存两个指针；其次，双向链表的各个节点是单独的内存块，地址不连续，节点多了容易产生内存碎片。 ziplist由于是一整块连续内存，所以存储效率很高。但是，它不利于修改操作，每次数据变动都会引发一次内存的realloc。特别是当ziplist长度很长的时候，一次realloc可能会导致大批量的数据拷贝，进一步降低性能。 于是，结合了双向链表和ziplist的优点，quicklist就应运而生了。 不过，这也带来了一个新问题：到底一个quicklist节点包含多长的ziplist合适呢？比如，同样是存储12个数据项，既可以是一个quicklist包含3个节点，而每个节点的ziplist又包含4个数据项，也可以是一个quicklist包含6个节点，而每个节点的ziplist又包含2个数据项。 这又是一个需要找平衡点的难题。我们只从存储效率上分析一下： 每个quicklist节点上的ziplist越短，则内存碎片越多。内存碎片多了，有可能在内存中产生很多无法被利用的小碎片，从而降低存储效率。这种情况的极端是每个quicklist节点上的ziplist只包含一个数据项，这就蜕化成一个普通的双向链表了。 每个quicklist节点上的ziplist越长，则为ziplist分配大块连续内存空间的难度就越大。有可能出现内存里有很多小块的空闲空间（它们加起来很多），但却找不到一块足够大的空闲空间分配给ziplist的情况。这同样会降低存储效率。这种情况的极端是整个quicklist只有一个节点，所有的数据项都分配在这仅有的一个节点的ziplist里面。这其实蜕化成一个ziplist了。 可见，一个quicklist节点上的ziplist要保持一个合理的长度。那到底多长合理呢？这可能取决于具体应用场景。实际上，Redis提供了一个配置参数list-max-ziplist-size，就是为了让使用者可以来根据自己的情况进行调整。 1list-max-ziplist-size -2 我们来详细解释一下这个参数的含义。它可以取正值，也可以取负值。 当取正值的时候，表示按照数据项个数来限定每个quicklist节点上的ziplist长度。比如，当这个参数配置成5的时候，表示每个quicklist节点的ziplist最多包含5个数据项。 当取负值的时候，表示按照占用字节数来限定每个quicklist节点上的ziplist长度。这时，它只能取-1到-5这五个值，每个值含义如下： -5: 每个quicklist节点上的ziplist大小不能超过64 Kb。（注：1kb =&gt; 1024 bytes） -4: 每个quicklist节点上的ziplist大小不能超过32 Kb。 -3: 每个quicklist节点上的ziplist大小不能超过16 Kb。 -2: 每个quicklist节点上的ziplist大小不能超过8 Kb。（-2是Redis给出的默认值） -1: 每个quicklist节点上的ziplist大小不能超过4 Kb。 另外，list的设计目标是能够用来存储很长的数据列表的。比如，Redis官网给出的这个教程：Writing a simple Twitter clone with PHP and Redis，就是使用list来存储类似Twitter的timeline数据。 当列表很长的时候，最容易被访问的很可能是两端的数据，中间的数据被访问的频率比较低（访问起来性能也很低）。如果应用场景符合这个特点，那么list还提供了一个选项，能够把中间的数据节点进行压缩，从而进一步节省内存空间。Redis的配置参数list-compress-depth就是用来完成这个设置的。 1list-compress-depth 0 这个参数表示一个quicklist两端不被压缩的节点个数。注：这里的节点个数是指quicklist双向链表的节点个数，而不是指ziplist里面的数据项个数。实际上，一个quicklist节点上的ziplist，如果被压缩，就是整体被压缩的。 参数list-compress-depth的取值含义如下： 0: 是个特殊值，表示都不压缩。这是Redis的默认值。 1: 表示quicklist两端各有1个节点不压缩，中间的节点压缩。 2: 表示quicklist两端各有2个节点不压缩，中间的节点压缩。 3: 表示quicklist两端各有3个节点不压缩，中间的节点压缩。 依此类推… 由于0是个特殊值，很容易看出quicklist的头节点和尾节点总是不被压缩的，以便于在表的两端进行快速存取。Redis对于quicklist内部节点的压缩算法，采用的LZF——一种无损压缩算法。 quicklist的数据结构定义quicklist相关的数据结构定义可以在quicklist.h中找到： 1234567891011121314151617181920212223242526typedef struct quicklistNode &#123; struct quicklistNode *prev; struct quicklistNode *next; unsigned char *zl; unsigned int sz; /* ziplist size in bytes */ unsigned int count : 16; /* count of items in ziplist */ unsigned int encoding : 2; /* RAW==1 or LZF==2 */ unsigned int container : 2; /* NONE==1 or ZIPLIST==2 */ unsigned int recompress : 1; /* was this node previous compressed? */ unsigned int attempted_compress : 1; /* node can&#x27;t compress; too small */ unsigned int extra : 10; /* more bits to steal for future usage */&#125; quicklistNode;typedef struct quicklistLZF &#123; unsigned int sz; /* LZF size in bytes*/ char compressed[];&#125; quicklistLZF;typedef struct quicklist &#123; quicklistNode *head; quicklistNode *tail; unsigned long count; /* total count of all entries in all ziplists */ unsigned int len; /* number of quicklistNodes */ int fill : 16; /* fill factor for individual nodes */ unsigned int compress : 16; /* depth of end nodes not to compress;0=off */&#125; quicklist; quicklistNode结构代表quicklist的一个节点，其中各个字段的含义如下： prev: 指向链表前一个节点的指针。 next: 指向链表后一个节点的指针。 zl: 数据指针。如果当前节点的数据没有压缩，那么它指向一个ziplist结构；否则，它指向一个quicklistLZF结构。 sz: 表示zl指向的ziplist的总大小（包括zlbytes, zltail, zllen, zlend和各个数据项）。需要注意的是：如果ziplist被压缩了，那么这个sz的值仍然是压缩前的ziplist大小。 count: 表示ziplist里面包含的数据项个数。这个字段只有16bit。稍后我们会一起计算一下这16bit是否够用。 encoding: 表示ziplist是否压缩了（以及用了哪个压缩算法）。目前只有两种取值：2表示被压缩了（而且用的是LZF压缩算法），1表示没有压缩。 container: 是一个预留字段。本来设计是用来表明一个quicklist节点下面是直接存数据，还是使用ziplist存数据，或者用其它的结构来存数据（用作一个数据容器，所以叫container）。但是，在目前的实现中，这个值是一个固定的值2，表示使用ziplist作为数据容器。 recompress: 当我们使用类似lindex这样的命令查看了某一项本来压缩的数据时，需要把数据暂时解压，这时就设置recompress=1做一个标记，等有机会再把数据重新压缩。 attempted_compress: 这个值只对Redis的自动化测试程序有用。我们不用管它。 extra: 其它扩展字段。目前Redis的实现里也没用上。 quicklistLZF结构表示一个被压缩过的ziplist。其中： sz: 表示压缩后的ziplist大小。 compressed: 是个柔性数组（flexible array member），存放压缩后的ziplist字节数组。 真正表示quicklist的数据结构是同名的quicklist这个struct： head: 指向头节点（左侧第一个节点）的指针。 tail: 指向尾节点（右侧第一个节点）的指针。 count: 所有ziplist数据项的个数总和。 len: quicklist节点的个数。 fill: 16bit，ziplist大小设置，存放list-max-ziplist-size参数的值。 compress: 16bit，节点压缩深度设置，存放list-compress-depth参数的值。 上图是一个quicklist的结构图举例。图中例子对应的ziplist大小配置和节点压缩深度配置，如下： 12list-max-ziplist-size 3list-compress-depth 2 这个例子中我们需要注意的几点是： 两端各有2个橙黄色的节点，是没有被压缩的。它们的数据指针zl指向真正的ziplist。中间的其它节点是被压缩过的，它们的数据指针zl指向被压缩后的ziplist结构，即一个quicklistLZF结构。 左侧头节点上的ziplist里有2项数据，右侧尾节点上的ziplist里有1项数据，中间其它节点上的ziplist里都有3项数据（包括压缩的节点内部）。这表示在表的两端执行过多次push和pop操作后的一个状态。 现在我们来大概计算一下quicklistNode结构中的count字段这16bit是否够用。我们已经知道，ziplist大小受到list-max-ziplist-size参数的限制。按照正值和负值有两种情况： 当这个参数取正值的时候，就是恰好表示一个quicklistNode结构中zl所指向的ziplist所包含的数据项的最大值。list-max-ziplist-size参数是由quicklist结构的fill字段来存储的，而fill字段是16bit，所以它所能表达的值能够用16bit来表示。 当这个参数取负值的时候，能够表示的ziplist最大长度是64 Kb。而ziplist中每一个数据项，最少需要2个字节来表示：1个字节的prevrawlen，1个字节的data（len字段和data合二为一；详见上一篇）。所以，ziplist中数据项的个数不会超过32 K，用16bit来表达足够了。 实际上，在目前的quicklist的实现中，ziplist的大小还会受到另外的限制，根本不会达到这里所分析的最大值。 quicklist的创建当我们使用lpush或rpush命令第一次向一个不存在的list里面插入数据的时候，Redis会首先调用quicklistCreate接口创建一个空的quicklist。 1234567891011quicklist *quicklistCreate(void) &#123; struct quicklist *quicklist; quicklist = zmalloc(sizeof(*quicklist)); quicklist-&gt;head = quicklist-&gt;tail = NULL; quicklist-&gt;len = 0; quicklist-&gt;count = 0; quicklist-&gt;compress = 0; quicklist-&gt;fill = -2; return quicklist;&#125; 在很多介绍数据结构的书上，实现双向链表的时候经常会多增加一个空余的头节点，主要是为了插入和删除操作的方便。从上面quicklistCreate的代码可以看出，quicklist是一个不包含空余头节点的双向链表（head和tail都初始化为NULL）。 quicklist的push操作quicklist的push操作是调用quicklistPush来实现的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354void quicklistPush(quicklist *quicklist, void *value, const size_t sz, int where) &#123; if (where == QUICKLIST_HEAD) &#123; quicklistPushHead(quicklist, value, sz); &#125; else if (where == QUICKLIST_TAIL) &#123; quicklistPushTail(quicklist, value, sz); &#125;&#125;/* Add new entry to head node of quicklist. * * Returns 0 if used existing head. * Returns 1 if new head created. */int quicklistPushHead(quicklist *quicklist, void *value, size_t sz) &#123; quicklistNode *orig_head = quicklist-&gt;head; if (likely( _quicklistNodeAllowInsert(quicklist-&gt;head, quicklist-&gt;fill, sz))) &#123; quicklist-&gt;head-&gt;zl = ziplistPush(quicklist-&gt;head-&gt;zl, value, sz, ZIPLIST_HEAD); quicklistNodeUpdateSz(quicklist-&gt;head); &#125; else &#123; quicklistNode *node = quicklistCreateNode(); node-&gt;zl = ziplistPush(ziplistNew(), value, sz, ZIPLIST_HEAD); quicklistNodeUpdateSz(node); _quicklistInsertNodeBefore(quicklist, quicklist-&gt;head, node); &#125; quicklist-&gt;count++; quicklist-&gt;head-&gt;count++; return (orig_head != quicklist-&gt;head);&#125;/* Add new entry to tail node of quicklist. * * Returns 0 if used existing tail. * Returns 1 if new tail created. */int quicklistPushTail(quicklist *quicklist, void *value, size_t sz) &#123; quicklistNode *orig_tail = quicklist-&gt;tail; if (likely( _quicklistNodeAllowInsert(quicklist-&gt;tail, quicklist-&gt;fill, sz))) &#123; quicklist-&gt;tail-&gt;zl = ziplistPush(quicklist-&gt;tail-&gt;zl, value, sz, ZIPLIST_TAIL); quicklistNodeUpdateSz(quicklist-&gt;tail); &#125; else &#123; quicklistNode *node = quicklistCreateNode(); node-&gt;zl = ziplistPush(ziplistNew(), value, sz, ZIPLIST_TAIL); quicklistNodeUpdateSz(node); _quicklistInsertNodeAfter(quicklist, quicklist-&gt;tail, node); &#125; quicklist-&gt;count++; quicklist-&gt;tail-&gt;count++; return (orig_tail != quicklist-&gt;tail);&#125; 不管是在头部还是尾部插入数据，都包含两种情况： 如果头节点（或尾节点）上ziplist大小没有超过限制（即_quicklistNodeAllowInsert返回1），那么新数据被直接插入到ziplist中（调用ziplistPush）。 如果头节点（或尾节点）上ziplist太大了，那么新创建一个quicklistNode节点（对应地也会新创建一个ziplist），然后把这个新创建的节点插入到quicklist双向链表中（调用_quicklistInsertNodeAfter）。 在_quicklistInsertNodeAfter的实现中，还会根据list-compress-depth的配置将里面的节点进行压缩。它的实现比较繁琐，我们这里就不展开讨论了。 quicklist的其它操作quicklist的操作较多，且实现细节都比较繁杂，这里就不一一分析源码了，我们简单介绍一些比较重要的操作。 quicklist的pop操作是调用quicklistPopCustom来实现的。quicklistPopCustom的实现过程基本上跟quicklistPush相反，先从头部或尾部节点的ziplist中把对应的数据项删除，如果在删除后ziplist为空了，那么对应的头部或尾部节点也要删除。删除后还可能涉及到里面节点的解压缩问题。 quicklist不仅实现了从头部或尾部插入，也实现了从任意指定的位置插入。quicklistInsertAfter和quicklistInsertBefore就是分别在指定位置后面和前面插入数据项。这种在任意指定位置插入数据的操作，情况比较复杂，有众多的逻辑分支。 当插入位置所在的ziplist大小没有超过限制时，直接插入到ziplist中就好了； 当插入位置所在的ziplist大小超过了限制，但插入的位置位于ziplist两端，并且相邻的quicklist链表节点的ziplist大小没有超过限制，那么就转而插入到相邻的那个quicklist链表节点的ziplist中； 当插入位置所在的ziplist大小超过了限制，但插入的位置位于ziplist两端，并且相邻的quicklist链表节点的ziplist大小也超过限制，这时需要新创建一个quicklist链表节点插入。 对于插入位置所在的ziplist大小超过了限制的其它情况（主要对应于在ziplist中间插入数据的情况），则需要把当前ziplist分裂为两个节点，然后再其中一个节点上插入数据。 quicklistSetOptions用于设置ziplist大小配置参数（list-max-ziplist-size）和节点压缩深度配置参数（list-compress-depth）。代码比较简单，就是将相应的值分别设置给quicklist结构的fill字段和compress字段。","categories":[{"name":"中间件","slug":"中间件","permalink":"https://utinner.gitee.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://utinner.gitee.io/tags/redis/"}]},{"title":"redis内部数据结构(4)-ziplist","slug":"redis内部数据结构-4-ziplist","date":"2020-11-26T08:11:58.000Z","updated":"2021-12-06T09:23:00.874Z","comments":true,"path":"2020/11/26/redis内部数据结构-4-ziplist/","link":"","permalink":"https://utinner.gitee.io/2020/11/26/redis%E5%86%85%E9%83%A8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-4-ziplist/","excerpt":"在本文中，我们首先介绍一个新的Redis内部数据结构——ziplist，然后在文章后半部分我们会讨论一下在robj, dict和ziplist的基础上，Redis对外暴露的hash结构是怎样构建起来的。 我们在讨论中还会涉及到两个Redis配置（在redis.conf中的ADVANCED CONFIG部分）： 12hash-max-ziplist-entries 512hash-max-ziplist-value 64","text":"在本文中，我们首先介绍一个新的Redis内部数据结构——ziplist，然后在文章后半部分我们会讨论一下在robj, dict和ziplist的基础上，Redis对外暴露的hash结构是怎样构建起来的。 我们在讨论中还会涉及到两个Redis配置（在redis.conf中的ADVANCED CONFIG部分）： 12hash-max-ziplist-entries 512hash-max-ziplist-value 64 什么是ziplistRedis官方对于ziplist的定义是（出自ziplist.c的文件头部注释）： The ziplist is a specially encoded dually linked list that is designed to be very memory efficient. It stores both strings and integer values, where integers are encoded as actual integers instead of a series of characters. It allows push and pop operations on either side of the list in O(1) time. 翻译一下就是说：ziplist是一个经过特殊编码的双向链表，它的设计目标就是为了提高存储效率。ziplist可以用于存储字符串或整数，其中整数是按真正的二进制表示进行编码的，而不是编码成字符串序列。它能以O(1)的时间复杂度在表的两端提供push和pop操作。 实际上，ziplist充分体现了Redis对于存储效率的追求。一个普通的双向链表，链表中每一项都占用独立的一块内存，各项之间用地址指针（或引用）连接起来。这种方式会带来大量的内存碎片，而且地址指针也会占用额外的内存。而ziplist却是将表中每一项存放在前后连续的地址空间内，一个ziplist整体占用一大块内存。它是一个表（list），但其实不是一个链表（linked list）。 另外，ziplist为了在细节上节省内存，对于值的存储采用了变长的编码方式，大概意思是说，对于大的整数，就多用一些字节来存储，而对于小的整数，就少用一些字节来存储。 ziplist的数据结构定义从宏观上看，ziplist的内存结构如下： 1&lt;zlbytes&gt;&lt;zltail&gt;&lt;zllen&gt;&lt;entry&gt;...&lt;entry&gt;&lt;zlend&gt; 各个部分在内存上是前后相邻的，它们分别的含义如下： &lt;zlbytes&gt;: 32bit，表示ziplist占用的字节总数（也包括&lt;zlbytes&gt;本身占用的4个字节）。 &lt;zltail&gt;: 32bit，表示ziplist表中最后一项（entry）在ziplist中的偏移字节数。&lt;zltail&gt;的存在，使得我们可以很方便地找到最后一项（不用遍历整个ziplist），从而可以在ziplist尾端快速地执行push或pop操作。 &lt;zllen&gt;: 16bit， 表示ziplist中数据项（entry）的个数。zllen字段因为只有16bit，所以可以表达的最大值为2^16-1。这里需要特别注意的是，如果ziplist中数据项个数超过了16bit能表达的最大值，ziplist仍然可以来表示。那怎么表示呢？这里做了这样的规定：如果&lt;zllen&gt;小于等于2^16-2（也就是不等于2^16-1），那么&lt;zllen&gt;就表示ziplist中数据项的个数；否则，也就是&lt;zllen&gt;等于16bit全为1的情况，那么&lt;zllen&gt;就不表示数据项个数了，这时候要想知道ziplist中数据项总数，那么必须对ziplist从头到尾遍历各个数据项，才能计数出来。 &lt;entry&gt;: 表示真正存放数据的数据项，长度不定。一个数据项（entry）也有它自己的内部结构，这个稍后再解释。 &lt;zlend&gt;: ziplist最后1个字节，是一个结束标记，值固定等于255。上面的定义中还值得注意的一点是：&lt;zlbytes&gt;, &lt;zltail&gt;, &lt;zllen&gt;既然占据多个字节，那么在存储的时候就有大端（big endian）和小端（little endian）的区别。ziplist采取的是小端模式来存储，这在下面我们介绍具体例子的时候还会再详细解释。 我们再来看一下每一个数据项&lt;entry&gt;的构成： 1&lt;prevrawlen&gt;&lt;len&gt;&lt;data&gt; 我们看到在真正的数据（&lt;data&gt;）前面，还有两个字段： &lt;prevrawlen&gt;: 表示前一个数据项占用的总字节数。这个字段的用处是为了让ziplist能够从后向前遍历（从后一项的位置，只需向前偏移prevrawlen个字节，就找到了前一项）。这个字段采用变长编码。 &lt;len&gt;: 表示当前数据项的数据长度（即&lt;data&gt;部分的长度）。也采用变长编码。 那么&lt;prevrawlen&gt;和&lt;len&gt;是怎么进行变长编码的呢？先说&lt;prevrawlen&gt;。它有两种可能，或者是1个字节，或者是5个字节： 如果前一个数据项占用字节数小于254，那么&lt;prevrawlen&gt;就只用一个字节来表示，这个字节的值就是前一个数据项的占用字节数。 如果前一个数据项占用字节数大于等于254，那么&lt;prevrawlen&gt;就用5个字节来表示，其中第1个字节的值是254（作为这种情况的一个标记），而后面4个字节组成一个整型值，来真正存储前一个数据项的占用字节数。 为什么没有255的情况呢？这是因为：255已经定义为ziplist结束标记&lt;zlend&gt;的值了。在ziplist的很多操作的实现中，都会根据数据项的第1个字节是不是255来判断当前是不是到达ziplist的结尾了，因此一个正常的数据的第1个字节（也就是&lt;prevrawlen&gt;的第1个字节）是不能够取255这个值的，否则就冲突了。 而字段就更加复杂了，它根据第1个字节的不同，总共分为9种情况（下面的表示法是按二进制表示）： |00pppppp| - 1 byte。第1个字节最高两个bit是00，那么字段只有1个字节，剩余的6个bit用来表示长度值，最高可以表示63 (2^6-1)。 |01pppppp|qqqqqqqq| - 2 bytes。第1个字节最高两个bit是01，那么字段占2个字节，总共有14个bit用来表示长度值，最高可以表示16383 (2^14-1)。 |10__|qqqqqqqq|rrrrrrrr|ssssssss|tttttttt| - 5 bytes。第1个字节最高两个bit是10，那么len字段占5个字节，总共使用32个bit来表示长度值（6个bit舍弃不用），最高可以表示2^32-1。需要注意的是：在前三种情况下，都是按字符串来存储的；从下面第4种情况开始，开始变为按整数来存储了。 |11000000| - 1 byte。字段占用1个字节，值为0xC0，后面的数据存储为2个字节的int16_t类型。 |11010000| - 1 byte。字段占用1个字节，值为0xD0，后面的数据存储为4个字节的int32_t类型。 |11100000| - 1 byte。字段占用1个字节，值为0xE0，后面的数据存储为8个字节的int64_t类型。 |11110000| - 1 byte。字段占用1个字节，值为0xF0，后面的数据存储为3个字节长的整数。 |11111110| - 1 byte。字段占用1个字节，值为0xFE，后面的数据存储为1个字节的整数。 |1111xxxx| - - (xxxx的值在0001和1101之间)。这是一种特殊情况，xxxx从1到13一共13个值，这时就用这13个值来表示真正的数据。注意，这里是表示真正的数据，而不是数据长度了。也就是说，在这种情况下，后面不再需要一个单独的字段来表示真正的数据了，而是和合二为一了。另外，由于xxxx只能取0001和1101这13个值了（其它可能的值和其它情况冲突了，比如0000和1110分别同前面第7种第8种情况冲突，1111跟结束标记冲突），而小数值应该从0开始，因此这13个值分别表示0到12，即xxxx的值减去1才是它所要表示的那个整数数据的值。 好了，ziplist的数据结构定义，我们介绍完了，现在我们看一个具体的例子。 上图是一份真实的ziplist数据。我们逐项解读一下： 这个ziplist一共包含33个字节。字节编号从byte[0]到byte[32]。图中每个字节的值使用16进制表示。 头4个字节（0x21000000）是按小端（little endian）模式存储的&lt;zlbytes&gt;字段。什么是小端呢？就是指数据的低字节保存在内存的低地址中（参见维基百科词条Endianness）。因此，这里&lt;zlbytes&gt;的值应该解析成0x00000021，用十进制表示正好就是33。 接下来4个字节（byte[4..7]）是&lt;zltail&gt;，用小端存储模式来解释，它的值是0x0000001D（值为29），表示最后一个数据项在byte[29]的位置（那个数据项为0x05FE14）。 再接下来2个字节（byte[8..9]），值为0x0004，表示这个ziplist里一共存有4项数据。 接下来6个字节（byte[10..15]）是第1个数据项。其中，prevrawlen=0，因为它前面没有数据项；len=4，相当于前面定义的9种情况中的第1种，表示后面4个字节按字符串存储数据，数据的值为”name”。 接下来8个字节（byte[16..23]）是第2个数据项，与前面数据项存储格式类似，存储1个字符串”tielei”。 接下来5个字节（byte[24..28]）是第3个数据项，与前面数据项存储格式类似，存储1个字符串”age”。 接下来3个字节（byte[29..31]）是最后一个数据项，它的格式与前面的数据项存储格式不太一样。其中，第1个字节prevrawlen=5，表示前一个数据项占用5个字节；第2个字节=FE，相当于前面定义的9种情况中的第8种，所以后面还有1个字节用来表示真正的数据，并且以整数表示。它的值是20（0x14）。 最后1个字节（byte[32]）表示&lt;zlend&gt;，是固定的值255（0xFF）。 总结一下，这个ziplist里存了4个数据项，分别为： 字符串: “name” 字符串: “tielei” 字符串: “age” 整数: 20 实际上，这个ziplist是通过两个hset命令创建出来的。这个我们后半部分会再提到。 ziplist的接口几个重要的接口： 12345678910unsigned char *ziplistNew(void);unsigned char *ziplistMerge(unsigned char **first, unsigned char **second);unsigned char *ziplistPush(unsigned char *zl, unsigned char *s, unsigned int slen, int where);unsigned char *ziplistIndex(unsigned char *zl, int index);unsigned char *ziplistNext(unsigned char *zl, unsigned char *p);unsigned char *ziplistPrev(unsigned char *zl, unsigned char *p);unsigned char *ziplistInsert(unsigned char *zl, unsigned char *p, unsigned char *s, unsigned int slen);unsigned char *ziplistDelete(unsigned char *zl, unsigned char **p);unsigned char *ziplistFind(unsigned char *p, unsigned char *vstr, unsigned int vlen, unsigned int skip);unsigned int ziplistLen(unsigned char *zl); 我们从这些接口的名字就可以粗略猜出它们的功能，下面简单解释一下： ziplist的数据类型，没有用自定义的struct之类的来表达，而就是简单的unsigned char *。这是因为ziplist本质上就是一块连续内存，内部组成结构又是一个高度动态的设计（变长编码），也没法用一个固定的数据结构来表达。 ziplistNew: 创建一个空的ziplist（只包含&lt;zlbytes&gt;&lt;zltail&gt;&lt;zllen&gt;&lt;zlend&gt;）。 ziplistMerge: 将两个ziplist合并成一个新的ziplist。 ziplistPush: 在ziplist的头部或尾端插入一段数据（产生一个新的数据项）。注意一下这个接口的返回值，是一个新的ziplist。调用方必须用这里返回的新的ziplist，替换之前传进来的旧的ziplist变量，而经过这个函数处理之后，原来旧的ziplist变量就失效了。为什么一个简单的插入操作会导致产生一个新的ziplist呢？这是因为ziplist是一块连续空间，对它的追加操作，会引发内存的realloc，因此ziplist的内存位置可能会发生变化。实际上，我们在之前介绍sds的文章中提到过类似这种接口使用模式（参见sdscatlen函数的说明）。 ziplistIndex: 返回index参数指定的数据项的内存位置。index可以是负数，表示从尾端向前进行索引。 ziplistNext和ziplistPrev分别返回一个ziplist中指定数据项p的后一项和前一项。 ziplistInsert: 在ziplist的任意数据项前面插入一个新的数据项。 ziplistDelete: 删除指定的数据项。 ziplistFind: 查找给定的数据（由vstr和vlen指定）。注意它有一个skip参数，表示查找的时候每次比较之间要跳过几个数据项。为什么会有这么一个参数呢？其实这个参数的主要用途是当用ziplist表示hash结构的时候，是按照一个field，一个value来依次存入ziplist的。也就是说，偶数索引的数据项存field，奇数索引的数据项存value。当按照field的值进行查找的时候，就需要把奇数项跳过去。 ziplistLen: 计算ziplist的长度（即包含数据项的个数）。 hash与ziplisthash是Redis中可以用来存储一个对象结构的比较理想的数据类型。一个对象的各个属性，正好对应一个hash结构的各个field。 我们在网上很容易找到这样一些技术文章，它们会说存储一个对象，使用hash比string要节省内存。实际上这么说是有前提的，具体取决于对象怎么来存储。如果你把对象的多个属性存储到多个key上（各个属性值存成string），当然占的内存要多。但如果你采用一些序列化方法，比如Protocol Buffers，或者Apache Thrift，先把对象序列化为字节数组，然后再存入到Redis的string中，那么跟hash相比，哪一种更省内存，就不一定了。 当然，hash比序列化后再存入string的方式，在支持的操作命令上，还是有优势的：它既支持多个field同时存取（hmset/hmget），也支持按照某个特定的field单独存取（hset/hget）。 实际上，hash随着数据的增大，其底层数据结构的实现是会发生变化的，当然存储效率也就不同。在field比较少，各个value值也比较小的时候，hash采用ziplist来实现；而随着field增多和value值增大，hash可能会变成dict来实现。当hash底层变成dict来实现的时候，它的存储效率就没法跟那些序列化方式相比了。 当我们为某个key第一次执行 hset key field value 命令的时候，Redis会创建一个hash结构，这个新创建的hash底层就是一个ziplist。 123456robj *createHashObject(void) &#123; unsigned char *zl = ziplistNew(); robj *o = createObject(OBJ_HASH, zl); o-&gt;encoding = OBJ_ENCODING_ZIPLIST; return o;&#125; 上面的createHashObject函数，出自object.c，它负责的任务就是创建一个新的hash结构。可以看出，它创建了一个type = OBJ_HASH但encoding = OBJ_ENCODING_ZIPLIST的robj对象。 实际上，本文前面给出的那个ziplist实例，就是由如下两个命令构建出来的。 12hset user:100 name tieleihset user:100 age 20 每执行一次hset命令，插入的field和value分别作为一个新的数据项插入到ziplist中（即每次hset产生两个数据项）。 当随着数据的插入，hash底层的这个ziplist就可能会转成dict。那么到底插入多少才会转呢？ 还记得本文开头提到的两个Redis配置吗？ 12hash-max-ziplist-entries 512hash-max-ziplist-value 64 这个配置的意思是说，在如下两个条件之一满足的时候，ziplist会转成dict： 当hash中的数据项（即field-value对）的数目超过512的时候，也就是ziplist数据项超过1024的时候（请参考t_hash.c中的hashTypeSet函数）。 当hash中插入的任意一个value的长度超过了64的时候（请参考t_hash.c中的hashTypeTryConversion函数）。 Redis的hash之所以这样设计，是因为当ziplist变得很大的时候，它有如下几个缺点： 每次插入或修改引发的realloc操作会有更大的概率造成内存拷贝，从而降低性能。 一旦发生内存拷贝，内存拷贝的成本也相应增加，因为要拷贝更大的一块数据。 当ziplist数据项过多的时候，在它上面查找指定的数据项就会性能变得很低，因为ziplist上的查找需要进行遍历。 总之，ziplist本来就设计为各个数据项挨在一起组成连续的内存空间，这种结构并不擅长做修改操作。一旦数据发生改动，就会引发内存realloc，可能导致内存拷贝。","categories":[{"name":"中间件","slug":"中间件","permalink":"https://utinner.gitee.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://utinner.gitee.io/tags/redis/"}]},{"title":"redis内部数据结构(3)--robj","slug":"redis内部数据结构-3-robj","date":"2020-11-26T07:47:05.000Z","updated":"2021-12-06T09:23:00.874Z","comments":true,"path":"2020/11/26/redis内部数据结构-3-robj/","link":"","permalink":"https://utinner.gitee.io/2020/11/26/redis%E5%86%85%E9%83%A8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-3-robj/","excerpt":"从Redis的使用者的角度来看，一个Redis节点包含多个database（非cluster模式下默认是16个，cluster模式下只能是1个），而一个database维护了从key space到object space的映射关系。这个映射关系的key是string类型，而value可以是多种数据类型，比如：string, list, hash等。我们可以看到，key的类型固定是string，而value可能的类型是多个。 而从Redis内部实现的角度来看，在前面第一篇文章中，我们已经提到过，一个database内的这个映射关系是用一个dict来维护的。dict的key固定用一种数据结构来表达就够了，这就是动态字符串sds。而value则比较复杂，为了在同一个dict内能够存储不同类型的value，这就需要一个通用的数据结构，这个通用的数据结构就是robj（全名是redisObject）。举个例子：如果value是一个list，那么它的内部存储结构是一个quicklist；如果value是一个string，那么它的内部存储结构一般情况下是一个sds。当然实际情况更复杂一点，比如一个string类型的value，如果它的值是一个数字，那么Redis内部还会把它转成long型来存储，从而减小内存使用。而一个robj既能表示一个sds，也能表示一个quicklist，甚至还能表示一个long型。","text":"从Redis的使用者的角度来看，一个Redis节点包含多个database（非cluster模式下默认是16个，cluster模式下只能是1个），而一个database维护了从key space到object space的映射关系。这个映射关系的key是string类型，而value可以是多种数据类型，比如：string, list, hash等。我们可以看到，key的类型固定是string，而value可能的类型是多个。 而从Redis内部实现的角度来看，在前面第一篇文章中，我们已经提到过，一个database内的这个映射关系是用一个dict来维护的。dict的key固定用一种数据结构来表达就够了，这就是动态字符串sds。而value则比较复杂，为了在同一个dict内能够存储不同类型的value，这就需要一个通用的数据结构，这个通用的数据结构就是robj（全名是redisObject）。举个例子：如果value是一个list，那么它的内部存储结构是一个quicklist；如果value是一个string，那么它的内部存储结构一般情况下是一个sds。当然实际情况更复杂一点，比如一个string类型的value，如果它的值是一个数字，那么Redis内部还会把它转成long型来存储，从而减小内存使用。而一个robj既能表示一个sds，也能表示一个quicklist，甚至还能表示一个long型。 robj的数据结构定义在server.h中我们找到跟robj定义相关的代码，如下（注意，本系列文章中的代码片段全部来源于Redis源码的3.2分支）： 1234567891011121314151617181920212223242526272829/* Object types */#define OBJ_STRING 0#define OBJ_LIST 1#define OBJ_SET 2#define OBJ_ZSET 3#define OBJ_HASH 4/* Objects encoding. Some kind of objects like Strings and Hashes can be * internally represented in multiple ways. The &#x27;encoding&#x27; field of the object * is set to one of this fields for this object. */#define OBJ_ENCODING_RAW 0 /* Raw representation */#define OBJ_ENCODING_INT 1 /* Encoded as integer */#define OBJ_ENCODING_HT 2 /* Encoded as hash table */#define OBJ_ENCODING_ZIPMAP 3 /* Encoded as zipmap */#define OBJ_ENCODING_LINKEDLIST 4 /* Encoded as regular linked list */#define OBJ_ENCODING_ZIPLIST 5 /* Encoded as ziplist */#define OBJ_ENCODING_INTSET 6 /* Encoded as intset */#define OBJ_ENCODING_SKIPLIST 7 /* Encoded as skiplist */#define OBJ_ENCODING_EMBSTR 8 /* Embedded sds string encoding */#define OBJ_ENCODING_QUICKLIST 9 /* Encoded as linked list of ziplists */#define LRU_BITS 24typedef struct redisObject &#123; unsigned type:4; unsigned encoding:4; unsigned lru:LRU_BITS; /* lru time (relative to server.lruclock) */ int refcount; void *ptr;&#125; robj; 一个robj包含如下5个字段： type: 对象的数据类型。占4个bit。可能的取值有5种：OBJ_STRING, OBJ_LIST, OBJ_SET, OBJ_ZSET, OBJ_HASH，分别对应Redis对外暴露的5种数据结构（即我们在第一篇文章中提到的第一个层面的5种数据结构）。 encoding: 对象的内部表示方式（也可以称为编码）。占4个bit。可能的取值有10种，即前面代码中的10个OBJ_ENCODING_XXX常量。 lru: 做LRU替换算法用，占24个bit。这个不是我们这里讨论的重点，暂时忽略。 refcount: 引用计数。它允许robj对象在某些情况下被共享。 ptr: 数据指针。指向真正的数据。比如，一个代表string的robj，它的ptr可能指向一个sds结构；一个代表list的robj，它的ptr可能指向一个quicklist。 这里特别需要仔细察看的是encoding字段。对于同一个type，还可能对应不同的encoding，这说明同样的一个数据类型，可能存在不同的内部表示方式。而不同的内部表示，在内存占用和查找性能上会有所不同。比如，当type = OBJ_STRING的时候，表示这个robj存储的是一个string，这时encoding可以是下面3种中的一种： OBJ_ENCODING_RAW: string采用原生的表示方式，即用sds来表示。 OBJ_ENCODING_INT: string采用数字的表示方式，实际上是一个long型。 OBJ_ENCODING_EMBSTR: string采用一种特殊的嵌入式的sds来表示。 再举一个例子：当type = OBJ_HASH的时候，表示这个robj存储的是一个hash，这时encoding可以是下面2种中的一种： OBJ_ENCODING_HT: hash采用一个dict来表示。 OBJ_ENCODING_ZIPLIST: hash采用一个ziplist来表示（ziplist的具体实现我们放在后面的文章讨论）。 本文剩余主要部分将针对表示string的robj对象，围绕它的3种不同的encoding来深入讨论。前面代码段中出现的所有10种encoding，在这里我们先简单解释一下，在这个系列后面的文章中，我们应该还有机会碰到它们。 OBJ_ENCODING_RAW: 最原生的表示方式。其实只有string类型才会用这个encoding值（表示成sds）。 OBJ_ENCODING_INT: 表示成数字。实际用long表示。 OBJ_ENCODING_HT: 表示成dict。 OBJ_ENCODING_ZIPMAP: 是个旧的表示方式，已不再用。在小于Redis 2.6的版本中才有。 OBJ_ENCODING_LINKEDLIST: 也是个旧的表示方式，已不再用。 OBJ_ENCODING_ZIPLIST: 表示成ziplist。 OBJ_ENCODING_INTSET: 表示成intset。用于set数据结构。 OBJ_ENCODING_SKIPLIST: 表示成skiplist。用于sorted set数据结构。 OBJ_ENCODING_EMBSTR: 表示成一种特殊的嵌入式的sds。 OBJ_ENCODING_QUICKLIST: 表示成quicklist。用于list数据结构。 robj的作用： 为多种数据类型提供一种统一的表示方式。 允许同一类型的数据采用不同的内部表示，从而在某些情况下尽量节省内存。 支持对象共享和引用计数。当对象被共享的时候，只占用一份内存拷贝，进一步节省内存。 string robj的编码过程当我们执行Redis的set命令的时候，Redis首先将接收到的value值（string类型）表示成一个type = OBJ_STRING并且encoding = OBJ_ENCODING_RAW的robj对象，然后在存入内部存储之前先执行一个编码过程，试图将它表示成另一种更节省内存的encoding方式。这一过程的核心代码，是object.c中的tryObjectEncoding函数。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778robj *tryObjectEncoding(robj *o) &#123; long value; sds s = o-&gt;ptr; size_t len; /* Make sure this is a string object, the only type we encode * in this function. Other types use encoded memory efficient * representations but are handled by the commands implementing * the type. */ serverAssertWithInfo(NULL,o,o-&gt;type == OBJ_STRING); /* We try some specialized encoding only for objects that are * RAW or EMBSTR encoded, in other words objects that are still * in represented by an actually array of chars. */ if (!sdsEncodedObject(o)) return o; /* It&#x27;s not safe to encode shared objects: shared objects can be shared * everywhere in the &quot;object space&quot; of Redis and may end in places where * they are not handled. We handle them only as values in the keyspace. */ if (o-&gt;refcount &gt; 1) return o; /* Check if we can represent this string as a long integer. * Note that we are sure that a string larger than 21 chars is not * representable as a 32 nor 64 bit integer. */ len = sdslen(s); if (len &lt;= 21 &amp;&amp; string2l(s,len,&amp;value)) &#123; /* This object is encodable as a long. Try to use a shared object. * Note that we avoid using shared integers when maxmemory is used * because every object needs to have a private LRU field for the LRU * algorithm to work well. */ if ((server.maxmemory == 0 || (server.maxmemory_policy != MAXMEMORY_VOLATILE_LRU &amp;&amp; server.maxmemory_policy != MAXMEMORY_ALLKEYS_LRU)) &amp;&amp; value &gt;= 0 &amp;&amp; value &lt; OBJ_SHARED_INTEGERS) &#123; decrRefCount(o); incrRefCount(shared.integers[value]); return shared.integers[value]; &#125; else &#123; if (o-&gt;encoding == OBJ_ENCODING_RAW) sdsfree(o-&gt;ptr); o-&gt;encoding = OBJ_ENCODING_INT; o-&gt;ptr = (void*) value; return o; &#125; &#125; /* If the string is small and is still RAW encoded, * try the EMBSTR encoding which is more efficient. * In this representation the object and the SDS string are allocated * in the same chunk of memory to save space and cache misses. */ if (len &lt;= OBJ_ENCODING_EMBSTR_SIZE_LIMIT) &#123; robj *emb; if (o-&gt;encoding == OBJ_ENCODING_EMBSTR) return o; emb = createEmbeddedStringObject(s,sdslen(s)); decrRefCount(o); return emb; &#125; /* We can&#x27;t encode the object... * * Do the last try, and at least optimize the SDS string inside * the string object to require little space, in case there * is more than 10% of free space at the end of the SDS string. * * We do that only for relatively large strings as this branch * is only entered if the length of the string is greater than * OBJ_ENCODING_EMBSTR_SIZE_LIMIT. */ if (o-&gt;encoding == OBJ_ENCODING_RAW &amp;&amp; sdsavail(s) &gt; len/10) &#123; o-&gt;ptr = sdsRemoveFreeSpace(o-&gt;ptr); &#125; /* Return the original object. */ return o;&#125; 这段代码执行的操作比较复杂，我们有必要仔细看一下每一步的操作： 第1步检查，检查type。确保只对string类型的对象进行操作。 第2步检查，检查encoding。sdsEncodedObject是定义在server.h中的一个宏，确保只对OBJ_ENCODING_RAW和OBJ_ENCODING_EMBSTR编码的string对象进行操作。这两种编码的string都采用sds来存储，可以尝试进一步编码处理。 第3步检查，检查refcount。引用计数大于1的共享对象，在多处被引用。由于编码过程结束后robj的对象指针可能会变化（我们在前一篇介绍sdscatlen函数的时候提到过类似这种接口使用模式），这样对于引用计数大于1的对象，就需要更新所有地方的引用，这不容易做到。因此，对于计数大于1的对象不做编码处理。 试图将字符串转成64位的long。64位的long所能表达的数据范围是-2^63到2^63-1，用十进制表达出来最长是20位数（包括负号）。这里判断小于等于21，似乎是写多了，实际判断小于等于20就够了（如果我算错了请一定告诉我哦）。string2l如果将字符串转成long转成功了，那么会返回1并且将转好的long存到value变量里。 在转成long成功时，又分为两种情况。 第一种情况：如果Redis的配置不要求运行LRU替换算法，且转成的long型数字的值又比较小（小于OBJ_SHARED_INTEGERS，在目前的实现中这个值是10000），那么会使用共享数字对象来表示。之所以这里的判断跟LRU有关，是因为LRU算法要求每个robj有不同的lru字段值，所以用了LRU就不能共享robj。shared.integers是一个长度为10000的数组，里面预存了10000个小的数字对象。这些小数字对象都是encoding = OBJ_ENCODING_INT的string robj对象。 第二种情况：如果前一步不能使用共享小对象来表示，那么将原来的robj编码成encoding = OBJ_ENCODING_INT，这时ptr字段直接存成这个long型的值。注意ptr字段本来是一个void *指针（即存储的是内存地址），因此在64位机器上有64位宽度，正好能存储一个64位的long型值。这样，除了robj本身之外，它就不再需要额外的内存空间来存储字符串值。 接下来是对于那些不能转成64位long的字符串进行处理。最后再做两步处理： 如果字符串长度足够小（小于等于OBJ_ENCODING_EMBSTR_SIZE_LIMIT，定义为44），那么调用createEmbeddedStringObject编码成encoding = OBJ_ENCODING_EMBSTR； 如果前面所有的编码尝试都没有成功（仍然是OBJ_ENCODING_RAW），且sds里空余字节过多，那么做最后一次努力，调用sds的sdsRemoveFreeSpace接口来释放空余字节。 其中调用的createEmbeddedStringObject，我们有必要看一下它的代码： 123456789101112131415161718192021robj *createEmbeddedStringObject(const char *ptr, size_t len) &#123; robj *o = zmalloc(sizeof(robj)+sizeof(struct sdshdr8)+len+1); struct sdshdr8 *sh = (void*)(o+1); o-&gt;type = OBJ_STRING; o-&gt;encoding = OBJ_ENCODING_EMBSTR; o-&gt;ptr = sh+1; o-&gt;refcount = 1; o-&gt;lru = LRU_CLOCK(); sh-&gt;len = len; sh-&gt;alloc = len; sh-&gt;flags = SDS_TYPE_8; if (ptr) &#123; memcpy(sh-&gt;buf,ptr,len); sh-&gt;buf[len] = &#x27;\\0&#x27;; &#125; else &#123; memset(sh-&gt;buf,0,len+1); &#125; return o;&#125; createEmbeddedStringObject对sds重新分配内存，将robj和sds放在一个连续的内存块中分配，这样对于短字符串的存储有利于减少内存碎片。这个连续的内存块包含如下几部分： 16个字节的robj结构。 3个字节的sdshdr8头。 最多44个字节的sds字符数组。 1个NULL结束符。 加起来一共不超过64字节（16+3+44+1），因此这样的一个短字符串可以完全分配在一个64字节长度的内存块中。 string robj的解码过程当我们需要获取字符串的值，比如执行get命令的时候，我们需要执行与前面讲的编码过程相反的操作——解码。 这一解码过程的核心代码，是object.c中的getDecodedObject函数。 1234567891011121314151617robj *getDecodedObject(robj *o) &#123; robj *dec; if (sdsEncodedObject(o)) &#123; incrRefCount(o); return o; &#125; if (o-&gt;type == OBJ_STRING &amp;&amp; o-&gt;encoding == OBJ_ENCODING_INT) &#123; char buf[32]; ll2string(buf,32,(long)o-&gt;ptr); dec = createStringObject(buf,strlen(buf)); return dec; &#125; else &#123; serverPanic(&quot;Unknown encoding type&quot;); &#125;&#125; 这个过程比较简单，需要我们注意的点有： 编码为OBJ_ENCODING_RAW和OBJ_ENCODING_EMBSTR的字符串robj对象，不做变化，原封不动返回。站在使用者的角度，这两种编码没有什么区别，内部都是封装的sds。 编码为数字的字符串robj对象，将long重新转为十进制字符串的形式，然后调用createStringObject转为sds的表示。注意：这里由long转成的sds字符串长度肯定不超过20，而根据createStringObject的实现，它们肯定会被编码成OBJ_ENCODING_EMBSTR的对象。createStringObject的代码如下：123456robj *createStringObject(const char *ptr, size_t len) &#123; if (len &lt;= OBJ_ENCODING_EMBSTR_SIZE_LIMIT) return createEmbeddedStringObject(ptr,len); else return createRawStringObject(ptr,len);&#125; 再谈sds与string的关系在上一篇文章中，我们简单地提到了sds与string的关系；在本文介绍了robj的概念之后，我们重新总结一下sds与string的关系。 确切地说，string在Redis中是用一个robj来表示的。 用来表示string的robj可能编码成3种内部表示：OBJ_ENCODING_RAW, OBJ_ENCODING_EMBSTR, OBJ_ENCODING_INT。其中前两种编码使用的是sds来存储，最后一种OBJ_ENCODING_INT编码直接把string存成了long型。 在对string进行incr, decr等操作的时候，如果它内部是OBJ_ENCODING_INT编码，那么可以直接进行加减操作；如果它内部是OBJ_ENCODING_RAW或OBJ_ENCODING_EMBSTR编码，那么Redis会先试图把sds存储的字符串转成long型，如果能转成功，再进行加减操作。 对一个内部表示成long型的string执行append, setbit, getrange这些命令，针对的仍然是string的值（即十进制表示的字符串），而不是针对内部表示的long型进行操作。比如字符串”32”，如果按照字符数组来解释，它包含两个字符，它们的ASCII码分别是0x33和0x32。当我们执行命令setbit key 7 0的时候，相当于把字符0x33变成了0x32，这样字符串的值就变成了”22”。而如果将字符串”32”按照内部的64位long型来解释，那么它是0x0000000000000020，在这个基础上执行setbit位操作，结果就完全不对了。因此，在这些命令的实现中，会把long型先转成字符串再进行相应的操作。由于篇幅原因，这三个命令的实现代码这里就不详细介绍了，有兴趣的读者可以参考Redis源码： t_string.c中的appendCommand函数； biops.c中的setbitCommand函数； t_string.c中的getrangeCommand函数。 值得一提的是，append和setbit命令的实现中，都会最终调用到db.c中的dbUnshareStringValue函数，将string对象的内部编码转成OBJ_ENCODING_RAW的（只有这种编码的robj对象，其内部的sds 才能在后面自由追加新的内容），并解除可能存在的对象共享状态。这里面调用了前面提到的getDecodedObject。 12345678910robj *dbUnshareStringValue(redisDb *db, robj *key, robj *o) &#123; serverAssert(o-&gt;type == OBJ_STRING); if (o-&gt;refcount != 1 || o-&gt;encoding != OBJ_ENCODING_RAW) &#123; robj *decoded = getDecodedObject(o); o = createRawStringObject(decoded-&gt;ptr, sdslen(decoded-&gt;ptr)); decrRefCount(decoded); dbOverwrite(db,key,o); &#125; return o;&#125; robj的引用计数操作将robj的引用计数加1和减1的操作，定义在object.c中： 1234567891011121314151617181920void incrRefCount(robj *o) &#123; o-&gt;refcount++;&#125;void decrRefCount(robj *o) &#123; if (o-&gt;refcount &lt;= 0) serverPanic(&quot;decrRefCount against refcount &lt;= 0&quot;); if (o-&gt;refcount == 1) &#123; switch(o-&gt;type) &#123; case OBJ_STRING: freeStringObject(o); break; case OBJ_LIST: freeListObject(o); break; case OBJ_SET: freeSetObject(o); break; case OBJ_ZSET: freeZsetObject(o); break; case OBJ_HASH: freeHashObject(o); break; default: serverPanic(&quot;Unknown object type&quot;); break; &#125; zfree(o); &#125; else &#123; o-&gt;refcount--; &#125;&#125; 我们特别关注一下将引用计数减1的操作decrRefCount。如果只剩下最后一个引用了（refcount已经是1了），那么在decrRefCount被调用后，整个robj将被释放。 注意：Redis的del命令就依赖decrRefCount操作将value释放掉。 经过了本文的讨论，我们很容易看出，robj所表示的就是Redis对外暴露的第一层面的数据结构：string, list, hash, set, sorted set，而每一种数据结构的底层实现所对应的是哪个（或哪些）第二层面的数据结构（dict, sds, ziplist, quicklist, skiplist, 等），则通过不同的encoding来区分。可以说，robj是联结两个层面的数据结构的桥梁。 本文详细介绍了OBJ_STRING类型的字符串对象的底层实现，其编码和解码过程在Redis里非常重要，应用广泛，我们在后面的讨论中可能还会遇到。现在有了robj的概念基础，我们下一篇会讨论ziplist，以及它与hash的关系。","categories":[{"name":"中间件","slug":"中间件","permalink":"https://utinner.gitee.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://utinner.gitee.io/tags/redis/"}]},{"title":"redis内部数据结构(2)--sds","slug":"redis内部数据结构-2-sds","date":"2020-11-26T06:56:41.000Z","updated":"2021-12-06T09:23:00.872Z","comments":true,"path":"2020/11/26/redis内部数据结构-2-sds/","link":"","permalink":"https://utinner.gitee.io/2020/11/26/redis%E5%86%85%E9%83%A8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-2-sds/","excerpt":"不管在哪门编程语言当中，字符串都几乎是使用最多的数据结构。sds正是在Redis中被广泛使用的字符串结构，它的全称是Simple Dynamic String。与其它语言环境中出现的字符串相比，它具有如下显著的特点： 可动态扩展内存。sds表示的字符串其内容可以修改，也可以追加。在很多语言中字符串会分为mutable和immutable两种，显然sds属于mutable类型的。 二进制安全（Binary Safe）。sds能存储任意二进制数据，而不仅仅是可打印字符。 与传统的C语言字符串类型兼容","text":"不管在哪门编程语言当中，字符串都几乎是使用最多的数据结构。sds正是在Redis中被广泛使用的字符串结构，它的全称是Simple Dynamic String。与其它语言环境中出现的字符串相比，它具有如下显著的特点： 可动态扩展内存。sds表示的字符串其内容可以修改，也可以追加。在很多语言中字符串会分为mutable和immutable两种，显然sds属于mutable类型的。 二进制安全（Binary Safe）。sds能存储任意二进制数据，而不仅仅是可打印字符。 与传统的C语言字符串类型兼容 看到这里，很多对Redis有所了解的同学可能已经产生了一个疑问：Redis已经对外暴露了一个字符串结构，叫做string，那这里所说的sds到底和string是什么关系呢？可能有人会猜：string是基于sds实现的。这个猜想已经非常接近事实，但在描述上还不太准确。有关string和sds之间关系的详细分析，我们放在后面再讲。现在为了方便讨论，让我们先暂时简单地认为，string的底层实现就是sds。 在讨论sds的具体实现之前，我们先站在Redis使用者的角度，来观察一下string所支持的一些主要操作。下面是一个操作示例： 以上这些操作都比较简单，我们简单解释一下： 初始的字符串的值设为”tinner”。 第3步通过append命令对字符串进行了追加，变成了”tinner jin”。 然后通过setbit命令将第53个bit设置成了1。bit的偏移量从左边开始算，从0开始。其中第48～55bit是中间的空格那个字符，它的ASCII码是0x20。将第53个bit设置成1之后，它的ASCII码变成了0x24，打印出来就是’$’。因此，- 现在字符串的值变成了”tinneri$jin”。 最后通过getrange取从倒数第3个字节到倒数第1个字节的内容，得到”jin”。 这些命令的实现，有一部分是和sds的实现有关的。下面我们开始详细讨论。 sds的数据结构定义我们知道，在C语言中，字符串是以’\\0’字符结尾（NULL结束符）的字符数组来存储的，通常表达为字符指针的形式（char *）。它不允许字节0出现在字符串中间，因此，它不能用来存储任意的二进制数据。 我们可以在sds.h中找到sds的类型定义： 1typedef char *sds; 肯定有人感到困惑了，竟然sds就等同于char *？我们前面提到过，sds和传统的C语言字符串保持类型兼容，因此它们的类型定义是一样的，都是char *。在有些情况下，需要传入一个C语言字符串的地方，也确实可以传入一个sds。但是，sds和char *并不等同。sds是Binary Safe的，它可以存储任意二进制数据，不能像C语言字符串那样以字符’\\0’来标识字符串的结束，因此它必然有个长度字段。但这个长度字段在哪里呢？实际上sds还包含一个header结构： 12345678910111213141516171819202122232425262728struct __attribute__ ((__packed__)) sdshdr5 &#123; unsigned char flags; /* 3 lsb of type, and 5 msb of string length */ char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr8 &#123; uint8_t len; /* used */ uint8_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr16 &#123; uint16_t len; /* used */ uint16_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr32 &#123; uint32_t len; /* used */ uint32_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr64 &#123; uint64_t len; /* used */ uint64_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];&#125;; sds一共有5种类型的header。之所以有5种，是为了能让不同长度的字符串可以使用不同大小的header。这样，短字符串就能使用较小的header，从而节省内存。 一个sds字符串的完整结构，由在内存地址上前后相邻的两部分组成： 一个header。通常包含字符串的长度(len)、最大容量(alloc)和flags。sdshdr5有所不同。 一个字符数组。这个字符数组的长度等于最大容量+1。真正有效的字符串数据，其长度通常小于最大容量。在真正的字符串数据之后，是空余未用的字节（一般以字节0填充），允许在不重新分配内存的前提下让字符串数据向后做有限的扩展。在真正的字符串数据之后，还有一个NULL结束符，即ASCII码为0的’\\0’字符。这是为了和传统C字符串兼容。之所以字符数组的长度比最大容量多1个字节，就是为了在字符串长度达到最大容量时仍然有1个字节存放NULL结束符。 除了sdshdr5之外，其它4个header的结构都包含3个字段： len: 表示字符串的真正长度（不包含NULL结束符在内）。 alloc: 表示字符串的最大容量（不包含最后多余的那个字节）。 flags: 总是占用一个字节。其中的最低3个bit用来表示header的类型。header的类型共有5种，在sds.h中有常量定义。 #define SDS_TYPE_5 0#define SDS_TYPE_8 1#define SDS_TYPE_16 2#define SDS_TYPE_32 3#define SDS_TYPE_64 4 sds的数据结构，我们有必要非常仔细地去解析它。 上图是sds的一个内部结构的例子。图中展示了两个sds字符串s1和s2的内存结构，一个使用sdshdr8类型的header，另一个使用sdshdr16类型的header。但它们都表达了同样的一个长度为6的字符串的值：”tielei”。下面我们结合代码，来解释每一部分的组成。 sds的字符指针（s1和s2）就是指向真正的数据（字符数组）开始的位置，而header位于内存地址较低的方向。在sds.h中有一些跟解析header有关的宏定义： #define SDS_TYPE_MASK 7#define SDS_TYPE_BITS 3#define SDS_HDR_VAR(T,s) struct sdshdr##T sh = (void)((s)-(sizeof(struct sdshdr##T)));#define SDS_HDR(T,s) ((struct sdshdr##T *)((s)-(sizeof(struct sdshdr##T))))#define SDS_TYPE_5_LEN(f) ((f)&gt;&gt;SDS_TYPE_BITS) 其中SDS_HDR用来从sds字符串获得header起始位置的指针，比如SDS_HDR(8, s1)表示s1的header指针，SDS_HDR(16, s2)表示s2的header指针。 当然，使用SDS_HDR之前我们必须先知道到底是哪一种header，这样我们才知道SDS_HDR第1个参数应该传什么。由sds字符指针获得header类型的方法是，先向低地址方向偏移1个字节的位置，得到flags字段。比如，s1[-1]和s2[-1]分别获得了s1和s2的flags的值。然后取flags的最低3个bit得到header的类型。 由于s1[-1] == 0x01 == SDS_TYPE_8，因此s1的header类型是sdshdr8。 由于s2[-1] == 0x02 == SDS_TYPE_16，因此s2的header类型是sdshdr16。 有了header指针，就能很快定位到它的len和alloc字段： s1的header中，len的值为0x06，表示字符串数据长度为6；alloc的值为0x80，表示字符数组最大容量为128。 s2的header中，len的值为0x0006，表示字符串数据长度为6；alloc的值为0x03E8，表示字符数组最大容量为1000。（注意：图中是按小端地址构成） 在各个header的类型定义中，还有几个需要我们注意的地方： 在各个header的定义中使用了__attribute__ ((packed))，是为了让编译器以紧凑模式来分配内存。如果没有这个属性，编译器可能会为struct的字段做优化对齐，在其中填充空字节。那样的话，就不能保证header和sds的数据部分紧紧前后相邻，也不能按照固定向低地址方向偏移1个字节的方式来获取flags字段了。 在各个header的定义中最后有一个char buf[]。我们注意到这是一个没有指明长度的字符数组，这是C语言中定义字符数组的一种特殊写法，称为柔性数组（flexible array member），只能定义在一个结构体的最后一个字段上。它在这里只是起到一个标记的作用，表示在flags字段后面就是一个字符数组，或者说，它指明了紧跟在flags字段后面的这个字符数组在结构体中的偏移位置。而程序在为header分配的内存的时候，它并不占用内存空间。如果计算sizeof(struct sdshdr16)的值，那么结果是5个字节，其中没有buf字段。 sdshdr5与其它几个header结构不同，它不包含alloc字段，而长度使用flags的高5位来存储。因此，它不能为字符串分配空余空间。如果字符串需要动态增长，那么它就必然要重新分配内存才行。所以说，这种类型的sds字符串更适合存储静态的短字符串（长度小于32）。 至此，我们非常清楚地看到了：sds字符串的header，其实隐藏在真正的字符串数据的前面（低地址方向）。这样的一个定义，有如下几个好处： header和数据相邻，而不用分成两块内存空间来单独分配。这有利于减少内存碎片，提高存储效率（memory efficiency）。 虽然header有多个类型，但sds可以用统一的char *来表达。且它与传统的C语言字符串保持类型兼容。如果一个sds里面存储的是可打印字符串，那么我们可以直接把它传给C函数，比如使用strcmp比较字符串大小，或者使用printf进行打印。弄清了sds的数据结构，它的具体操作函数就比较好理解了。 sds的一些基础函数 sdslen(const sds s): 获取sds字符串长度。 sdssetlen(sds s, size_t newlen): 设置sds字符串长度。 sdsinclen(sds s, size_t inc): 增加sds字符串长度。 sdsalloc(const sds s): 获取sds字符串容量。 sdssetalloc(sds s, size_t newlen): 设置sds字符串容量。 sdsavail(const sds s): 获取sds字符串空余空间（即alloc - len）。 sdsHdrSize(char type): 根据header类型得到header大小。 sdsReqType(size_t string_size): 根据字符串数据长度计算所需要的header类型。 这里我们挑选sdslen和sdsReqType的代码，察看一下。 12345678910111213141516171819202122232425262728static inline size_t sdslen(const sds s) &#123; unsigned char flags = s[-1]; switch(flags&amp;SDS_TYPE_MASK) &#123; case SDS_TYPE_5: return SDS_TYPE_5_LEN(flags); case SDS_TYPE_8: return SDS_HDR(8,s)-&gt;len; case SDS_TYPE_16: return SDS_HDR(16,s)-&gt;len; case SDS_TYPE_32: return SDS_HDR(32,s)-&gt;len; case SDS_TYPE_64: return SDS_HDR(64,s)-&gt;len; &#125; return 0;&#125;static inline char sdsReqType(size_t string_size) &#123; if (string_size &lt; 1&lt;&lt;5) return SDS_TYPE_5; if (string_size &lt; 1&lt;&lt;8) return SDS_TYPE_8; if (string_size &lt; 1&lt;&lt;16) return SDS_TYPE_16; if (string_size &lt; 1ll&lt;&lt;32) return SDS_TYPE_32; return SDS_TYPE_64;&#125; 跟前面的分析类似，sdslen先用s[-1]向低地址方向偏移1个字节，得到flags；然后与SDS_TYPE_MASK进行按位与，得到header类型；然后根据不同的header类型，调用SDS_HDR得到header起始指针，进而获得len字段。 通过sdsReqType的代码，很容易看到： 长度在0和2^5-1之间，选用SDS_TYPE_5类型的header。 长度在2^5和2^8-1之间，选用SDS_TYPE_8类型的header。 长度在2^8和2^16-1之间，选用SDS_TYPE_16类型的header。 长度在2^16和2^32-1之间，选用SDS_TYPE_32类型的header。 长度大于2^32的，选用SDS_TYPE_64类型的header。能表示的最大长度为2^64-1。 注：sdsReqType的实现代码，直到3.2.0，它在长度边界值上都一直存在问题，直到最近3.2 branch上的commit 6032340才修复。 sds的创建和销毁123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869sds sdsnewlen(const void *init, size_t initlen) &#123; void *sh; sds s; char type = sdsReqType(initlen); /* Empty strings are usually created in order to append. Use type 8 * since type 5 is not good at this. */ if (type == SDS_TYPE_5 &amp;&amp; initlen == 0) type = SDS_TYPE_8; int hdrlen = sdsHdrSize(type); unsigned char *fp; /* flags pointer. */ sh = s_malloc(hdrlen+initlen+1); if (!init) memset(sh, 0, hdrlen+initlen+1); if (sh == NULL) return NULL; s = (char*)sh+hdrlen; fp = ((unsigned char*)s)-1; switch(type) &#123; case SDS_TYPE_5: &#123; *fp = type | (initlen &lt;&lt; SDS_TYPE_BITS); break; &#125; case SDS_TYPE_8: &#123; SDS_HDR_VAR(8,s); sh-&gt;len = initlen; sh-&gt;alloc = initlen; *fp = type; break; &#125; case SDS_TYPE_16: &#123; SDS_HDR_VAR(16,s); sh-&gt;len = initlen; sh-&gt;alloc = initlen; *fp = type; break; &#125; case SDS_TYPE_32: &#123; SDS_HDR_VAR(32,s); sh-&gt;len = initlen; sh-&gt;alloc = initlen; *fp = type; break; &#125; case SDS_TYPE_64: &#123; SDS_HDR_VAR(64,s); sh-&gt;len = initlen; sh-&gt;alloc = initlen; *fp = type; break; &#125; &#125; if (initlen &amp;&amp; init) memcpy(s, init, initlen); s[initlen] = &#x27;\\0&#x27;; return s;&#125;sds sdsempty(void) &#123; return sdsnewlen(&quot;&quot;,0);&#125;sds sdsnew(const char *init) &#123; size_t initlen = (init == NULL) ? 0 : strlen(init); return sdsnewlen(init, initlen);&#125;void sdsfree(sds s) &#123; if (s == NULL) return; s_free((char*)s-sdsHdrSize(s[-1]));&#125; sdsnewlen创建一个长度为initlen的sds字符串，并使用init指向的字符数组（任意二进制数据）来初始化数据。如果init为NULL，那么使用全0来初始化数据。它的实现中，我们需要注意的是： 如果要创建一个长度为0的空字符串，那么不使用SDS_TYPE_5类型的header，而是转而使用SDS_TYPE_8类型的header。这是因为创建的空字符串一般接下来的操作很可能是追加数据，但SDS_TYPE_5类型的sds字符串不适合追加数据（会引发内存重新分配）。 需要的内存空间一次性进行分配，其中包含三部分：header、数据、最后的多余字节（hdrlen+initlen+1）。 初始化的sds字符串数据最后会追加一个NULL结束符（s[initlen] = ‘\\0’）。 关于sdsfree，需要注意的是：内存要整体释放，所以要先计算出header起始指针，把它传给s_free函数。这个指针也正是在sdsnewlen中调用s_malloc返回的那个地址。 sds的连接（追加）操作123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263sds sdscatlen(sds s, const void *t, size_t len) &#123; size_t curlen = sdslen(s); s = sdsMakeRoomFor(s,len); if (s == NULL) return NULL; memcpy(s+curlen, t, len); sdssetlen(s, curlen+len); s[curlen+len] = &#x27;\\0&#x27;; return s;&#125;sds sdscat(sds s, const char *t) &#123; return sdscatlen(s, t, strlen(t));&#125;sds sdscatsds(sds s, const sds t) &#123; return sdscatlen(s, t, sdslen(t));&#125;sds sdsMakeRoomFor(sds s, size_t addlen) &#123; void *sh, *newsh; size_t avail = sdsavail(s); size_t len, newlen; char type, oldtype = s[-1] &amp; SDS_TYPE_MASK; int hdrlen; /* Return ASAP if there is enough space left. */ if (avail &gt;= addlen) return s; len = sdslen(s); sh = (char*)s-sdsHdrSize(oldtype); newlen = (len+addlen); if (newlen &lt; SDS_MAX_PREALLOC) newlen *= 2; else newlen += SDS_MAX_PREALLOC; type = sdsReqType(newlen); /* Don&#x27;t use type 5: the user is appending to the string and type 5 is * not able to remember empty space, so sdsMakeRoomFor() must be called * at every appending operation. */ if (type == SDS_TYPE_5) type = SDS_TYPE_8; hdrlen = sdsHdrSize(type); if (oldtype==type) &#123; newsh = s_realloc(sh, hdrlen+newlen+1); if (newsh == NULL) return NULL; s = (char*)newsh+hdrlen; &#125; else &#123; /* Since the header size changes, need to move the string forward, * and can&#x27;t use realloc */ newsh = s_malloc(hdrlen+newlen+1); if (newsh == NULL) return NULL; memcpy((char*)newsh+hdrlen, s, len+1); s_free(sh); s = (char*)newsh+hdrlen; s[-1] = type; sdssetlen(s, len); &#125; sdssetalloc(s, newlen); return s;&#125; sdscatlen将t指向的长度为len的任意二进制数据追加到sds字符串s的后面。本文开头演示的string的append命令，内部就是调用sdscatlen来实现的。 在sdscatlen的实现中，先调用sdsMakeRoomFor来保证字符串s有足够的空间来追加长度为len的数据。sdsMakeRoomFor可能会分配新的内存，也可能不会。 sdsMakeRoomFor是sds实现中很重要的一个函数。关于它的实现代码，我们需要注意的是： 如果原来字符串中的空余空间够用（avail &gt;= addlen），那么它什么也不做，直接返回。 如果需要分配空间，它会比实际请求的要多分配一些，以防备接下来继续追加。它在字符串已经比较长的情况下要至少多分配SDS_MAX_PREALLOC个字节，这个常量在sds.h中定义为(1024*1024)=1MB。 按分配后的空间大小，可能需要更换header类型（原来header的alloc字段太短，表达不了增加后的容量）。 如果需要更换header，那么整个字符串空间（包括header）都需要重新分配（s_malloc），并拷贝原来的数据到新的位置。 如果不需要更换header（原来的header够用），那么调用一个比较特殊的s_realloc，试图在原来的地址上重新分配空间。s_realloc的具体实现得看Redis编译的时候选用了哪个allocator（在Linux上默认使用jemalloc）。但不管是哪个realloc的实现，它所表达的含义基本是相同的：它尽量在原来分配好的地址位置重新分配，如果原来的地址位置有足够的空余空间完成重新分配，那么它返回的新地址与传入的旧地址相同；否则，它分配新的地址块，并进行数据搬迁。参见(http://man.cx/realloc)[http://man.cx/realloc]。 从sdscatlen的函数接口，我们可以看到一种使用模式：调用它的时候，传入一个旧的sds变量，然后它返回一个新的sds变量。由于它的内部实现可能会造成地址变化，因此调用者在调用完之后，原来旧的变量就失效了，而都应该用新返回的变量来替换。不仅仅是sdscatlen函数，sds中的其它函数（比如sdscpy、sdstrim、sdsjoin等），还有Redis中其它一些能自动扩展内存的数据结构（如ziplist），也都是同样的使用模式。 浅谈sds与string的关系现在我们回过头来看看本文开头给出的string操作的例子。 append操作使用sds的sdscatlen来实现。前面已经提到。 setbit和getrange都是先根据key取到整个sds字符串，然后再从字符串选取或修改指定的部分。由于sds就是一个字符数组，所以对它的某一部分进行操作似乎都比较简单。 但是，string除了支持这些操作之外，当它存储的值是个数字的时候，它还支持incr、decr等操作。那么，当string存储数字值的时候，它的内部存储还是sds吗？实际上，不是了。而且，这种情况下，setbit和getrange的实现也会有所不同。这些细节，我们放在下一篇介绍robj的时候再进行系统地讨论。","categories":[{"name":"中间件","slug":"中间件","permalink":"https://utinner.gitee.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://utinner.gitee.io/tags/redis/"}]},{"title":"redis内部数据结构(1)--dist","slug":"redis内部数据结构-1-dist","date":"2020-11-26T06:22:02.000Z","updated":"2021-12-06T09:23:00.870Z","comments":true,"path":"2020/11/26/redis内部数据结构-1-dist/","link":"","permalink":"https://utinner.gitee.io/2020/11/26/redis%E5%86%85%E9%83%A8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-1-dist/","excerpt":"当我们提到Redis的“数据结构”的时候，可能是在两个不同的层面来讨论它 第一个层面，是从使用者的角度，分为了5个数据结构 String List Hash Set Sorted set 第一个层面也是Redis暴露给外部提供的接口","text":"当我们提到Redis的“数据结构”的时候，可能是在两个不同的层面来讨论它 第一个层面，是从使用者的角度，分为了5个数据结构 String List Hash Set Sorted set 第一个层面也是Redis暴露给外部提供的接口 第二个层面，是从内部实现的角度，属于更底层的实现。比如： dict sds ziplist quicklist skiplist 本文的重点在于讨论第二个层面，Redis数据结构的内部实现，以及这两个层面的数据结构之间的关系：Redis如何通过组合第二个层面的各种基础数据结构来实现第一个层面的更高层的数据结构。 在讨论任何一个系统的内部实现的时候，我们都要先明确它的设计原则，这样我们才能更深刻地理解它为什么会进行如此设计的真正意图。在本文接下来的讨论中，我们主要关注以下几点： 存储效率（memory efficiency）。Redis是专用于存储数据的，它对于计算机资源的主要消耗就在于内存，因此节省内存是它非常非常重要的一个方面。这意味着Redis一定是非常精细地考虑了压缩数据、减少内存碎片等问题。 快速响应时间（fast response time）。与快速响应时间相对的，是高吞吐量（high throughput）。Redis是用于提供在线访问的，对于单个请求的响应时间要求很高，因此，快速响应时间是比高吞吐量更重要的目标。有时候，这两个目标是矛盾的。 单线程（single-threaded）。Redis的性能瓶颈不在于CPU资源，而在于内存访问和网络IO。而采用单线程的设计带来的好处是，极大简化了数据结构和算法的实现。相反，Redis通过异步IO和pipelining等机制来实现高速的并发访问。显然，单线程的设计，对于单个请求的快速响应时间也提出了更高的要求。 distdict是一个用于维护key和value映射关系的数据结构，与很多语言中的Map或dictionary类似。Redis的一个database中所有key到value的映射，就是使用一个dict来维护的。不过，这只是它在Redis中的一个用途而已，它在Redis中被使用的地方还有很多。比如，一个Redis hash结构，当它的field较多时，便会采用dict来存储。再比如，Redis配合使用dict和skiplist来共同维护一个sorted set。这些细节我们后面再讨论，在本文中，我们集中精力讨论dict本身的实现。 dict本质上是为了解决算法中的查找问题（Searching），一般查找问题的解法分为两个大类：一个是基于各种平衡树，一个是基于哈希表。我们平常使用的各种Map或dictionary，大都是基于哈希表实现的。在不要求数据有序存储，且能保持较低的哈希值冲突概率的前提下，基于哈希表的查找性能能做到非常高效，接近O(1)，而且实现简单。 在Redis中，dict也是一个基于哈希表的算法。和传统的哈希算法类似，它采用某个哈希函数从key计算得到在哈希表中的位置，采用拉链法解决冲突，并在装载因子（load factor）超过预定值时自动扩展内存，引发重哈希（rehashing）。Redis的dict实现最显著的一个特点，就在于它的重哈希。它采用了一种称为增量式重哈希（incremental rehashing）的方法，在需要扩展内存时避免一次性对所有key进行重哈希，而是将重哈希操作分散到对于dict的各个增删改查的操作中去。这种方法能做到每次只对一小部分key进行重哈希，而每次重哈希之间不影响dict的操作。dict之所以这样设计，是为了避免重哈希期间单个请求的响应时间剧烈增加，这与前面提到的“快速响应时间”的设计原则是相符的。 dict的数据结构定义为了实现增量式重哈希（incremental rehashing），dict的数据结构里包含两个哈希表。在重哈希期间，数据从第一个哈希表向第二个哈希表迁移。 dict的C代码定义如下（出自Redis源码dict.h）： 123456789101112131415161718192021222324252627282930313233343536typedef struct dictEntry &#123; void *key; union &#123; void *val; uint64_t u64; int64_t s64; double d; &#125; v; struct dictEntry *next;&#125; dictEntry;typedef struct dictType &#123; unsigned int (*hashFunction)(const void *key); void *(*keyDup)(void *privdata, const void *key); void *(*valDup)(void *privdata, const void *obj); int (*keyCompare)(void *privdata, const void *key1, const void *key2); void (*keyDestructor)(void *privdata, void *key); void (*valDestructor)(void *privdata, void *obj);&#125; dictType;/* This is our hash table structure. Every dictionary has two of this as we * implement incremental rehashing, for the old to the new table. */typedef struct dictht &#123; dictEntry **table; unsigned long size; unsigned long sizemask; unsigned long used;&#125; dictht;typedef struct dict &#123; dictType *type; void *privdata; dictht ht[2]; long rehashidx; /* rehashing not in progress if rehashidx == -1 */ int iterators; /* number of iterators currently running */&#125; dict; 为了能更清楚地展示dict的数据结构定义，我们用一张结构图来表示它。如下: 一个dict由如下若干项组成： 一个指向dictType结构的指针（type）。它通过自定义的方式使得dict的key和value能够存储任何类型的数据。 一个私有数据指针（privdata）。由调用者在创建dict的时候传进来。 两个哈希表（ht[2]）。只有在重哈希的过程中，ht[0]和ht[1]才都有效。而在平常情况下，只有ht[0]有效，ht[1]里面没有任何数据。上图表示的就是重哈希进行到中间某一步时的情况。 当前重哈希索引（rehashidx）。如果rehashidx = -1，表示当前没有在重哈希过程中；否则，表示当前正在进行重哈希，且它的值记录了当前重哈希进行到哪一步了。 当前正在进行遍历的iterator的个数。这不是我们现在讨论的重点，暂时忽略。 dictType结构包含若干函数指针，用于dict的调用者对涉及key和value的各种操作进行自定义。这些操作包含： hashFunction，对key进行哈希值计算的哈希算法。 keyDup和valDup，分别定义key和value的拷贝函数，用于在需要的时候对key和value进行深拷贝，而不仅仅是传递对象指针。 keyCompare，定义两个key的比较操作，在根据key进行查找时会用到。 keyDestructor和valDestructor，分别定义对key和value的析构函数。 私有数据指针（privdata）就是在dictType的某些操作被调用时会传回给调用者。 需要详细察看的是dictht结构。它定义一个哈希表的结构，由如下若干项组成： 一个dictEntry指针数组（table）。key的哈希值最终映射到这个数组的某个位置上（对应一个bucket）。如果多个key映射到同一个位置，就发生了冲突，那么就拉出一个dictEntry链表。 size：标识dictEntry指针数组的长度。它总是2的指数。 sizemask：用于将哈希值映射到table的位置索引。它的值等于(size-1)，比如7, 15, 31, 63，等等，也就是用二进制表示的各个bit全1的数字。每个key先经过hashFunction计算得到一个哈希值，然后计算(哈希值 &amp; - - sizemask)得到在table上的位置。相当于计算取余(哈希值 % size)。 used：记录dict中现有的数据个数。它与size的比值就是装载因子（load factor）。这个比值越大，哈希值冲突概率越高。 dictEntry结构中包含k, v和指向链表下一项的next指针。k是void指针，这意味着它可以指向任何类型。v是个union，当它的值是uint64_t、int64_t或double类型时，就不再需要额外的存储，这有利于减少内存碎片。当然，v也可以是void指针，以便能存储任何类型的数据。 dict的创建（dictCreate）12345678910111213141516171819202122232425262728dict *dictCreate(dictType *type, void *privDataPtr)&#123; dict *d = zmalloc(sizeof(*d)); _dictInit(d,type,privDataPtr); return d;&#125;int _dictInit(dict *d, dictType *type, void *privDataPtr)&#123; _dictReset(&amp;d-&gt;ht[0]); _dictReset(&amp;d-&gt;ht[1]); d-&gt;type = type; d-&gt;privdata = privDataPtr; d-&gt;rehashidx = -1; d-&gt;iterators = 0; return DICT_OK;&#125;static void _dictReset(dictht *ht)&#123; ht-&gt;table = NULL; ht-&gt;size = 0; ht-&gt;sizemask = 0; ht-&gt;used = 0;&#125; dictCreate为dict的数据结构分配空间并为各个变量赋初值。其中两个哈希表ht[0]和ht[1]起始都没有分配空间，table指针都赋为NULL。这意味着要等第一个数据插入时才会真正分配空间。 dict的查找（dictFind）12345678910111213141516171819202122#define dictIsRehashing(d) ((d)-&gt;rehashidx != -1)dictEntry *dictFind(dict *d, const void *key)&#123; dictEntry *he; unsigned int h, idx, table; if (d-&gt;ht[0].used + d-&gt;ht[1].used == 0) return NULL; /* dict is empty */ if (dictIsRehashing(d)) _dictRehashStep(d); h = dictHashKey(d, key); for (table = 0; table &lt;= 1; table++) &#123; idx = h &amp; d-&gt;ht[table].sizemask; he = d-&gt;ht[table].table[idx]; while(he) &#123; if (key==he-&gt;key || dictCompareKeys(d, key, he-&gt;key)) return he; he = he-&gt;next; &#125; if (!dictIsRehashing(d)) return NULL; &#125; return NULL;&#125; 上述dictFind的源码，根据dict当前是否正在重哈希，依次做了这么几件事： 如果当前正在进行重哈希，那么将重哈希过程向前推进一步（即调用_dictRehashStep）。实际上，除了查找，插入和删除也都会触发这一动作。这就将重哈希过程分散到各个查找、插入和删除操作中去了，而不是集中在某一个操作中一次性做完。 计算key的哈希值（调用dictHashKey，里面的实现会调用前面提到的hashFunction）。 先在第一个哈希表ht[0]上进行查找。在table数组上定位到哈希值对应的位置（如前所述，通过哈希值与sizemask进行按位与），然后在对应的dictEntry链表上进行查找。查找的时候需要对key进行比较，这时候调用dictCompareKeys，它里面的实现会调用到前面提到的keyCompare。如果找到就返回该项。否则，进行下一步。 判断当前是否在重哈希，如果没有，那么在ht[0]上的查找结果就是最终结果（没找到，返回NULL）。否则，在ht[1]上进行查找（过程与上一步相同）。 下面我们有必要看一下增量式重哈希的_dictRehashStep的实现。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748static void _dictRehashStep(dict *d) &#123; if (d-&gt;iterators == 0) dictRehash(d,1);&#125;int dictRehash(dict *d, int n) &#123; int empty_visits = n*10; /* Max number of empty buckets to visit. */ if (!dictIsRehashing(d)) return 0; while(n-- &amp;&amp; d-&gt;ht[0].used != 0) &#123; dictEntry *de, *nextde; /* Note that rehashidx can&#x27;t overflow as we are sure there are more * elements because ht[0].used != 0 */ assert(d-&gt;ht[0].size &gt; (unsigned long)d-&gt;rehashidx); while(d-&gt;ht[0].table[d-&gt;rehashidx] == NULL) &#123; d-&gt;rehashidx++; if (--empty_visits == 0) return 1; &#125; de = d-&gt;ht[0].table[d-&gt;rehashidx]; /* Move all the keys in this bucket from the old to the new hash HT */ while(de) &#123; unsigned int h; nextde = de-&gt;next; /* Get the index in the new hash table */ h = dictHashKey(d, de-&gt;key) &amp; d-&gt;ht[1].sizemask; de-&gt;next = d-&gt;ht[1].table[h]; d-&gt;ht[1].table[h] = de; d-&gt;ht[0].used--; d-&gt;ht[1].used++; de = nextde; &#125; d-&gt;ht[0].table[d-&gt;rehashidx] = NULL; d-&gt;rehashidx++; &#125; /* Check if we already rehashed the whole table... */ if (d-&gt;ht[0].used == 0) &#123; zfree(d-&gt;ht[0].table); d-&gt;ht[0] = d-&gt;ht[1]; _dictReset(&amp;d-&gt;ht[1]); d-&gt;rehashidx = -1; return 0; &#125; /* More to rehash... */ return 1;&#125; dictRehash每次将重哈希至少向前推进n步（除非不到n步整个重哈希就结束了），每一步都将ht[0]上某一个bucket（即一个dictEntry链表）上的每一个dictEntry移动到ht[1]上，它在ht[1]上的新位置根据ht[1]的sizemask进行重新计算。rehashidx记录了当前尚未迁移（有待迁移）的ht[0]的bucket位置。 如果dictRehash被调用的时候，rehashidx指向的bucket里一个dictEntry也没有，那么它就没有可迁移的数据。这时它尝试在ht[0].table数组中不断向后遍历，直到找到下一个存有数据的bucket位置。如果一直找不到，则最多走n*10步，本次重哈希暂告结束。 最后，如果ht[0]上的数据都迁移到ht[1]上了（即d-&gt;ht[0].used == 0），那么整个重哈希结束，ht[0]变成ht[1]的内容，而ht[1]重置为空。 根据以上对于重哈希过程的分析，我们容易看出，本文前面的dict结构图中所展示的正是rehashidx=2时的情况，前面两个bucket（ht[0].table[0]和ht[0].table[1]）都已经迁移到ht[1]上去了。 dict的插入（dictAdd和dictReplace）dictAdd插入新的一对key和value，如果key已经存在，则插入失败。 dictReplace也是插入一对key和value，不过在key存在的时候，它会更新value。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960int dictAdd(dict *d, void *key, void *val)&#123; dictEntry *entry = dictAddRaw(d,key); if (!entry) return DICT_ERR; dictSetVal(d, entry, val); return DICT_OK;&#125;dictEntry *dictAddRaw(dict *d, void *key)&#123; int index; dictEntry *entry; dictht *ht; if (dictIsRehashing(d)) _dictRehashStep(d); /* Get the index of the new element, or -1 if * the element already exists. */ if ((index = _dictKeyIndex(d, key)) == -1) return NULL; /* Allocate the memory and store the new entry. * Insert the element in top, with the assumption that in a database * system it is more likely that recently added entries are accessed * more frequently. */ ht = dictIsRehashing(d) ? &amp;d-&gt;ht[1] : &amp;d-&gt;ht[0]; entry = zmalloc(sizeof(*entry)); entry-&gt;next = ht-&gt;table[index]; ht-&gt;table[index] = entry; ht-&gt;used++; /* Set the hash entry fields. */ dictSetKey(d, entry, key); return entry;&#125;static int _dictKeyIndex(dict *d, const void *key)&#123; unsigned int h, idx, table; dictEntry *he; /* Expand the hash table if needed */ if (_dictExpandIfNeeded(d) == DICT_ERR) return -1; /* Compute the key hash value */ h = dictHashKey(d, key); for (table = 0; table &lt;= 1; table++) &#123; idx = h &amp; d-&gt;ht[table].sizemask; /* Search if this slot does not already contain the given key */ he = d-&gt;ht[table].table[idx]; while(he) &#123; if (key==he-&gt;key || dictCompareKeys(d, key, he-&gt;key)) return -1; he = he-&gt;next; &#125; if (!dictIsRehashing(d)) break; &#125; return idx;&#125; 以上是dictAdd的关键实现代码。我们主要需要注意以下几点： 它也会触发推进一步重哈希（_dictRehashStep）。 如果正在重哈希中，它会把数据插入到ht[1]；否则插入到ht[0]。 在对应的bucket中插入数据的时候，总是插入到dictEntry的头部。因为新数据接下来被访问的概率可能比较高，这样再次查找它时就比较次数较少。 _dictKeyIndex在dict中寻找插入位置。如果不在重哈希过程中，它只查找ht[0]；否则查找ht[0]和ht[1]。 _dictKeyIndex可能触发dict内存扩展（_dictExpandIfNeeded，它将哈希表长度扩展为原来两倍，具体请参考dict.c中源码）。dictReplace在dictAdd基础上实现，如下：1234567891011121314151617181920int dictReplace(dict *d, void *key, void *val)&#123; dictEntry *entry, auxentry; /* Try to add the element. If the key * does not exists dictAdd will suceed. */ if (dictAdd(d, key, val) == DICT_OK) return 1; /* It already exists, get the entry */ entry = dictFind(d, key); /* Set the new value and free the old one. Note that it is important * to do that in this order, as the value may just be exactly the same * as the previous one. In this context, think to reference counting, * you want to increment (set), and then decrement (free), and not the * reverse. */ auxentry = *entry; dictSetVal(d, entry, val); dictFreeVal(d, &amp;auxentry); return 0;&#125; 在key已经存在的情况下，dictReplace会同时调用dictAdd和dictFind，这其实相当于两次查找过程。这里Redis的代码不够优化。 dict的删除（dictDelete）dictDelete的源码这里忽略，具体请参考dict.c。需要稍加注意的是： dictDelete也会触发推进一步重哈希（_dictRehashStep） 如果当前不在重哈希过程中，它只在ht[0]中查找要删除的key；否则ht[0]和ht[1]它都要查找。 删除成功后会调用key和value的析构函数（keyDestructor和valDestructor）。","categories":[{"name":"中间件","slug":"中间件","permalink":"https://utinner.gitee.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://utinner.gitee.io/tags/redis/"}]},{"title":"Spring初探","slug":"Spring初探","date":"2020-11-21T17:22:01.000Z","updated":"2021-12-06T09:23:00.845Z","comments":true,"path":"2020/11/22/Spring初探/","link":"","permalink":"https://utinner.gitee.io/2020/11/22/Spring%E5%88%9D%E6%8E%A2/","excerpt":"","text":"一、Spring发展的几个大致阶段SpringCore最初应用的是工厂模式（DI）和代理模式（AOP），用来解耦应用组件；SpringMVC用来解决web应用的开发；又发现每次开发都需要写很多配置样板代码，为了更方便地整合引入了SpringBoot一些列stater；SringCloud的意义在于推动了微服务架构的落地。 二、IOC(Inversion of Control):控制反转不是一种技术，而是一种思想，是SpringCore最核心的部分 IOC的优势 1.避免在各处使用new来创建类，并且可以做到统一维护 2.创建实例的时候不需要了解其中的细节 IOC支持的功能 依赖注入 依赖检查 自动装配 支持集合 指定初始化方法和销毁方法 支持回调方法（有侵入方式，需谨慎使用） 1. IOC的实现方式 依赖注入（Dependency Injection），是当前IOC的主流实现 Setter方法注入 接口注入 注解注入 构造器注入 依赖查找（Dependency Lookup） DL相对于DI而言是一种更为主动的方法，他会在需要的时候通过调用框架来获取对象，获取时需要提供配置文件相关的路径、key等信息来确定获取对象的状态。DL需要用户自己去使用API进行查找资源和组装对象，对业务有侵入性，已经被抛弃。 2. 依赖倒置原则： 是一种思想，高层模块不应该依赖于底层模块，两者都应该依赖于其抽象 由于依赖倒置原则思想，才有了IOC的思路，而DI是实现IOC的方法 3.容器（控制反转容器） Spring框架基于IOC提出了容器的概念。容器管理着bean的生命周期，控制着bean的依赖注入。 Spring启动时去读取应用程序提供的bean配置信息，并在Spring容器中生成一份响应的bean配置注册表，然后根据这张注册表去实例化bean，装配好bean之间的依赖关系，为上层提供准备就绪的运行环境。Spring提供一个配置文件描述bean还有bean之间的依赖关系，利用java语言的反射功能实例化bean并建立bean之间的依赖关系。 在Spring容器中，默认的情况下bean都是以单例的形式存在的 3.1 SpringIOC容器的核心接口 BeanFactory 最核心的接口 提供了IOC的配置机制 包含了bean的各种定义，便于实例化Bean 在对象实例化之时建立bean之间的依赖关系 包含了bean生命周期的控制 ApplicationContext BeanFactory的子接口之一，能够管理、装配bean 继承了ResourcePatternResolver接口，能够加载资源文件 继承了MessageSource接口，能够实现国际化能功能 继承了ApplicationEventPublisher接口，能够注册监听器，实现监听机制 两者比较 BeanFactory是Spring框架的基础设施，面向Spring ApplicationContext面向使用Spring框架的开发者 3.2 几个重要的类和方法 BeanDefinition 主要用来描述bean的定义，Spring容器在启动的时候会将xml或者注解中的bean的定义解析成Spring内部的BeanDefinition BeanDefinitionRegistry 提供了向IOC容器注册BeanDefinition对象的方法。 Spring将bean的定义解析成BeanDefinition之后会通过BeanDefinitionRegistry以beanName为key，BeanDefinition为value存储到BeanDefinitionMap(ConcurrentHashmap)中，同时还将beanName存储到beanDefinitionNames的ArrayList中去，以便后续bean的实例化。 refresh方法 主要为IOC容器以及Bean的生命周期管理提供条件 用于刷新Spring整个上下文信息，定义Spring上下文加载流程 getBean方法 getBean用来加载bean，主要用于查找或实例化bean 实现主要是通过AbstractBeanFactory方法去实现的，所有的getBean方法最终都会去调用doGetBean方法 大致逻辑： 首先会通过调用transformedBeanName转换beanName 之后会尝试从缓存中加载实例，或者从工厂中返回实例 实例化bean 检测parentBeanFactory 初始化依赖的bean 创建bean 在检查bean的类型符合要求之后进行返回 3.3 Spring Bean的作用域（5个） singleton：Spring的默认作用域，容器里拥有唯一的bean实例 prototype：针对每个getBean请求，容器都会创建一个bean实例 request：会为每个http请求创建一个单独的bean实例 session：会为每个session创建一个bean实例 globalSession：会为每个全局的HttpSession创建一个bean实例，该作用域仅对Portlet有效 3.4 Springbean的生命周期 创建过程 销毁过程 三、 AOP面向切面编程1.产生的背景软件工程有一个基本编码原则：关注点分离（不同的问题交给不同的部分去解决，每部分专注于解决自己的问题）。AOP正是此种技术的实现，我们的代码主要就是实现某种特定的功能实现逻辑，但是我们往往不能专注于业务逻辑。比如我们写业务逻辑代码的同时还要写事务管理、缓存、日志等通用化的功能，而且这些通用化的功能还要与业务功能混写在一起，就很痛苦。为了将业务功能的专注点和通用功能的专注点分离开来，就出现了AOP的技术，这些通用化功能的代码实现，对应的就是所谓的切面（Aspect）。业务功能代码合切面代码分开之后，架构将变得高内聚低耦合。为了确保功能的完整性，切面最终需要被合并到业务中（织入Weave）。而对于业务代码，我需要在那些地方加入这些通用功能的代码，就是切点。 2.织入的三种方式 编译时织入：在代码编译时，把切面代码融合进来，生成完整功能的Java字节码，需要特殊的Java编辑器，如AspectJ 类加载时织入：在字节码加载的时候，把切面的代码融合进来，需要特殊的Java编辑器，如AspectJ和AspectWorkz 运行时织入：Spring采用的方式，通过动态代理的方式，调用切面代码增强业务功能，实现简单 3.主要名词概念 Aspect： 通用功能的代码实现 Target： 被织入Aspect的对象 JoinPoint： 可以作为切入点的机会，所有方法都都可以作为切入点 Pointcut： Aspect实际被应用在的Join Point，支持正则 Advice(通知)： 类里的方法以及这个方法如何织入到目标方法的方式 Weaving(织入): AOP的实现过程。即将切面应用到实际对象，从而创建一个新的代理对象的过程。对于Spring来说，就是初始化context中的对象时，完成织入操作。 4.Advice的类型（通知的5种类型） 前置通知（Before） 后置通知（AfterReturning） 异常通知（AfterThrowing） 最终通知（After） 环绕通知（Around） 5.Spring提供了两种方式来生成代理对象 JdkProxy 核心：通过Java的内部反射机制来接收被代理的类，并且要求被代理的类必需实现InvocationHandler接口 核心就是和InvocationHandler接口和Proxy类 反射机制在生成类的过程中比较高效 cglib 以继承的方式动态地生成目标类的代理，它是通过修改字节码来实现代理的。（如果某个类是final修饰的，则不能用此种方式） 借助ASM实现（ASM是一种可以操作字节码的框架） ASM在生成类之后的执行过程中比较高效 具体使用哪种方式生成由AopProxyFactory根据AdvisedSupport对象的配置来决定 默认的策略：如果目标类是接口，则用JdkProxy来实现，否则用后者 四、代理模式：接口+真实实现类+代理类 其中，真实实现类和代理类都是需要实现接口的，实例化的时候要使用代理类。 SpringAOP需要做的是生成一个代理类来替换掉真实实现类以对外提供服务 Spring里的代理模式的实现 对Spring来讲，真实实现类的逻辑包含在了getBean方法里面 getBean方法返回的实际上是Proxy的实例 Proxy实例是Spring采用Jdk proxy或CGLIB动态生成的 五、Spring事务的相关考点ACID隔离级别事务传播","categories":[{"name":"Java","slug":"Java","permalink":"https://utinner.gitee.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://utinner.gitee.io/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"https://utinner.gitee.io/tags/Spring/"}]},{"title":"redis面试题","slug":"redis面试题","date":"2020-11-19T17:22:01.000Z","updated":"2021-12-06T09:23:00.890Z","comments":true,"path":"2020/11/20/redis面试题/","link":"","permalink":"https://utinner.gitee.io/2020/11/20/redis%E9%9D%A2%E8%AF%95%E9%A2%98/","excerpt":"","text":"一、redis和memcache的比较1. memcache代码层面类似hash支持简单数据类型不支持数据持久化存储不支持主从不支持分片 2 redis数据类型丰富支持数据磁盘持久化存储支持主从在3.0之后支持数据分片 二、redis相关1. 为什么redis能这么快？qps：10W+(qps:每秒内查询的次数) 完全基于内存，绝大部分请求是纯粹的内存操作，执行效率高 数据结构简单，对数据操作也简单 主线程采用单线程，单线程也能处理高并发请求，想多核也可以启动多实例 使用多路I/O复用模型，非阻塞IO 2. redis采用的IO多路复用函数：epoll/kqueue/evport/select? 因地制宜 优先选择时间复杂度为O(1)的IO多路复用函数作为底层实现 以时间复杂度为O(n)的select作为保底 基于react设计模式监听IO事件 redis服务采用react设计模式来实现文件事件处理器的，文件事件处理器使用IO多路复用模块同时监听多个fd，当accept、read、write和close文件事件产生时，文件事件处理器就会回调fd绑定的文件事件处理器，虽然整个文件事件处理器是在单线程上运行的，但是通过IO多路复用模块的引用实现了同时对多个fd读写的监控，提高了网络通信模型的性能，同时也可以保证整个redis服务实现的简单。 3. 基本使用类型 String：最基本的数据类型，二进制安全 底层保存字符串对象的结构： 12345678struct sdshdr&#123; //buf中已占用空间的长度 int len; //buf中剩余可用空间的长度 int free; //数据空间，数据存储在这个buf[]中 char buf[];&#125; Hash：String元素组成的字典，适合用于存储对象 List：列表，按照String元素插入顺序排序 Set：String元素组成的无序集合，通过哈希表来实现，不允许重复 Sorted Set：通过分数来为集合中的成员进行从小到大排序 用于计数的HyperLogLog 用于支持存储地理位置信息的Geo 4. 底层数据类型基础 简单动态字符串 链表 字典 跳跃表 整数集合 压缩列表 对象 三、相关面试题1. 从海量key中查询出某一固定前缀的key keys指令对线上业务的影响： KEYS pattern：查找出所有符合给定模式pattern的key KEYS指令一次性返回所有匹配的key 键的数量过大会使得服务卡顿 scan指令： 无阻塞地提取。会返回两个值：游标和结果集 SCAN cursor [MATCH pattern][COUNT count] scan指令时一个基于游标的迭代器，需要基于上一次的游标延续之前的迭代过程 以0作为游标开始一次新的迭代，直到命令返回游标0完成一次遍历。从0到0的过程为一次完整的遍历 不保证每次执行都返回某个给定数量的元素，支持模糊查询 一次返回的数量不可控，只是大概率符合count参数 2. 如何实现分布式锁？分布式锁是控制分布式系统或不用系统之间共同访问共享资源的一种锁的实现，不同系统之间需要互斥来保证共享数据的线程安全。 2.1 分布式锁需要解决的问题： 互斥性：任一时刻，只能允许有一个客户端获取锁 安全性：锁只能由持有锁的客户端删除，不能由其他没锁的客户端删除 死锁：获得锁的客户端由于某些原因宕机了而不能释放锁，其他客户端不能获取锁而产生死锁，此时需要有机制来避免该问题的发生 容错：当redis某些节点宕机的时候，客户端仍然能够获取锁或释放锁 2.2 实现SETNX key value：如果key不存在，则创建并赋值时间复杂度：O(1)返回值：设置成功-1；设置失败-0 2.3 如何解决SETNX长期有效的问题？ EXPIRE key seconds，为key设定给定的过期时间 这种方式的缺点：不能保证原子性 在2.6.12之后： SET key value [EX seconds][PX miliseconds][NX|XX] EX seconds：设置键的过期时间为second秒 PX miliseconds：设置键的过期时间为miliseconds毫秒 NX：只有在键不存在时，才对键进行设置操作 XX：只有在键已经存在时，才对键进行设置操作 SET操作成功时，返回Ok，否则返回nil 2.4 大量的key同时过期的注意事项集中过期，由于清除大量的key会很耗时，会出现短暂的卡顿现象解决方案：在设置key的过期时间的时候，给每个时间加上随机值，使得过期时间分散一些 3. 如何使用redis做异步队列？ 使用list作为队列，Rpush生产消息，Lpop消费消息 缺点：没有等待队列里有值就直接消费 弥补：可以通过在应用层引入sleep机制去调用lpop重试 BLPOP key timeout:阻塞直到队列有消息或者超时缺点：只能供一个消费者消费 如何让生产者消费，多个消费者消费？ pub/sub：主题订阅者模式 发送者（pub）发送消息，订阅者（sub）接收消息 订阅者可以订阅任意数量的频道（topic） 多个客户端运行：subscribe myTopic命令 在一个客户端中：public myTopic &quot;Hello&quot;,那么在其他订阅该topic的消费者能够接收到这个消息 缺点：消息的发布是无状态的，无法保证可达。某个客户端在获取的时候宕机，重启之后是接收不到这个消息的，如果要解决这个问题，需要借助消息队列，即kafka等。 4. redis如何做持久化？4.1 RDB（快照）持久化：保存某个时间点的全量数据快照在redis.conf配置文件中，默认： 123456789101112# 900秒之内如果有一条写入指令则执行一次备份save 900 1# 300秒之内如果有十条写入指令则执行一次备份save 300 10# 60秒之内如果有十万条写入指令则执行一次备份 save 60 10000# 设置成yes的时候表示当备份进程出错的时候主进程就停止接收写入操作了，为了保护数据持久化的一致性问题stop-writes-on-basave-error yes# rdb持久化的时候，对持久化备份文件进行压缩，建议设置为no，因为redis是数据cpu密集型服务，开启压缩会带来更多的cpu消耗rdbcompression yes# 禁用rdb配置save &quot;&quot; 在src目录下，会生成rdb后缀的文件（dump.rdb），即备份文件,是二进制文件 rdb文件可以通过两个命令来生成： SAVE：阻塞redis的服务器进程，直到RDB文件被创建完毕（很少被使用） BGSAVE：fork出一个子进程来创建RDB文件，不会阻塞服务器进程。主进程会继续接收客户端的操作命令 自动化触发RDB持久化方式 根据redis.conf配置中的save m n定时触发（用的是BGSAVE） 主从复制时，主节点自动触发 执行Debug Reload 执行Shutdown且没有开启AOF持久化 BGSAVE原理 系统调用fork():创建进程，实现了copy-on-write copy-on-write如果有多个调用者同时要求相同资源（如内存或磁盘上的数据存储），他们会共同获取相同的指针指向相同的资源，直到某个调用者试图修改资源的内容时，系统才会真正复制一份专属副本给该调用者，而其他调用者所见到的最初的资源仍然保持不变。 RDB缺点 内存数据的全量同步，数据量大会由于IO而严重影响性能 可能会因为redis挂掉而丢失当前至最近一次快照期间的数据 4.2 AOF(append-only-file)持久化：保存写状态记录下除了查询以外的所有变更数据库状态的指令,以append的形式追加保存到AOF文件中（增量）,默认是关闭的 123456appendonly noappendfilename &quot;appendonly.conf&quot;# always:一旦缓冲区的内容发生变化，则总是及时地将缓冲区的内容写入到aof当中# everysec：将缓冲区的内容每隔一秒写入到aof中（推荐且默认，速度比较快，安全性也不错）# no：写入aof的操作交给操作系统去决定，一般而言操作系统会等待缓冲区被填满才同步appendfsync everysec 导致的问题：随着时间的推移，数据量越来越大，AOF文件也很大，怎么办？ 日志重写解决AOF文件大小不断增大的问题 原理如下： 调用fork()，创建一个子进程 子进程把新的AOF写到一个临时文件中，新的AOF的重写直接将当前内存的数据生成对应的命令，不依赖原来的AOF文件 主进程持续将新的变动同时写到内存和原来的AOF中 主进程获取子进程重写AOF的完成信号之后，往新的AOF同步增量变动 使用新的AOF文件替换掉旧的AOF文件 BGOVERWRITEAOF指令即可触发AOF的重写，也可以让redis自动触发 4.3 RDB和AOF的优缺点RDB优点：全量数据快照，文件小，恢复快RDB缺点：无法保存最近一次快照之后的数据AOF优点：可读性高，适合保存增量数据，数据不易丢失AOF缺点：文件体积大，恢复时间长 4.4 Redis4.0之后提出了结合两种的RDB-AOF混合持久化方式，并且作为默认的配置来使用 子进程在做AOF重写时，会通过管道从父进程读取增量数据并缓存下来，在以RDB格式保存全量数据时，也会从管道读取数据，同时不会造成管道的阻塞，也就是说AOF文件的前半段是RDB格式的全量数据，而后半段是redis命令格式的增量数据 BGSAVE做镜像全量持久化，AOF做增量持久化 5. pipelinepipeline和linux的管道类似redis基于请求/响应模型，单个请求处理需要一一应答pipeline批量执行指令，节省多次IO往返的时间有顺序依赖的指令建议分批发送 四、集群相关1. redis的同步机制（主从、哨兵）主从同步原理 一个master进行写操作，多个salve进行读操作 定期的数据备份操作是单独选择一个salve去完成的，这样可以最大程度发挥出redis的性能，为的是让redis支持弱一致性，即最终一致性。我们不需要实时保证master和salve的数据是同步的，但是在过了一段时间之后他们的数据是趋于同步的。 redis可以使用主从同步、从从同步。 第一次同步时主节点进行一次BGSAVE并同时将后续的写操作记录到内存中的buffer中去，待完成后将rdb文件全量同步到从节点中，从节点接收到rdb文件之后将rdb文件加载到内存中，加载完成后再通知主节点将期间修改的操作记录（即增量数据）同步到从节点进行重放，这样子就完成了整个同步的过程。 全同步过程Slave发送sync命令到mastermaster启动一个后台进程，将redis中的数据快照保存到文件中（BGSAVE）master将保存数据快照期间接收到的写命令缓存起来master完成写文件操作后，将该文件发送给Slave使用新的RDB文件替换掉旧的RDB文件master将这期间收集的增量写命令发送给slave端。 增量同步过程 Master接收到用户的操作指令，判断是否需要传播到Slave（增删改）将操作记录追加到AOF文件中将操作传播到其他slave中： - 1.对齐主从库。确保从数据库是该操作所对应的数据库 - 2.往响应缓存写入指令。将命令和参数按照redis的协议格式写入到相应的缓存中将缓存中的数据发送给Slave 主从模式的弊端 不具备高可用性，当master宕机之后redis将不能对外提供写入操作 2. 哨兵模式：解决主从同步Master宕机后的主从切换问题监控：sentinel检查主从服务器是否运行正常提醒：通过API向管理员或者其他应用程序发送故障通知自动故障迁移：主从切换 流言协议Gossip 在杂乱无章中寻求一致每个节点都随机地与对方通信，最终所有节点的状态达成一致种子节点定期随机向其他节点发送节点列表以及需要传播的消息不保证信息一定会传递给所有节点，但是最终会趋于一致 3.如何从海量数据中快速找到所需要的数据？（集群）分片：按照某种规则去划分数据，分散存储在多个节点上通过数据分片，来降低单节点服务器的压力redisCluster采用无中心结构，每个节点保存数据和整个redis集群的状态，每个节点和其他所有节点连接，每个节点通过Gossip协议传播信息以及发现新的节点。常规的按照hash无法实现节点的动态增减，采用一致性hash算法来实现 4.一致性hash算法 一致性hash：对2^32取模，将hash值空间组织成虚拟的圆环 物理机的ip经过hash计算得出hash值，所有节点得到的hash值组织成一个虚拟的圆环 当数据需要被存储的时候，按照key的hash值，按照圆环的顺时针方向保存到离他最近的hash对应的节点上，经过这样的方式就可以实现数据的分片 好处：假设一个节点C宕机，此时ABD并不会收到影响，原先需要分配到C节点的数据会重新定位到D中去，在一致性hash算法中，如果一个机器不可用，则受影响的仅仅是此服务器到其环空间前一台之间的服务器，即沿着逆时针方向行走遇到第一台服务器中间的数据，做到最小化有损的服务。如果在系统中新增了服务器，则影响的数据是新服务器到其环空间中的前一台服务器之间的数据，其他的数据不会受到影响 Hash环的数据倾斜问题 如果节点数量很少的时候，容易在圆环上造成hash分布不均匀的情况，导致一个节点上的数据比其他节点上的数据多出很多的情况。造成数据倾斜，数据倾斜就是大部分的数据分布在同一个节点上。 引入虚拟节点来解决数据倾斜问题 对每个服务器节点计算多个hash，每个计算结果位置都放置一个节点为该节点的虚拟节点（具体做法可以在主机名或者ip后增加编号来实现），这样来实现圆环的大致均匀。数据算法不变，只是多了一步虚拟节点到真实节点的映射。 通常将虚拟节点设置为32甚至更大。 五、Redis的五种淘汰策略 volatile-lru:从设置了过期时间的数据集中，选择最近最久未使用的数据释放； allkeys-lru:从数据集中(包括设置过期时间以及未设置过期时间的数据集中)，选择最近最久未使用的数据释放； volatile-random:从设置了过期时间的数据集中，随机选择一个数据进行释放； allkeys-random:从数据集中(包括了设置过期时间以及未设置过期时间)随机选择一个数据进行入释放； volatile-ttl：从设置了过期时间的数据集中，选择马上就要过期的数据进行释放操作； noeviction：不删除任意数据(但redis还会根据引用计数器进行释放),这时如果内存不够时，会直接返回错误。","categories":[{"name":"中间件","slug":"中间件","permalink":"https://utinner.gitee.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://utinner.gitee.io/tags/redis/"}]},{"title":"计算机网络","slug":"计算机网络","date":"2020-11-14T14:30:17.000Z","updated":"2021-12-06T09:23:00.923Z","comments":true,"path":"2020/11/14/计算机网络/","link":"","permalink":"https://utinner.gitee.io/2020/11/14/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/","excerpt":"一.OSI七层协议 1.物理层 机器A往机器B发送比特流，机器B要保证能收到比特流，这就是物理层要做的事情。物理层主要定义了网络设备的标准，如：网线的类型、光纤的接口类型。网卡就是工作在这一层里面的，这一层主要负责数模、模数的转换（比特流转化为电流，电流再转化为比特流） 2.数据链路层 在传输比特流的过程中，会产生错传、数据传输不完整的可能，因此数据链路层定义了如何格式化数据以进行传输，这一层通常还提供错误检测和纠正，以确保数据传输的可靠性，本层将比特数据组成了“帧”，其中交换机工作在这一层中，对帧解码，并根据帧中包含的信息将数据发送给正确的接收方 3.网络层 随着网络节点的不断增加，点对点通信的时候是需要经过多个节点的，如何找到目标节点、如何找到最佳路径便成为了首要需求，此时便有了网络层。其主要功能是将网络地址翻译成对应的物理地址，并决定如何将数据从发送方路由到接收方。网络层通过综合考虑发送优先权、网络拥塞程度、服务质量以及可选路由的花费来决定从一个节点A到另一个节点B的最佳路径。路由器属于网络层，此时的数据我们称之为“数据包”。本层需要关注的协议主要是TCP/IP协议中的IP协议 4.传输层 随着网络通信需求的进一步扩大，通信过程中需要发送大量的数据（如海量文件的传输，可能需要很长的时间），而网络在通信的过程中会中断好多次，此时为了保证传输大量文件时的准确性，需要对发出去的数据进行切分，切分为一个个的小段落(segment),其中一个段落丢失了怎么办？要不要重传？每个段落要按照顺序到达吗？这些便是传输层需要考虑的问题了。传输层解决了数据之间的传输，解决了传输质量的问题，该层为OSI模型中最终要的一层。以太网无法接收超过1500字节的数据包。本层需要关注的协议主要是TCP/IP协议中的TCP协议和UDP协议。 5.会话层 建立和管理应用程序之间的通信 6.表示层 windows上无法运行linux中的脚本文件，机器之间存在数据通信的语法差异。表示层就是为了解决不同和操作系统之间的通信语法问题。在表示层，数据将按照网络能理解的方案进行格式化，这种格式化也因所使用网络的类型不同而不同。 7.应用层 规定发送方和接收方必须使用固定格式的消息头，消息头必须使用某种固定的组成，而且消息头里必须记录消息体的长度等一系列信息，以方便接受方能够正确地解析发送方发送的数据，应用层旨在让我们更方便地应用从网络中接收到的数据。本层需要关注的协议主要是TCP/IP协议中的HTTP协议。","text":"一.OSI七层协议 1.物理层 机器A往机器B发送比特流，机器B要保证能收到比特流，这就是物理层要做的事情。物理层主要定义了网络设备的标准，如：网线的类型、光纤的接口类型。网卡就是工作在这一层里面的，这一层主要负责数模、模数的转换（比特流转化为电流，电流再转化为比特流） 2.数据链路层 在传输比特流的过程中，会产生错传、数据传输不完整的可能，因此数据链路层定义了如何格式化数据以进行传输，这一层通常还提供错误检测和纠正，以确保数据传输的可靠性，本层将比特数据组成了“帧”，其中交换机工作在这一层中，对帧解码，并根据帧中包含的信息将数据发送给正确的接收方 3.网络层 随着网络节点的不断增加，点对点通信的时候是需要经过多个节点的，如何找到目标节点、如何找到最佳路径便成为了首要需求，此时便有了网络层。其主要功能是将网络地址翻译成对应的物理地址，并决定如何将数据从发送方路由到接收方。网络层通过综合考虑发送优先权、网络拥塞程度、服务质量以及可选路由的花费来决定从一个节点A到另一个节点B的最佳路径。路由器属于网络层，此时的数据我们称之为“数据包”。本层需要关注的协议主要是TCP/IP协议中的IP协议 4.传输层 随着网络通信需求的进一步扩大，通信过程中需要发送大量的数据（如海量文件的传输，可能需要很长的时间），而网络在通信的过程中会中断好多次，此时为了保证传输大量文件时的准确性，需要对发出去的数据进行切分，切分为一个个的小段落(segment),其中一个段落丢失了怎么办？要不要重传？每个段落要按照顺序到达吗？这些便是传输层需要考虑的问题了。传输层解决了数据之间的传输，解决了传输质量的问题，该层为OSI模型中最终要的一层。以太网无法接收超过1500字节的数据包。本层需要关注的协议主要是TCP/IP协议中的TCP协议和UDP协议。 5.会话层 建立和管理应用程序之间的通信 6.表示层 windows上无法运行linux中的脚本文件，机器之间存在数据通信的语法差异。表示层就是为了解决不同和操作系统之间的通信语法问题。在表示层，数据将按照网络能理解的方案进行格式化，这种格式化也因所使用网络的类型不同而不同。 7.应用层 规定发送方和接收方必须使用固定格式的消息头，消息头必须使用某种固定的组成，而且消息头里必须记录消息体的长度等一系列信息，以方便接受方能够正确地解析发送方发送的数据，应用层旨在让我们更方便地应用从网络中接收到的数据。本层需要关注的协议主要是TCP/IP协议中的HTTP协议。 二.TCP/IP概念层模型 1.应用层（应用层、表示层、会话层） 2.传输层 3.网络层 4.链路层（数据链路层，物理层） 2.1 IP协议 IP协议是无连接的通信协议，它不会占用两个正在通信的计算机之间的通信线路，这样IP就降低对网络线路的需求，每条线都可以满足许多计算机之间的通信需要，通过IP，消息或者其他会被分割为较小的独立的包，并通过在因特网在计算机之间传送。IP负责将每个包，路由至其目的地。但IP协议没有做任何事情来确认数据包是否按顺序发送，或者包被破坏。所以IP数据包是不可靠的，需要由它的上层协议作出控制。 2.2 TCP协议 传输控制协议TCP 是传输层的协议 面向连接的，可靠的，基于字节流的传输层通信协议 将应用层的数据流分割成报文段并发送给目标节点的TCP层 报文段的长度通常受该计算机连接网络的数据链路层最大传输单元及MPU的限制，之后TCP把结果包传给IP层 数据包都有序号，对方收到则发送ACK确认，未收到则重传 数据包有序号的原因就是为了保证包不丢失，序列号(Sequence Number),也保证了传送到目标节点包的按序处理。然后接收端实体对已成功收到的包发回一个相应的确认，即ACK确认。如果发送端实体在合理的往返时延(RTT)内未收到确认，那么对应的数据包会被认为已丢失，并且将会对其进行重传。 使用校验和未校验数据在传输过程中是否有误 TCP用奇偶校验和函数来检验数据是否有错误，在发送和接收时都要计算校验和 2.3 TCP报文头 TCP报文是TCP层传输的数据单元，也叫报文段。 1.端口号：用来标识同一台计算机的不同的应用进程。 1）源端口：源端口和IP地址的作用是标识报文的返回地址。 2）目的端口：端口指明接收方计算机上的应用程序接口。 TCP报头中的源端口号和目的端口号同IP数据报中的源IP与目的IP唯一确定一条TCP连接。 2.序号和确认号：是TCP可靠传输的关键部分。序号是本报文段发送的数据组的第一个字节的序号。在TCP传送的流中，每一个字节一个序号。 一个报文段的序号为300，此报文段数据部分共有100字节，则下一个报文段的序号为400。所以序号确保了TCP传输的有序性。确认号，即ACK，指明下一个期待收到的字节序号，表明该序号之前的所有数据已经正确无误的收到。确认号只有当ACK标志为1时才有效。比如建立连接时，SYN报文的ACK标志位为0。 3.数据偏移／首部长度： 4bits。由于首部可能含有可选项内容，因此TCP报头的长度是不确定的，报头不包含任何任选字段则长度为20字节，4位首部长度字段所能表示的最大值为1111，转化为10进制为15，15*32/8 = 60，故报头最大长度为60字节。首部长度也叫数据偏移，是因为首部长度实际上指示了数据区在报文段中的起始偏移值。 4.控制位 由8个标志位来组成，每个标志位表示一个控制的功能，其中常见的包括： 123456URG: 紧急指针标志。1-紧急指针有效，0-忽略紧急指针ACK: 确认序号标志。1-确认序号有效，0-报文中不含确认信息，忽略确认字段PSH: push标志。1-表有push的标志，指示接收方在接收到报文段以后，应尽快将报文段交给应用程序，而不是在缓冲区排队 RST: 重置连接标志。用于重置，主机崩溃或者其他原因而出现错误的连接，或者用于拒绝非法的报文端和拒绝连接请求SYN: 同步序号，用于建立连接过程，在连接请求中SYN=1,ACK=0表示该数据段没有使用捎带的确认域，而连接应答捎带一个确认，即SYN=1,ACK=1FIN: finsh标志。用于释放连接，唯一标识发送方没有数据发送，即关闭本方数据流， 5.窗口 滑动窗口大小，用来告知发送端接受端的缓存大小，以此控制发送端发送数据的速率，从而达到流量控制。窗口大小是一个16bit字段，因而窗口大小最大为65535。 7.校验和 奇偶校验，此校验和是对整个的 TCP 报文段，包括 TCP 头部和 TCP 数据，以 16 位字进行计算所得。由发送端计算和存储，并由接收端进行验证。 8.紧急指针 只有当 URG 标志置 1 时紧急指针才有效。紧急指针是一个正的偏移量，和顺序号字段中的值相加表示紧急数据最后一个字节的序号。 TCP 的紧急方式是发送端向另一端发送紧急数据的一种方式。 9.选项和填充 最常见的可选字段是最长报文大小，又称为MSS（Maximum Segment Size），每个连接方通常都在通信的第一个报文段（为建立连接而设置SYN标志为1的那个段）中指明这个选项，它表示本端所能接受的最大报文段的长度。选项长度不一定是32位的整数倍，所以要加填充位，即在这个字段中加入额外的零，以保证TCP头是32的整数倍。 10.数据部分 TCP 报文段中的数据部分是可选的。在一个连接建立和一个连接终止时，双方交换的报文段仅有 TCP 首部。如果一方没有数据要发送，也使用没有任何数据的首部来确认收到的数据。在处理超时的许多情况中，也会发送不带任何数据的报文段。 三.TCP三次握手当应用程序希望通过TCP与另一个应用通信时，它会发送一个通信请求，这个请求必须被送到一个确切的地址，在双方握手之后，TCP将在两个应用之间建立一个全双通的通信，这个全双通（A可以给B发送信息的同时，B也能够给A发信息）的通信将占用两个计算机之间的通信线路，直到被一方，或者双方关闭为止。 第一次握手 一开始客户端和服务器端都处于Close状态。 刚开始的时候TCP服务器进程先创建传输控制块(PCD)，时刻准备接受其他客户进程发送过来的连接请求。 此时服务端进入了Listen，即监听的状态。此时客户端进程也先创建一个传输控制块(PCD)然后向服务器发出连接请求报文，SYN就是TCP Flags的同步序号，SYN =1,选择一个初始序号seq =x ,x可以是任意的正整数值。 此时TCP客户端进程就进入了一个SYN-SENT同步已发送的状态，发送给服务端的数据包，即报文端会被称为SYN报文段，不能携带数据，但是要消耗一个序号。 第二次握手 当服务器接收到一个报文请求之后，同意连接，则发出确认报文，确认报文中包含TCP Flags中的SYN,ACK两位的字段。 SYN=1,ACK=1,seq=y,ack=x+1。 ack = x+1的原因是第一次握手SYN报文中指定了seq=x,服务端要回应相关的信息，并且第一次握手中报文消耗了一个序号，因此ack=x+1,同时为自己的缓存初始化一个序列号，即seq=y。此时服务器就进入到了SYN-RCVD,即同步收到的状态。 这个报文也是不能携带数据的，同时也需要消耗一个序号。 第三次握手 当TCP客户进程收到确认报文之后，还要给服务器一个确认。ACK=1,seq=x+1,ack=y+1 ack=y+1,原因是服务器给客户端发送一个seq=y，客户端作为回应。所以就加了1。同时第二次握手的报文会消耗一个序号。 同时第一次握手的时候，客户端告知(ack)服务器序号被+1了，即seq =x ,第二次握手时ack=x +1 。所以第三次握手时候seq = x+ 1。 此时TCP连接建立，客户端就进入了ESTAB-LISHED,即已建立连接的状态，此时TCP规定这个时候的报文段可以携带数据。第一次，第二次握手的报文段都是不可以携带的。也可以不携带数据，这样就不会消耗序号了。 当服务器也收到了客户端的确认后也会进入ESTAB-LISHED状态。 完成三次握手之后，双方就可以开始通信了。 总结 在TCP/IP协议中，TCP协议提供可靠的链接服务，采用三次握手建立一个连接 第一次握手：建立连接时，客户端发送SYN包(SYN=j)到服务器，进入SYN_SEND状态，等待服务器确认； 第二次握手：服务器收到SYN包，必须确认客户的SYN(ack=j+1),同时自己也发送一个SYN包(syn=k),即SYN+ACK包，此时服务器进入SYN_RECV状态； 第三次握手：客户端收到服务器的SYN+ACK包，向服务器发送确认包ACK(ack=k+1),此时包发送完毕，客户端和服务区进入ESTABLISHED状态，完成三次握手。 四.TCP四次挥手 断开一个TCP连接时，需要客户端和服务器端总共发出4个包，以确认连接的断开。 在Socket编程中，这过程由客户端或服务端任一方，执行Close来触发。 “挥手”是为了终止连接，TCP四次挥手的流程图如下 上图由客户端主动触发close。数据传送完毕之后，双方都可以释放连接，最开始的时候客户端和服务端都处于ESTABLISHED状态。然后客户端主动关闭，服务器被动关闭。 第一次挥手首先客户端进程发出连接释放报文（FIN），并且停止发送数据。在该数据报的报头中，TCP Flags 中的 FIN = 1，假设客户端定义的序列号为seq=u，该值等于前面ESTABLISHED状态数据最后一次发送的时候，已经传送过来的数据的最后一个字节的序号加上1。此时客户端就进入了FINWAIT1,这个终止等待1的状态。TCP规定即使FIN不携带数据，也要消耗掉一个序号。即回值的时候u要加上1。 第二次挥手当服务器收到连接释放报文之后，也要发出确认报文，即ACK=1。作为回应akc=u+1,并且也带上了自己的序列号seq=v。此时服务端就进入了CLOSEWAIT,关闭等待的状态。TCP服务器通知高层的进程，客服端要释放与服务器之间的连接，这时候会处于半关闭的状态，即客户端没有数据要发送了，但是服务器要发送数据，客户端还是能够接受的。CLOSEWAIT状态还要持续一段时间。 第三次挥手客户端收到服务器的确认请求之后，客户端就进入了FIN_WAIT_2,即终止等待2状态。等待服务器发送释放连接报文，也就是第三次挥手的请求。因此在这个时间内还需要接收服务器发送最后的数据，服务器将最后的数据发送完毕后就会向客户端发送连接释放报文，FIN=1,ack=u+1。有可能在半关闭的状态，服务器很可能又发送了一些数据，假定此时的序号变为了w。此时服务器就进入到了LAST_ACK的状态。等待客户端的最终确认。 第四次挥手客户端在收到服务器的连接释放报文之后，必须发出确认，即ACK=1，然后再将服务器发送过来的w变成w+1,回发给服务器。 此时的seq为u+1。此时客户端就进入了TIME_WAIT,即时间等待的状态，这时客户端的TCP连接还没有释放，必须经过2MSL时间后，连接才会真正的释放，才会进入到CLOSED状态。MSL最长报文段生命。在Linux MSL 为30s,而服务器只要收到客户端发出的确认，立即就进入CLOSED状态。 由图可知，服务器结束TCP的连接时间要比客户端稍早一些。 总结 第一次挥手：Client发送一个FIN，用来关闭Client到Server的数据，Client进入FIN_WAIT_1状态； 第二次挥手：Server收到FIN后，发送一个ACK给Client，确认序号为收到序号+1（与SYN相同，一个FIN占用一个序号），Server进入CLOSE_WAIT状态,Client进入FIN_WAIT_2状态 第三次挥手：Server发送一个FIN，用来关闭Server到Client的数据传送，Server进入LAST_ACK状态； 第四次挥手：Client收到FIN后，Client进入TIME_WAIT状态，接着发送一个ACK给Server,确认序号为收到序号+1，Server进入CLOSED状态，完成四次挥手。 4.1 为什么会有TIME_WAIT状态？ 确保由足够的时间让对方收到ACK TIME_WAIT状态用来保证有足够的时间让对端接收完ACK，如果被动关闭的那方没有收到ACK就会触发被动端重发FIN包，一来一去正好是2MSL。 避免新旧连接混淆 有足够的时间让这个连接，不会跟后面的连接混在一起，因为有些路由器会缓存IP数据包。如果连接被重用了，那么这些延迟被收到的包就有可能跟新连接混在一起 4.2 为什么需要四次挥手才能断开连接？ 全双通的意思是允许数据在两个方向上同时传输，即在同一时间，服务器可以发送数据给客户端，客户端也可以发送数据给服务器。 因为全双工，发送方和接收方都需要FIN报文和ACK报文 发送方和接收方各只需两两次挥手即可，只不过有一方是被动的，所以看上去就成了四次挥手 4.3 服务器出现CLOSE_WAIT状态的原因 问题其中一个表现是客户端一直在请求，但是返回给客户端的信息是异常的。服务端压根也没收到请求。 服务器保持大量的CLOSE_WAIT只有一种情况，那就是在对方发送一个FIN报文之后，程序这边没有进一步发送ACK，或者FIN报文以确认。 4.4 对方关闭Socket连接，我方忙于读或写，没有及时关闭连接对方关闭连接后，程序里没有检测到，或者程序本身就已经忘了这个时候需要关闭连接，于是这个资源就被程序占用着。遇到这种情况多数是程序里面有BUG，通常是有些连接没有释放检查代码，特别是释放资源代码检查配置，特别是处理请求的线程配置 五.TCP和UDP的区别相比TCP报文，UDP的域少了很多。简单了很多。简单的报文结构意味着UDP不像TCP那样，支持错误重传，滑动窗口。 5.1UDP的特点 面向非连接 传输数据之前，源端和终端不建立连接，当它想传送时，就简单地去抓取来自应用程序的数据，并尽可能快地把它扔到网络上。 在发送端UDP传送数据的速度仅仅是受应用程序生成数据地速度，计算机的能力和传输带宽的限制。 在接收端UDP把每个消息段放在队列中，应用程序每次从队列中读取一个消息段。 不维护连接状态，支持同时向多个客户端传输相同的消息 由于传输数据不建立连接，所以不需要维护连接状态。 数据包报头只有8个字节，额外开销较小 相对TCP的20个字节包小很多 吞吐量只受限于数据生成速率，传输速率以及机器性能 吞吐量不受拥挤控制算法的调节，只受应用软件生成数据的效率，传输带宽，源端和终端主机性能的限制。 尽最大努力交付，不保证可靠交付，不需要维持复杂的链接状态表 面向报文，不对应用程序提交的报文信息进行拆分或者合并 发送方的UDP对应用程序，交下来的报文，在添加守护后就向下交付给IP层，既不拆分，也不合并。而是保留报文的边界。因此应用程序应该选择合适的报文大小，UDP将多数的控制交给上层去解决。 5.2 总结TCP和UDP是OSI模型中，运输层的协议。TCP提供可靠的传输，而UDP常被用于让广播和细节控制交给应用层的通信传输。 面向链接与面向无连接 TCP有三次握手的过程，UDP合适消息的多播发布，从单个点向多个点发布信息 可靠性 TCP利用握手，确认，重传机制提供了可靠性保证。UDP可能会被丢失，不知道有没有被接收 有序性 TCP利用序列号保证了消息报的顺序交付，达到可能无序，但是TCP最终还是会排序的。 UDP不具备有序性 速度 TCP速度比较慢，因为要创建连接，保证消息的可靠性和有序性，需要额外做很多事。 UDP比较适合对速度比较敏感的应用。比如在线视频媒体，电视广播，多人在线游戏。 量级 TCP属于重量级的 UDP属于轻量级的 体现在源数据头部大小 TCP 20个字节 UDP 8个字节 六.TCP的滑动窗口https://blog.csdn.net/qq_41398448/article/details/100775989 七.HTTP相关https://blog.csdn.net/qq_41398448/article/details/100780050 八.HTTP和HTTPS的区别https://blog.csdn.net/qq_41398448/article/details/100830299 九.ping和talnet命令ping基于ICMP协议，验证IP的可达性，ping ip地址 12ping 192.168.205.10 talne检车服务的可用性,ping ip地址 端口号 12ping 192.168.205.10 8080 十.网络抓包工具wireshark","categories":[{"name":"计算机基础","slug":"计算机基础","permalink":"https://utinner.gitee.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"基础知识","slug":"基础知识","permalink":"https://utinner.gitee.io/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"}]},{"title":"Flink深入了解","slug":"Flink深入了解","date":"2020-11-03T08:06:51.000Z","updated":"2021-12-06T09:23:00.713Z","comments":true,"path":"2020/11/03/Flink深入了解/","link":"","permalink":"https://utinner.gitee.io/2020/11/03/Flink%E6%B7%B1%E5%85%A5%E4%BA%86%E8%A7%A3/","excerpt":"一、Flink运行架构1.Flink运行时的组件Flink 运行时架构主要包括四个不同的组件，它们会在运行流处理应用程序时协同工作： 作业管理器（JobManager）、资源管理器（ResourceManager）、任务管理器（TaskManager）， 以及分发器（Dispatcher）。因为 Flink 是用 Java 和 Scala 实现的，所以所有组件都会运行在Java 虚拟机上。每个组件的职责如下：","text":"一、Flink运行架构1.Flink运行时的组件Flink 运行时架构主要包括四个不同的组件，它们会在运行流处理应用程序时协同工作： 作业管理器（JobManager）、资源管理器（ResourceManager）、任务管理器（TaskManager）， 以及分发器（Dispatcher）。因为 Flink 是用 Java 和 Scala 实现的，所以所有组件都会运行在Java 虚拟机上。每个组件的职责如下： JobManager: 控制一个应用程序执行的主进程，也就是说， 每个应用程序都会被一个不同的JobManager 所控制执行。JobManager 会先接收到要执行的应用程序，这个应用程序会包括： 作业图（JobGraph）、逻辑数据流图（logical dataflow graph）和打包了所有的类、库和其它资源的 JAR 包。JobManager 会把 JobGraph 转换成一个物理层面的数据流图，这个图被叫做“执行图”（ExecutionGraph），包含了所有可以并发执行的任务。JobManager 会向资源管理器（ResourceManager）请求执行任务必要的资源，也就是任务管理器（TaskManager）上的插槽（ slot）。一旦它获取到了足够的资源，就会将执行图分发到真正运行它们的TaskManager 上。而在运行过程中，JobManager 会负责所有需要中央协调的操作，比如说检查点（checkpoints）的协调。 TaskManager: Flink 中的工作进程。通常在 Flink 中会有多个 TaskManager 运行，每一个 TaskManager都包含了一定数量的插槽（slots）。插槽的数量限制了 TaskManager 能够执行的任务数量。启动之后， TaskManager 会向资源管理器注册它的插槽；收到资源管理器的指令后， TaskManager 就会将一个或者多个插槽提供给 JobManager 调用。JobManager 就可以向插槽分配任务（tasks）来执行了。在执行过程中，一个TaskManager 可以跟其它运行同一应用程序的 TaskManager 交换数据。 ResourceManager: 主要负责管理任务管理器（TaskManager）的插槽（slot），Slot是 Flink 中定义的处理资源单元。Flink 为不同的环境和资源管理工具提供了不同资源管理器，比如YARN、Mesos、K8s，以及 standalone 部署。当 JobManager 申请插槽资源时，ResourceManager 会将有空闲插槽的TaskManager 分配给 JobManager。如果 ResourceManager 没有足够的插槽来满足 JobManager 的请求，它还可以向资源提供平台发起会话，以提供启动 TaskManager 进程的容器。另外，ResourceManager 还负责终止空闲的 TaskManager，释放计算资源。 Dispacher: 分发器，可以跨作业运行，它为应用提交提供了 REST 接口。当一个应用被提交执行时，分发器就会启动并将应用移交给一个 JobManager。由于是 REST 接口，所以 Dispatcher 可以作为集群的一个 HTTP 接入点，这样就能够不受防火墙阻挡。Dispatcher 也会启动一个 Web UI，用来方便地展示和监控作业执行的信息。Dispatcher 在架构中可能并不是必需的，这取决于应用提交运行的方式。 2.任务提交流程我们来看看当一个应用提交执行时，Flink 的各个组件是如何交互协作的： 上图是从一个较为高层级的视角，来看应用中各组件的交互协作。如果部署的集群环境不同（例如 YARN，Mesos，Kubernetes，standalone 等），其中一些步骤可以被省略，或是有些组件会运行在同一个 JVM 进程中。 具体地，如果我们将 Flink 集群部署到 YARN 上，那么就会有如下的提交流程： Flink 任务提交后， Client 向 HDFS 上传 Flink 的 Jar 包和配置， 之后向 Yarn ResourceManager 提交任务， ResourceManager 分配 Container 资源并通知对应的NodeManager 启动 ApplicationMaster， ApplicationMaster 启动后加载 Flink 的 Jar 包和配置构建环境，然后启动 JobManager，之后 ApplicationMaster 向 ResourceManager 申请资源启动 TaskManager ， ResourceManager 分配 Container 资 源 后 ， 由ApplicationMaster 通 知 资 源 所 在 节 点 的 NodeManager 启动 TaskManager ， NodeManager 加载 Flink 的 Jar 包和配置构建环境并启动 TaskManager，TaskManager 启动后向 JobManager 发送心跳包， 并等待 JobManager 向其分配任务。 3.任务调度原理 客户端不是运行时和程序执行的一部分，但它用于准备并发送dataflow(JobGraph)给 Master(JobManager)， 然后， 客户端断开连接或者维持连接以等待接收计算结果。 当Flink集群启动后,首先会启动一个JobManger和一个或多个的TaskManager。由Client提交任务给JobManager,JobManager再调度任务到各个TaskManager去执行，然后TaskManager将心跳和统计信息汇报给JobManager。TaskManager之间以流的形式进行数据的传输。上述三者均为独立的 JVM 进程。 Client为提交Job的客户端，可以是运行在任何机器上（ 与 JobManager 环境连通即可）。提交 Job 后， Client 可以结束进程（ Streaming 的任务），也可以不结束并等待结果返回。 JobManager主要负责调度Job并协调Task做checkpoint(职责上很像Storm的Nimbus)。从Client处接收到Job和JAR包等资源后，会生成优化后的执行计划，并以Task的单元调度到各个TaskManager去执行。 TaskManager在启动的时候就设置好了槽位数（Slot），每个slot能启动一个Task,Task为线程。从JobManager处接收需要部署的Task，部署启动后，与自己的上游建立Netty连接,接收数据并处理。","categories":[{"name":"大数据","slug":"大数据","permalink":"https://utinner.gitee.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}],"tags":[{"name":"Flink","slug":"Flink","permalink":"https://utinner.gitee.io/tags/Flink/"}]},{"title":"Flink初识","slug":"Flink初识","date":"2020-11-02T08:58:40.000Z","updated":"2021-12-06T09:23:00.713Z","comments":true,"path":"2020/11/02/Flink初识/","link":"","permalink":"https://utinner.gitee.io/2020/11/02/Flink%E5%88%9D%E8%AF%86/","excerpt":"一.引入Flink的目的 低延迟 高吞吐 结果的准确性和良好的容错性 二、例子（实现wordCount）","text":"一.引入Flink的目的 低延迟 高吞吐 结果的准确性和良好的容错性 二、例子（实现wordCount） 12345678910111213141516171819202122232425262728293031package com.xesonline.demoimport org.apache.flink.api.scala.&#123;DataSet, ExecutionEnvironment&#125;import org.apache.flink.api.scala._/** * @Classname WordCount * @Description * @Date 2020/11/3 3:06 下午 * @Created by jinping *///批处理的wordCountobject WordCount &#123; def main(args: Array[String])&#123; //创建执行环境 val env:ExecutionEnvironment= ExecutionEnvironment.getExecutionEnvironment; val inputPath : String = &quot;/Users/jinping/Desktop/flink/ss-flink-scala/src/main/resources/word.txt&quot;; val inputDataSet : DataSet[String] = env.readTextFile(inputPath); //对数据进行转换处理，先分词 val resultDataset:DataSet[(String,Int)] = inputDataSet .flatMap(_.split(&quot; &quot;)) .map((_,1)) .groupBy(0)//以第一个元素作为key进行分组 .sum(1); resultDataset.print(); &#125;&#125;","categories":[{"name":"大数据","slug":"大数据","permalink":"https://utinner.gitee.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}],"tags":[{"name":"Flink","slug":"Flink","permalink":"https://utinner.gitee.io/tags/Flink/"}]},{"title":"垃圾回收","slug":"垃圾回收","date":"2020-10-26T20:00:51.000Z","updated":"2021-12-06T09:23:00.903Z","comments":true,"path":"2020/10/27/垃圾回收/","link":"","permalink":"https://utinner.gitee.io/2020/10/27/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/","excerpt":"一.如何知道对象是一个垃圾？没有任何引用指向的对象就是垃圾。 可达性分析(非GCRoot引用的对象) 通过判断对象的引用链是否可达来决定对象是否可以被回收 通过一系列名为GCRoot的对象为起始点，从这些节点开始向下搜索，搜索所走过的路径就被称为引用链 当一个对象从GCRoot没有任何引用链相连，即从GCRoot到这个对象是不可达的，在这个时候就证明了这个对象是不可用的，可以进行回收 引用计数法（判断对象的引用数量来决定对象是否可以被回收） 每个对象实例都有一个引用计数器，被引用则+1，完成引用则-1 任何引用计数为0的对象实例可以被当做垃圾收集优点：执行效率高，程序执行受影响较小缺点：无法检测出循环引用的情况，导致内存泄漏","text":"一.如何知道对象是一个垃圾？没有任何引用指向的对象就是垃圾。 可达性分析(非GCRoot引用的对象) 通过判断对象的引用链是否可达来决定对象是否可以被回收 通过一系列名为GCRoot的对象为起始点，从这些节点开始向下搜索，搜索所走过的路径就被称为引用链 当一个对象从GCRoot没有任何引用链相连，即从GCRoot到这个对象是不可达的，在这个时候就证明了这个对象是不可用的，可以进行回收 引用计数法（判断对象的引用数量来决定对象是否可以被回收） 每个对象实例都有一个引用计数器，被引用则+1，完成引用则-1 任何引用计数为0的对象实例可以被当做垃圾收集优点：执行效率高，程序执行受影响较小缺点：无法检测出循环引用的情况，导致内存泄漏 二.可以作为GCRoot的对象有哪些？ 虚拟机栈中引用的对象（栈帧中的本地变量表） 方法区中的常量引用的对象 方法区中的类静态属性引用的对象 本地方法栈中JNI(native方法）的引用对象 活跃线程的引用对象 三.GC算法 1.标记清除（有碎片） 2.拷贝算法（浪费空间，一般用于MinorGC,对于新生代的） 3.标记整理（一边做标记一边做整理，但是效率低） 标记清除和标记整理算法一般都是针对老年代进行回收的算法 四.垃圾回收器需要了解的相关概念： 吞吐量=运行用户代码时间/(运行用户代码时间+垃圾收集时间) Stop-the-world（STW） JVM由于要执行GC而停止了应用程序的执行 任何一种GC算法中都会发生 多数GC优化通过减少Stop-the-world发生的时间来提升程序性能 Safepoint（安全点） 分析可达性的过程中引用关系不会发生变化的点 产生Safepoint的地方：方法调用、循环跳转、异常跳转等 安全点的数量需要适中。太少会让GC等待太长的时间，太多会增加程序运行的负荷 JVM的运行模式 Server：启动较慢，但是启动成功之后server程序的运行效率要比Client快。采用的是重量级的虚拟机，对程序采用了更多的优化。 Client：启动较快，采用的是轻量级的虚拟机 通过java -version命令进行查看 1.分代模型对于新生代： Serial(最早的垃圾回收器，现在很少用，单线程) 可以通过-XX:+UseSerialGC,使得年轻代使用该垃圾回收期进行回收 在jdk1.3之前，是Java年轻代垃圾回收器的唯一选择 单线程通过复制算法进行收集，在进行垃圾收集时，必须暂停所有的工作线程 简单高效，是Client模式下默认的年轻代收集器 ParNew(多线程处理,工作在年轻代,专门和CMS做配合的) 可以通过-XX:+UseParNewGC,使得年轻代使用该垃圾回收期进行回收 多线程收集，其余的行为、特点和Serial收集器一样 是Server模式下首选的年轻代回收器 也是使用复制算法 单核执行效率不如Serial，在多核下执行才有优势 Parallel Scavenge(多线程处理,工作在年轻代) 可以通过-XX:+UseParallelGC,使得年轻代使用该垃圾回收期进行回收 使用复制算法 比起关注用户线程停顿时间，更关注系统的吞吐量 在多核执行下才有优势，Server模式下默认的年轻代收集器 自适应调节策略：-XX:+UseAdaptiveSizePolicy,会把内置管理的调优任务交给虚拟机去完成 对于老年代： Serial Old(单线程) 可以通过-XX:+UseSerialOldGC,使得老年代使用该垃圾回收期进行回收 单线程通过标记-整理算法进行收集，在进行垃圾收集时，必须暂停所有的工作线程 简单高效，是Client模式下默认的老年代收集器 Parallel Old(多线程处理) 可以通过-XX:+UseParallelOldGC,使得老年代使用该垃圾回收期进行回收 多线程使用标记-整理算法进行收集，JDK6之后开始提供的，吞吐量优先 CMS 标记-清除算法 垃圾回收线程几乎能与用户线程做到同时工作，只是尽可能缩短了停顿时间 JDK5提出的第一款针对于老年代GC与工作线程并发执行的收集器 2.分区模型 G1（1.8可用） ZGC Shenandoah Epsilon(无用) 3.关于JDK1.8 1.8默认的垃圾回收器：PS+PO 1.8推荐用G1 4.CMS垃圾回收器 中文：concurrent mark sweep 沿着路线在前进：内存越来越大，卡顿时间越来越短 垃圾回收线程和工作线程可以一起并行工作。 大致六个阶段，主要有四个阶段：1.初始标记；2.并发标记；3.重新标记；4.并发清理 1.初始标记：STW的时间很短，降低STW时间；G1垃圾回收器在STW的时间更短 2.并发标记：会跟工作线程发生混乱，会发生错标的问题 3.并发预清理：查找执行并发标记阶段从年轻代晋升到老年代的对象 4.重新标记：修正那些错标的对象，remark阶段，必须从头扫描一遍，暂停虚拟机，扫描堆中的剩余对象 5.并发清理：也是并发执行，发生错标问题，但是没关系，下次循环可以解决 6.并发重置：重置CMS收集器的数据结构，等待下一次垃圾回收 对于三色标记算法产生的漏标问题：CMS的解决方案为：incremental update 5.G1垃圾回收器 既用于新生代，也可以用于老年代的垃圾回收器 使用复制+标记-整理算法进行回收 设计的目的是为了替换掉JDK5中发布的CMS垃圾回收期 并发+并行，使用多个CPU来缩短STW的停顿时间，与用户线程并发执行 分代收集，独立管理整个堆 空间整合，基于标记整理算法，解决了内存碎片的问题 可预测的停顿，能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为n毫秒的时间片段内消耗在垃圾收集上的时间不得超过n毫秒，这个n是可以设置的。 用到了读屏障和写屏障 对于三色标记算法产生的漏标问题，对应的算法为SATB 将整个Java堆内存划分成多个大小相等的Region区 年轻代和老年代不再物理隔离 5.触发fullGC的情况 老年代空间不足 永久代空间不足（jdk8之后没有了永久代，该条件不成立，取而代之的是元空间，目的是为了降低fullGC的频率，减少GC的负担，提升效率），只针对1.7 CMS GC时出现promotionfailed,concurrent mode failure MinorGC晋升到老年代平均大小大于老年代的剩余空间 调用System.gc(),不会立即回收，而是通知jvm进行回收，回收时机需要等底层进行 使用RMI来进行RPC或管理的JDK的应用，每小时执行一次FullGC 五.内存模型1.分代1.1 新生代 新生代就是刚刚new出来的对象 新生代可以理解为大多数一次垃圾回收就能回收掉的对象 在新生代里面用拷贝算法效率极高 年轻代分为三个区域：Eden、2个survivor(幸存者)。比例为：8:1:1 不能回收的对象在两个survivor区中来回存活，直到达到-XX:MaxTenuringThreshold设置的最大年龄则进入老年代，默认为16 CMS的默认的一个对象在新生代的最大年龄为16 新生代空间耗尽触发MinorGC/YGC1.2 老年代 老年代就是经过了好多次垃圾回收之后老是回收不了的对象 垃圾回收不容易回收掉的对象 在老年代一般用标记清除或者标记整理 在老年代无法继续分配空间时触发MajorGC/FullGC，新生代老年代同时进行回收 大对象直接放在老年代（有参数可以确定） 六.对象回收步骤 当new一个对象的时候，判断是否可以不在堆上进行分配（可以在栈上进行分配，只要栈pop之后，对象就可以直接被回收，不用被GC所回收），但是这个栈上的对象有两个前提：逃逸分析(一个方法中的对象不能被另一个方法所引用)和标量替换(基础数据类型) 如果对象是个大对象，直接放到老年代 如果不是大对象，不管是不是TLAB（线程本地分配缓冲区），都会进入Eden区，然后进行GC清除，能清除的直接清除。清除不了的进入survivor1区域，年龄够了进入老年代，年龄不够进入survivor2，循环往复。 七.GC常用参数 -Xmn:年轻代 -Xms:最小堆内存 -Xmx:最大堆内存 -Xss:栈空间关于G1的参数 -XX:+UseG1GC -XX:MaxGCPauseMillis(建议值，G1会尝试调整young区的块数来达到这个值) -XX:GCPauseIntervalMillis(GC的间隔时间)","categories":[{"name":"Java","slug":"Java","permalink":"https://utinner.gitee.io/categories/Java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://utinner.gitee.io/tags/JVM/"}]},{"title":"计算机内存","slug":"计算机内存","date":"2020-10-26T19:29:33.000Z","updated":"2021-12-06T09:23:00.920Z","comments":true,"path":"2020/10/27/计算机内存/","link":"","permalink":"https://utinner.gitee.io/2020/10/27/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%86%85%E5%AD%98/","excerpt":"存储器的层次结构 L0:寄存器（最快、最小、成本最高） L1:高速缓存 L2:高速缓存 L3:高速缓存 L4:主存 L5:磁盘 L6:远程文件存储","text":"存储器的层次结构 L0:寄存器（最快、最小、成本最高） L1:高速缓存 L2:高速缓存 L3:高速缓存 L4:主存 L5:磁盘 L6:远程文件存储 多核CPUL1、L2、L3缓存和内存结构和读取逻辑 ALU在读取数据的时候会先从L1中取，L1没有读L2,L2没有读L3,L3还没有则直接从主存中去读。 L1和L2位于一个CPU核的内部 每颗CPU里面有一个三级缓存，在一颗CPU的每个核中是共享的 每次拿数据的时候都是按块读取，一块的大小大概是64字节 缓存行的概念","categories":[{"name":"计算机基础","slug":"计算机基础","permalink":"https://utinner.gitee.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"基础知识","slug":"基础知识","permalink":"https://utinner.gitee.io/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"}]},{"title":"Java的四种引用","slug":"Java的四种引用","date":"2020-10-26T17:22:01.000Z","updated":"2021-12-06T09:23:00.725Z","comments":true,"path":"2020/10/27/Java的四种引用/","link":"","permalink":"https://utinner.gitee.io/2020/10/27/Java%E7%9A%84%E5%9B%9B%E7%A7%8D%E5%BC%95%E7%94%A8/","excerpt":"Java里面有四种引用类型：强、软、弱、虚 一.强引用就是我们普通的引用。作为一个垃圾来说，什么时候才会被回收呢？当一个对象实例没有任何引用指向它的时候，它就是可以被回收的。当对象被回收的时候，会调用对象的finalize方法。 最普遍的引用：Object obj = new Object 抛出OutOfMemoryError终止程序也不会回收具有强引用的对象 通过将对象设置为null来弱化引用，使其被回收","text":"Java里面有四种引用类型：强、软、弱、虚 一.强引用就是我们普通的引用。作为一个垃圾来说，什么时候才会被回收呢？当一个对象实例没有任何引用指向它的时候，它就是可以被回收的。当对象被回收的时候，会调用对象的finalize方法。 最普遍的引用：Object obj = new Object 抛出OutOfMemoryError终止程序也不会回收具有强引用的对象 通过将对象设置为null来弱化引用，使其被回收 二.软引用代码： 1234567891011121314151617181920public class T_SoftReference &#123; public static void main(String[] args) &#123; SoftReference&lt;byte[]&gt; m = new SoftReference&lt;&gt;(new byte[1024 * 1024 *10]); System.out.println(m.get()); System.gc(); try &#123; Thread.sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(m.get()); //再分配一个数组，heap将装不下，这时候系统会垃圾回收，先回收一次，如果不够，会把软引用干掉 byte[] b = new byte[1024*1024*15]; System.out.println(m.get()); &#125;&#125;//软引用非常适合缓存使用 运行： 123456参数：-Xmx24M输出：[B@5387f9e0[B@5387f9e0null 软引用不会立即被垃圾回收器回收，只有当堆内存不足时，会将软引用的对象进行回收，软引用可以用来做缓存使用。 对象处在有用但非必须的状态 只有当内存空间不足时，GC会回收该引用对象的内存 可以实现高速缓存 三.弱引用弱引用只要被gc看到，就会立即回收这个对象。 非必须的对象，比软引用更弱一些 GC时会被回收 被回收的概率也不大，因为GC线程优先级比较低 适用于引用偶尔被使用且不影响垃圾收集的对象 ThreadLocal threadLocal隶属于一个线程，每个thread中都有一个ThreadLocalMap对象，这个对象以当前线程的threadlocal对象为key，要set的值为value进行存储，当get的时候先拿到当前线程，然后根据当前线程拿到ThreadLocalMap对象，然后根据threadlocal这个key拿到对应的值 而当我们set值的时候，是对entry进行set值操作，这个Entry对象继承了WeakReference，而这个entry里面的key指向了threadLocal对象，是一个弱引用。 为什么entry中的key要弱引用thread对象？如果是强引用的话，当我们的tl不用的时候(将tl = null)那么在我们的内存中，始终有一个key指向内存中的threadLocal对象，那么就不会被回收，就会发生内存泄漏问题。而弱引用就不会。 但是还是有内存泄漏存在，Threadlocal被回收，key的值变为null，则导致整value再也无法被访问到，因此依然存在内存泄漏。当你不想用这个数据的时候，需要调用tl.remove(). ！注意：线程池慎用ThreadLocal！！！ 四.虚引用 不会决定对象的生命周期 任何时候都可能会被垃圾回收期回收 主要跟踪对象被垃圾回收期回收的活动，起哨兵作用 必须与引用队列ReferenceQueue联合使用 gc在发现虚引用的对象的时候并不会真正地将其回收，而是会将他的引用放到引用队列中，作为垃圾回收线程会不断地去检查这个队列，发现什么时候有虚引用指向了一个对象，才会对其进行回收。 用途：在于管理直接内存，堆外内存。 五.引用队列（ReferenceQueue） 无实际存储结构，存储逻辑依赖于内部节点之间的关系来表达 存储关联的且被GC的软引用、弱引用及虚引用","categories":[{"name":"Java","slug":"Java","permalink":"https://utinner.gitee.io/categories/Java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://utinner.gitee.io/tags/JVM/"}]},{"title":"多线程相关面试题","slug":"多线程相关面试题","date":"2020-10-23T05:40:34.000Z","updated":"2021-12-06T09:23:00.903Z","comments":true,"path":"2020/10/23/多线程相关面试题/","link":"","permalink":"https://utinner.gitee.io/2020/10/23/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%9B%B8%E5%85%B3%E9%9D%A2%E8%AF%95%E9%A2%98/","excerpt":"Java中进程和线程的关系Java对操作系统提供的功能进行封装，包括进程和线程运行一个程序会产生一个进程，进程包含至少一个线程每个进程对应一个JVM实例，多个线程共享JVM里的堆Java采用单线程编程模型，程序会自动创建主线程主线程可以创建子线程，原则上要后于子线程完成执行","text":"Java中进程和线程的关系Java对操作系统提供的功能进行封装，包括进程和线程运行一个程序会产生一个进程，进程包含至少一个线程每个进程对应一个JVM实例，多个线程共享JVM里的堆Java采用单线程编程模型，程序会自动创建主线程主线程可以创建子线程，原则上要后于子线程完成执行 start和run方法的区别调用start()方法会创建一个新的子线程并启动run()方法只是Thread的一个普通方法的调用start()方法会去调用start0()方法，是一个native方法，底层是调用JVM_StartThread方法创建一个线程去调用run方法 Thread和Runnable是什么关系？Thread是一个类，这个类实现了Runnable接口，使得run支持多线程因类的单一继承原则，推荐多使用Runnable接口 如何给run()方法传参？构造函数传参成员变量传参回调函数传参 如何实现处理线程的返回值？1.主线程等待法：让主线程循环等待，直到目标子线程返回为止12345678910111213141516171819202122232425 public class CycleWait implements Runnable &#123; private String value; @Override public void run() &#123; try &#123; Thread.currentThread().sleep(5000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; value = &quot;we have data now&quot;; &#125; public static void main(String[] args) throws InterruptedException &#123; CycleWait cycleWait = new CycleWait(); Thread t = new Thread(cycleWait); t.start(); while (cycleWait.value == null)&#123; Thread.currentThread().sleep(100); &#125; System.out.println(&quot;value:&quot;+ cycleWait.value); &#125;&#125; 2.使用Thread类的join方法阻塞当前线程以等待子线程处理完毕3.通过Callable接口实现，通过FutureTask或者线程池获取线程的六个状态 新建(new)：创建后尚未启动的线程的状态 运行(Runnable):包含Running和Ready 无限等待(WAITING)：不会被分配CPU执行时间，需要显式被唤醒 没有设置Timeout参数的Object.wait()方法 没有设置Timeout参数的Thread.join()方法 LockSupport.park()方法 限期等待(TIMED_WAITING)：在一定时间后会由系统自动唤醒 Thread.sleep()方法 设置了Timeout参数的Object.wait()方法 设置了Timeout参数的Thread.join()方法 LockSupport.parkNanos()方法 LockSupport.parkUntil()方法 阻塞(BLOCKED):等待获取排他锁 结束(TERMINATED):已终止线程的状态，线程已经执行结束。一个线程处于结束状态就不能进行start()了 阻塞状态与等待方法的区别：阻塞状态在等待获取排他锁，这个事件将在一个线程放弃这个锁的时候发生等待状态是等待一段时间或者有唤醒动作的时候发生在程序等待进入同步区域的时候，线程将进入阻塞状态，比如当某个线程进入synchronized关键字修饰的方法（即获取锁去执行）的时候，其他想执行该方法的线程就只能等着，他们的状态就是BLOCKED sleep和wait的区别sleep是Thread类的方法，wait是Object类中定义的方法sleep是可以在任何地方去使用的wait方法只能在synchronized方法或synchronized代码块中使用Thread.sleep只会让出CPU，不会导致锁行为的改变Object.wait不仅让出CPU，还会释放已经占有的同步资源锁 notify和notifyAll的区别notifyAll会让所有处于等待池的线程全部进入锁池去竞争获取锁的机会notify只会随机选取一个处于等待池中的线程进入锁池去竞争获取锁的机会 1.两个概念锁池EntryList假设线程A已经拥有了某个对象的锁，而其他线程B、C想要调用这个对象的某个synchronized方法，由于B、C线程在进入对象的synchronized方法之前必须先获取该对象锁的拥有权，而恰巧该对象的锁目前正在被线程A锁占用，此时B、C线程就会被阻塞，进入一个地方去等待锁的释放，这个地方便是该对象的锁池等待池WaitSet假设线程A调用了某个对象的wait()方法，线程A就会释放该对象的锁，同时线程A就进入到了该对象的等待池中，进入到等待池中的线程不会竞争该对象的锁 yield当调用Thread.yield()函数时，会给线程调度器一个当前线程愿意让出CPU使用权的暗示，但是线程调度器可能会忽略这个暗示 如何中断线程1.已经被抛弃的方法通过调用stop()方法停止线程，可以由一个线程去停止另一个线程，这个方法太过暴力而且不安全通过调用线程实例的suspend()和resume()方法 2.目前使用的方法 调用interrupt()，通知线程应该中断了 1.如果一个线程处于被阻塞状态，那么线程将立即退出被阻塞状态，并抛出一个InterruptedException异常2.如果线程处于正常活动状态，那么会将该线程的中断标志设置为true。被设置中断标志的线程将继续正常运行，不受影响","categories":[{"name":"面试题","slug":"面试题","permalink":"https://utinner.gitee.io/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[{"name":"面试题","slug":"面试题","permalink":"https://utinner.gitee.io/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"}]},{"title":"面试准备","slug":"面试题","date":"2020-10-22T16:45:13.000Z","updated":"2021-12-06T09:23:00.938Z","comments":true,"path":"2020/10/23/面试题/","link":"","permalink":"https://utinner.gitee.io/2020/10/23/%E9%9D%A2%E8%AF%95%E9%A2%98/","excerpt":"一.基础1.hashmapHashMap是基于哈希表的Map接口的非同步实现。此实现提供所有可选的映射操作，并且允许null键和null值。不保证顺序。 1.1 7与8的区别hashmap初始容量都是16，扩容因子是0.75倍.当元素的数量达到了16*0.75=12的时候，会进行扩容。底层：数组+链表。数组中的元素存放的是entry的引用 jdk8中会将链表转化为红黑树（红黑树的查询插入效率介于链表和二叉树之间） 新节点插入链表的顺序不同（jdk7是插入头节点，jdk8因为要遍历链表把链表变为红黑树所以采用插入尾结点） hash算法简化。因为使用了红黑树，即使散列不均匀查询效率也不会很低。 resize的逻辑修改（jdk7会出现死循环，jdk8不会），resize方法完成了初始化和扩容。","text":"一.基础1.hashmapHashMap是基于哈希表的Map接口的非同步实现。此实现提供所有可选的映射操作，并且允许null键和null值。不保证顺序。 1.1 7与8的区别hashmap初始容量都是16，扩容因子是0.75倍.当元素的数量达到了16*0.75=12的时候，会进行扩容。底层：数组+链表。数组中的元素存放的是entry的引用 jdk8中会将链表转化为红黑树（红黑树的查询插入效率介于链表和二叉树之间） 新节点插入链表的顺序不同（jdk7是插入头节点，jdk8因为要遍历链表把链表变为红黑树所以采用插入尾结点） hash算法简化。因为使用了红黑树，即使散列不均匀查询效率也不会很低。 resize的逻辑修改（jdk7会出现死循环，jdk8不会），resize方法完成了初始化和扩容。 1.在put的时候一开始初始化的时候要用比阈值大的2的次方数。 2.在hash算法中，首先对其key的hashcode进行抑或操作，目的就是控制散列值在数组size中，但是在抑或之后还要对key的hashcode进行右移，目的就是让其高位参与运算，使得散列更为均匀。 3.jdk1.7中在对hashmap进行扩容的时候，由于使用的是头插法，就可能会导致出现死循环的问题，发生死锁。因为1.7是循环遍历，1.8是先判断元素是要放在高位还是低位，然后将low的元素和high的元素分别组合起来放到新的扩容数组中 4.jdk1.8当hash相同的链表中的node超过阈值（8）的时候并且数组的长度小于64的时候，会进行扩容；如果数组的长度大于64，会将当前下标指向的这个链表转化为红黑树。 5.链表转化为红黑树：先比较key的hashcode；如果相同则去看key有没有实现comparable接口，如果实现了则进行比较；如果没有实现或者相同，则会比较key的class的名字；如果key的className相同则会调同System.identityHashcode方法去进行比较jvm内部的hashcode。然后根据插入的元素进行红黑树root节点的调整。一个node节点既是红黑树的节点，同时也是双向链表的节点，因为它继承了hashmap的entry类。扩容的时候遍历双向链表，同样先判断元素是要放在高位还是低位. 1.2遍历方式12345678910111213Iterator&lt;Map.Entry&lt;String, Integer&gt;&gt; entryIterator = map.entrySet().iterator(); while (entryIterator.hasNext()) &#123; Map.Entry&lt;String, Integer&gt; next = entryIterator.next(); System.out.println(&quot;key=&quot; + next.getKey() + &quot; value=&quot; + next.getValue()); &#125;Iterator&lt;String&gt; iterator = map.keySet().iterator(); while (iterator.hasNext())&#123; String key = iterator.next(); System.out.println(&quot;key=&quot; + key + &quot; value=&quot; + map.get(key)); &#125; 2.Concurrenthashmapjdk1.7 如图所示，是由 Segment 数组、HashEntry 组成，和 HashMap 一样，仍然是数组加链表。 它的核心成员变量： 123456 /** * Segment 数组，存放数据时首先需要定位到具体的 Segment 中。 */ final Segment&lt;K,V&gt;[] segments; transient Set&lt;K&gt; keySet; transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet; 和 HashMap 非常类似，唯一的区别就是其中的核心数据如 value ，以及链表都是 volatile 修饰的，保证了获取时的可见性。 原理上来说：ConcurrentHashMap 采用了分段锁技术，其中 Segment 继承于 ReentrantLock。不会像 HashTable 那样不管是 put 还是 get 操作都需要做同步处理，理论上 ConcurrentHashMap 支持 CurrencyLevel (Segment 数组数量)的线程并发。每当一个线程占用锁访问一个 Segment 时，不会影响到其他的 Segment。 [put] 将当前 Segment 中的 table 通过 key 的 hashcode 定位到 HashEntry。 遍历该 HashEntry，如果不为空则判断传入的 key 和当前遍历的 key 是否相等，相等则覆盖旧的 value。 不为空则需要新建一个 HashEntry 并加入到 Segment 中，同时会先判断是否需要扩容。 最后会解除在 1 中所获取当前 Segment 的锁 [get] 只需要将 Key 通过 Hash 之后定位到具体的 Segment ，再通过一次 Hash 定位到具体的元素上。 由于 HashEntry 中的 value 属性是用 volatile 关键词修饰的，保证了内存可见性，所以每次获取时都是最新值。 ConcurrentHashMap 的 get 方法是非常高效的，因为整个过程都不需要加锁。 jdk1.8抛弃了原有的 Segment 分段锁，而采用了 CAS + synchronized 来保证并发安全性。 也将 1.7 中存放数据的 HashEntry 改为 Node，但作用都是相同的。 其中的 val next 都用了 volatile 修饰，保证了可见性。 [put] 根据 key 计算出 hashcode 。 判断是否需要进行初始化。 f 即为当前 key 定位出的 Node，如果为空表示当前位置可以写入数据，利用 CAS 尝试写入，失败则自旋保证成功。 如果当前位置的 hashcode == MOVED == -1,则需要进行扩容。 如果都不满足，则利用 synchronized 锁写入数据。 如果数量大于 TREEIFY_THRESHOLD 则要转换为红黑树。 [get] 根据计算出来的 hashcode 寻址，如果就在桶上那么直接返回值。 如果是红黑树那就按照树的方式获取值。 不满足那就按照链表的方式遍历获取值。 1.8 在 1.7 的数据结构上做了大的改动，采用红黑树之后可以保证查询效率（O(logn)），甚至取消了 ReentrantLock 改为了 synchronized，这样可以看出在新版的 JDK 中对 synchronized 优化是很到位的。 3.内存相关3.1 对象在内存中的布局：（4部分） markword :标记字，8字节（64位的话，给8字节），记录的是锁信息、hashcode、gc垃圾回收信息 class pointer:类型指针。（创建一个Object类型，就是Object.class） instance data:实例数据，一个类中的成员变量（8种基本数据类型和引用数据类型） padding:对齐，为了能够让上述三部分相加起来的字节数能够让8整除，多添加几个字节，目的是为了提高cpu的利用率。 一个Object对象，占16个字节，8个标记字，4个class pointer,还有4个对齐 3.2 锁升级java上的实现都是小端在前，大端在后；网络上的实现都是大端在前 new出来对象之后，优先上的锁叫偏向锁，偏向第一个进去做事的线程。偏向锁的意思就是当前线程的指针被记录在了markword里面，偏向锁严格来讲不是一把锁，它就是一个标志，表示这个锁归我了。 偏向锁不需要锁竞争，只需要第一个来的线程就直接给他上了这个锁，没有竞争，就少了同步，效率就会提升。 为什么要设计偏向锁？ 设计偏向锁的原因在于提高效率，因为这个锁相当于给了一个标记，标记它不需要去参与竞争。 如果第二个线程来了怎么办？ 1&gt;这个时候锁升级，升级为自旋锁（轻量级锁）。2&gt;自旋锁又会升级为重量级锁 那么什么时候自旋锁会升级为重量级锁？ 竞争加剧：有一个线程超过10次自旋，或者自旋线程超过CPU核数的一半，就会升级。1.6之后，加入自适应自旋AdapativeSlefSpinning，JVM自己控制 3.2.1 自旋锁和重量级锁的区别自旋是发生在用户空间的，它不经过os对线程的调度。一般来讲，只要调用了wait()、notify()等方法，就进入到了重量级锁的状态了。重量级状态是什么状态呢？这把锁，附着着一个队列，这个队列的专业叫法叫waitSet,waitSet这里面的线程都是排好队的，等着操作系统调度才能拿到锁，这个waitSet就是等待队列。区别就在于，自旋锁是大家相互抢，谁抢着锁算谁的，而重量级锁是大家都进入到一个等待队列中去，等着操作系统老大去进行调度拿锁。自旋锁在等待的时候消耗cpu资源，而重量级锁在等待的时候不需要消耗cpu资源。 3.2.2 偏向锁的时延：偏向锁是在jvm启动之后的4秒后开始启动，偏向锁启动之后，给对象上的偏向锁都是匿名偏向。为什么是4秒？原因是jvm启动的过程一定会有锁竞争，因此就没有必要启动这把偏向锁，等jvm启动之后，再启动偏向锁 3.2.3 偏向锁的效率是不是一定比自旋锁的效率高？打开偏向锁是不是效率一定会提升？不一定，因为偏向锁是希望没有锁竞争的，但是如果你明明知道会有锁竞争，还去加偏向锁，没有任何意义。 注意：偏向锁是锁的类型，可重入锁是锁的机制，两个不是一个概念。 3.3 volatile关键字作用： 1、线程间可见 A线程将变量的值更改了，另一个线程需要知道 2、禁止指令重排序 指令重排序：在程序运行中，可能后面的代码比前面的代码先执行（前提是后面的代码不依赖于前面的代码情况下，为了提高cpu利用率，会这样运行） 禁止重排序原理：在两条指令中间加了一层屏障：JSR内存屏障（分四种：LoadLoad屏障、StoreStore屏障、LoadStore屏障、StoreLoad屏障） load是读，store是写 3.3.1 汇编语言的lock指令: 用于在多处理器中执行指令时对共享内存的独占使用 它的作用是能够将当前处理器对应缓存的内容刷新到内存，并使其他处理器对应的缓存失效。 另外还提供了有序的指令无法越过这个内存屏障的作用。 lock addl实现了volatile的两个作用 3.4 Java和go Java的线程和内核线程是一对一的。 Go的线程和内核是M:N的，而且M远大于N Java中的线程池：forkjoinPool,每一个线程都有自己的任务队列，但是任务和任务之间它们是不能做同步的，就是说我这个任务执行完了才能执行下一个任务。但是go的routin任务和任务之间是可以同步的，在用户空间模拟了cpu的执行，有类似保存现场恢复现场的功能。 二.设计模式1.单例模式1.1 饿汉 对外提供一个返回该实例的方法，static用来在jvm启动过程中去创建对象，构造方法私有化，以此来保证在程序运行过程中用到的对象都是只有一个实例。 类加载到内存后，就会实例化一个单例，JVM保证线程安全。 简单实用，推荐使用。 唯一缺点：类装载的时候就完成实例化，不管你是否需要用到它。 1.2懒汉： 什么时候需要用，才会将这个实例给new出来，但是是线程不安全的，因为同一时刻如果多个线程都需要这个实例，产生出来的就不止一个对象，很简单的优化方式就是加synchronized锁，以此来保证只有一个实例。 但是这种锁的粒度太大了，如果在getInstance方法中有业务代码，那么会锁定相关的业务代码。所以就牵涉到一个优化问题 引入DCL：double check lock 相关代码如下： 12345678910111213141516public class Mgr01 &#123; private static volatile Mgr01 INSTANCE; private Mgr01()&#123; &#125; public static Mgr01 getInstance()&#123; if(INSTANCE == null)&#123; synchronized (Mgr01.class)&#123; if (INSTANCE == null )&#123; INSTANCE = new Mgr01(); &#125; &#125; &#125; return INSTANCE; &#125;&#125; DCl不能乱序，所以DCL一定要加volatile。因为在初始化一个对象的时候，在汇编层面有5条指令，大体的流程就是：开辟内存空间-&gt;成员变量初始化-&gt;引用绑定，之所以要用volatile就是为了不让其指令发生重排序，如果不加的话，可能第二步和第三步发生指令重排序，导致成员没有初始化就将引用绑定给变量了，那么其他线程用这个类的实例的时候就会出现问题。 三、存储层1.Mysql1.1 隔离级别 读未提交 脏读 读已提交 不可重复读 可重复度*（mysql默认的隔离级别） 幻读 可序列化 1.2 事务隔离级别实现原理1.2.1 事务隔离的实现-mvcc，多版本并发控制在mysql中，不管一个表的数据结构定义成什么样，都会有两个隐藏列： trx_id:每次对某条聚簇索引记录进行改动时，都会把对应的事务id赋值给trx_id隐藏列。 roll_pointer:每次对某条聚簇索引记录进行改动时，都会把旧的版本写入到undo日志中，然后这个隐藏列就相当于一个指针，可以通过它来找到该记录修改前的信息。 mvcc的流程 1.事务在查询数据之前，会生成数据库系统当前的一个快照（read view），记录并维护系统当前活跃事务的ID,快照里面存着的是当前时间活跃的事务id 2.把快照比作条件用来判断当前事务能够看到哪个版本的数据 3.快照是在查询数据时生成的。 总结：拿着数据比对版本，而不是拿着版本找数据。 不同的隔离级别底层就是因为他们的快照不一样。 读未提交就是根本没有快照，每次修改了不用提交就是一个新的版本。每次读都是一次全新的搜索 可重复读是在第一次查询数据的时候生成一次快照，只要我还没提交，我就不会改变我的快照，所以叫可重复读。 序列化就是我不存在快照，就是串行执行，没有并发的概念。 1.2 幻读是什么？ 幻读主要体现在读-写冲突上，而不可重复读主要体现在读-读冲突上 比如A事务开启之后，读了4条数据，而B事务同时插入了命中A查询条件中的一条数据。A查询之后进行了update，update语句是不会去管快照的，他会直接从B-tree上去读数据，但是这个时候B-tree上有5条数据，它的快照上还是4条，更新之后再次查询，查出了5条，这种现象就是幻读。 为什么是5条？因为在update的时候在trx_id这个隐藏列中有了A事务的事务id，所以在更新之后查询能查得到。 1.3 锁 行锁，表锁—-&gt;锁的粒度 乐观锁，悲观锁—-&gt;锁的时机 共享锁，排他锁—-&gt;锁的兼容性 mysql的官方文档中有8种锁模式 索引锁 记录存在与否和事务加锁成功与否无关，如SELECT * FROM user WHERE id = 5 FOR UPDATE，此时id=5的记录不存在，隔壁事务仍然无法插入记录（假设当前自增的主键id已经是4了）。因为锁定的是索引，故记录实体存在与否没关系。 间隙锁 临键锁 间隙锁一定是开区间，临键锁是是一个左开右闭的区间 间隙锁是不互斥的，即两个事务可以同时持有包含共同间隙的间隙锁。 在RR级别下，如果你使用select … in share mode或者select … for update语句，那么InnoDB会使用临键锁，因而可以防止幻读 共享锁/排他锁 意向共享锁/意向排他锁 共享锁/排他锁都只是行锁，意向共享锁/意向排他锁属于表锁 取得意向共享锁/意向排他锁是取得共享锁/排他锁的前置条件 一个事务在请求共享锁/排他锁时，获取到的结果却可能是行锁，也可能是间隙锁，也可能是临键锁 插入意向锁 插入意向锁是一种特殊的间隙锁 两个事务却不能在同一时间内一个拥有间隙锁，另一个拥有该间隙区间内的插入意向锁（当然，插入意向锁如果不在间隙锁区间内则是可以的） 自增锁 预测锁 自增锁是一种特殊的表级锁，主要用于事务中插入自增字段，也就是我们最常用的自增主键id。 自增锁有3种模式，决定了并发自增时并发的自增语句如何持有锁 四.Java底层1.锁 引入锁，目的是为了保证数据一致性。 锁住的一定是一个对象，而且同一时刻只能有一个线程拥有锁去做业务逻辑处理 2.不持有锁的线程怎么办？ 自旋：轻量级锁。 进入等待队列，等待操作系统调度，这个时候是重量级锁。 3.synchronized关键字 1.在早期1.0~1.2的时候，操作系统会接管对应的线程，是个重量级锁，效率非常低。 2.jdk1.5之后，诞生了JUC包 3.锁升级：偏向锁（没有竞争）—&gt;轻量级锁（重量级锁）—&gt;重量级锁 3.1 AtomicInteger incrementAndGet()用到的就是自旋锁。在这个方法的底层调用的是compareAndSwapInt，比较并交换，简写为CAS. 什么叫CAS？ CAS不需要操作系统的调度，只需要在用户空间即可解决。 3.2 CAS两大面试题3.2.1 ABA问题加版本号即可解决3.2.2 CAS修改值的时候的原子性问题 Q:当线程A在判断原值E是否是原值之后，还没有修改之前，如何保证没有其他线程B对其变量进行修改？ A:CAS在最底层是用lock cmpxchg指令来支撑的。在多核cpu下，lock指令是锁总线的作用。最终的CAS实现就是这条指令。 4.生成一个对象的过程？至少需要三步： 1.申请内存空间，用来装new出来的对象。 2.调用构造方法，从默认值变成初始值，此时是半初始化状态 3.建立引用连接 5.happens-before原则（JVM规定重排序必须遵守的原则） as if serial:不管如何重排序，单线程执行结果不会改变","categories":[{"name":"面试题","slug":"面试题","permalink":"https://utinner.gitee.io/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[{"name":"面试题","slug":"面试题","permalink":"https://utinner.gitee.io/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"}]},{"title":"分布式一致性问题","slug":"分布式一致性问题","date":"2020-08-17T09:53:50.000Z","updated":"2021-12-06T09:23:00.895Z","comments":true,"path":"2020/08/17/分布式一致性问题/","link":"","permalink":"https://utinner.gitee.io/2020/08/17/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7%E9%97%AE%E9%A2%98/","excerpt":"分布式事务一致性框架与分布式系统一致性算法分布式事务一致性框架： 核心就是解决我们在实际系统中产生跨事务导致分布式事务的问题，核心靠的是最终一致性。比如：rocketMq事务消息、rabbitmq补单、lcn、seata等。分布式系统一致性算法： 解决我们系统之间集群之后每隔节点保持数据的一致性。比如：raft、zab、paxos等分布式系统一致性算法应用于系统软件实现集群保持每隔节点数据的同步性。保持我们的集群中每个节点的数据的一致性问题。","text":"分布式事务一致性框架与分布式系统一致性算法分布式事务一致性框架： 核心就是解决我们在实际系统中产生跨事务导致分布式事务的问题，核心靠的是最终一致性。比如：rocketMq事务消息、rabbitmq补单、lcn、seata等。分布式系统一致性算法： 解决我们系统之间集群之后每隔节点保持数据的一致性。比如：raft、zab、paxos等分布式系统一致性算法应用于系统软件实现集群保持每隔节点数据的同步性。保持我们的集群中每个节点的数据的一致性问题。 相关算法在集群环境下，如何去进行领导角色的选举？由以下两个选举算法： 1、rap协议 对每个结点配置一个myid或者serverid，数值越大表示能力越强，或者随机时间 整个集群中为了保持数据的一致性的问题，必须满足大多数情况下&gt; n/2+1,可运行的节点环境才可以使用 ZAP的协议实现原理是通过比较myid，myid谁最大谁就最可能是领导角色，只要满足过半的机制就可以成为领导角色，后来启动的节点不会参与选举的。 ZAP如何保持数据的一致性问题： 所有写的请求统一交给我们的领导角色实现，领导角色写完数据之后，领导角色再将数据同步给每个节点。数据之间同步采用2pc两阶段提交协议。 选举过程： 先去比较zxid，zxid谁最大谁就为领导角色 如果zxid相等的情况下，myid谁最大谁就为领导角色。 关于zxid和2pc两阶段提交协议 zxid是每个节点都有的一个标记，所有的写请求都是交给主节点去进行操作的，当主节点操作完之后，会将zxid+1，然后同步给其他节点，其他节点确认自己本身能够将自己的zxid实现自增之后将确认信号给到主节点，当主节点全部收到确认信号之后将会通知所有节点进行zxid自增的操作。 2、Raft协议在Raft协议算法中分为三个角色|名词： 状态：分为三种：跟随者、竞选者（候选人）、领导角色 大多数：&gt;n/2+1 任期：每次选举一个新的领导角色，任期都会实现增加 竞选者谁的票数最多，谁就是领导角色 选举的过程是怎么样的？ 默认的情况下每个节点都是位跟随者 每个节点会随机地生成一个选举地超时时间，例如大概是100-300ms，在这个超时时间范围内必须要等待 超时时间过后，当前的节点状态可能由跟随者变为竞选者状态，会给其他的节点发出选举投票的通知，只要该竞选者有超过半数以上的票数即可选为领导角色核心的设计原理其实就是靠的谁的超时时间最短谁就有非常大的概率成为领导角色。 核心设计的原理：谁超时时间最短谁就有大概率地成为领导角色。 随机超时时间有可能一样的情况下： 1、如果所有地节点的超时随机数都是一样的情况下，当前投票全部作废，重新进入随机生成超时时间的状态 2、如果由多个节点生成的随机数都是一样的情况下，比较谁的票数最多，谁就是领导。如果票数完全一样的情况，直接作废，重新进入随机生成超时时间的状态。 建议:集群节点设为奇数 故障的重新选举： 如果我们的跟随者节点不能够及时地收到领导角色消息，那么这个时候跟随者就会将当前自己的状态由跟随者变为竞选者的角色，会给其他的节点发出选举投票的通知，只要该竞选者有超过半数以上的票数即可选为领导角色。 疑问：是否可能会产生两个同时的竞选者，同时实现拉票呢？ 当我们的节点为偶数的情况下，可能会存在该问题，如果两个竞选者获取的票数相等的情况下，开始重置竞选的超时时间，一直到谁的票数最多谁就为领导。 数据是如何保持一致性的？ 类似zap两阶段提交协议。 如何实现日志的复制？ 所有的写的请求都是统一地交给我们的领导角色完成的，写入该对应的日志，标记该日志为被提交状态。 为了提交该日志，领导角色就会将该日志以心跳的形式发送给其他的跟随者，只要满足过半的跟随者可以写入该数据，则会通知其他节点同步该数据，这个称作为日志复制。","categories":[{"name":"Java","slug":"Java","permalink":"https://utinner.gitee.io/categories/Java/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://utinner.gitee.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"Nacos和其他注册中心的比较","slug":"Nacos和其他注册中心的比较","date":"2020-08-17T09:10:18.000Z","updated":"2021-12-06T09:23:00.738Z","comments":true,"path":"2020/08/17/Nacos和其他注册中心的比较/","link":"","permalink":"https://utinner.gitee.io/2020/08/17/Nacos%E5%92%8C%E5%85%B6%E4%BB%96%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%E7%9A%84%E6%AF%94%E8%BE%83/","excerpt":"CAP定律这个定理的内容是指的是在一个分布式系统中、Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容错性），三者不可得兼。 一致性(C)： 在分布式系统中，如果服务器集群，每个节点在同时刻访问必须要保持数据的一致性。可用性(A)： 集群节点中，部分节点出现故障后任然可以使用 （高可用）分区容错性(P)： 在分布式系统中网络会存在脑裂的问题，部分Server与整个集群失去节点联系，无法组成一个群体。 只有在CP和AP选择一个平衡点 两种情况： CP情况下，虽然我们服务不能用，但是必须要保证数据的一致性 AP情况下，可以短暂保证数据不一致，但是最终可以一致性，不管怎么样，要保证我的服务可用。注册中心大多数采用AP 模式","text":"CAP定律这个定理的内容是指的是在一个分布式系统中、Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容错性），三者不可得兼。 一致性(C)： 在分布式系统中，如果服务器集群，每个节点在同时刻访问必须要保持数据的一致性。可用性(A)： 集群节点中，部分节点出现故障后任然可以使用 （高可用）分区容错性(P)： 在分布式系统中网络会存在脑裂的问题，部分Server与整个集群失去节点联系，无法组成一个群体。 只有在CP和AP选择一个平衡点 两种情况： CP情况下，虽然我们服务不能用，但是必须要保证数据的一致性 AP情况下，可以短暂保证数据不一致，但是最终可以一致性，不管怎么样，要保证我的服务可用。注册中心大多数采用AP 模式 Nacos、Eureka、Zookeeper比较相同点都可以实现分布式服务注册中心 不同点1.ZookeeperZookeeper采用CP保证数据一致性的问题，原理采用Zab原子广播协议，当我们的zk领导因为某种原因宕机的情况下，会自动触发重新选一个新的领导角色，整个选举的过程为了保证数据的一致性的问题，在选举的过程中整个zk环境是不可以使用的，可能短暂无法使用到zk，意味着微服务采用该模式的情况下可能无法实现通讯（本地有缓存除外）。ZK可以运行的节点必须满足过半机制，整个zk才可以使用。 2.EurekaEureka采用AP的设计理念架构注册中心，完全去中心化思想，也就是说没有主从之分。每个节点都是均等的，采用相互注册原理，你中有我我中有你，只要有最后有一个节点存在就可以保证整个微服务可以实现通讯。 中心化：必须要围绕一个领导角色为核心，选举为领导和跟随者角色去中心化：每个角色都是均等的 3.EurekaNacos从1.0版本支持CP和AP混合模式集群，默认是采用AP保证服务可用性，CP的形式底层集群通过raft协议保证数据的一致性问题。如果我们采用AP模式，注册服务的实例仅支持临时注册形式，在网络分区产生抖动的情况下，仍然可以继续注册我们的服务列表。如果选择CP模式，必须保证数据的强一致性问题，如果网络分区产生抖动的情况下，是无法注册我们的服务列表，但是选择CP模式可以支持注册实例持久。 什么情况下选择AP和CP呢？必须要求读取接口的地质保证强一致性的问题，可以采用CP模式，一般AP的情况是可以的。 如何实现切换模式？ 1$nacos_server:8848/nacos/v1/ns/operator/switches?entry=serverMode&amp;value=CP 注意： 必须是发送PUT请求！！！ 我们在使用注册中心时，可以允许读取的数据短暂不一致，但是要保证注册中心能够使用，可用性优先级最高。","categories":[{"name":"Java","slug":"Java","permalink":"https://utinner.gitee.io/categories/Java/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://utinner.gitee.io/tags/SpringCloud/"}]},{"title":"分布式配置中心","slug":"分布式配置中心","date":"2020-08-17T06:41:22.000Z","updated":"2021-12-06T09:23:00.898Z","comments":true,"path":"2020/08/17/分布式配置中心/","link":"","permalink":"https://utinner.gitee.io/2020/08/17/%E5%88%86%E5%B8%83%E5%BC%8F%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83/","excerpt":"一.分布式配置中心的作用分布式配置中心可以实现不需要重启我们的服务器，动态的修改我们的配置文件内容，常见的配置中心有携程的阿波罗、SpringCloud Config、Nacos轻量级的配置中心等。 轻量级： 部署、架构设计原理都比较简单，学习成本也比较低。重量级： 部署、架构设计、体积都非常大，学习成本比较高。","text":"一.分布式配置中心的作用分布式配置中心可以实现不需要重启我们的服务器，动态的修改我们的配置文件内容，常见的配置中心有携程的阿波罗、SpringCloud Config、Nacos轻量级的配置中心等。 轻量级： 部署、架构设计原理都比较简单，学习成本也比较低。重量级： 部署、架构设计、体积都非常大，学习成本比较高。 二.原理1、本地应用读取我们云端分布式配置中心文件（第一次建立长连接）2、本地应用读取到配置文件之后，本地jvm和硬盘中都会缓存一份3、本地应用与分布式配置中心服务端一直保持长连接4、当我们的配置文件发生变化（MD5|版本号）实现区分，将变化结果通知给我们的本地应用及时地刷新我们的配置文件。 完全百分百实现动态化修改我们的配置文件 三.代码实现1.新增配置文件 2.项目中添加依赖12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;version&gt;0.2.2.RELEASE&lt;/version&gt;&lt;/dependency&gt; 3.新建bootstrap.yml12345678910111213spring: cloud: nacos: discovery: server-addr: 127.0.0.1:8848 enabled: true config: ###配置中心连接地址 server-addr: 127.0.0.1:8848 ###分组 group: DEFAULT_GROUP ###类型 file-extension: yaml 4.代码1234567891011@RestController@RefreshScopepublic class UserServiceImpl implements UserService &#123; @Value(&quot;$&#123;tinner.name&#125;&quot;) private String tinnerName; @Override public String getUser(Integer userId) &#123; return tinnerName + &quot;我是会员服务&quot;; &#125;&#125; 5.注意事项 本地如果也配置相同的key，那么在启动的时候可能会抛出异常 可以实现动态实现@RefreshScope nacos在windows版本下运行默认是单机版本 需要指定startup.cmd -m cluster nacos在linux版本下运行默认是集群版本 如果想连接单机版本 startup.cmd –m standalone 6.bootstrap与application区别 bootstrap.yml 用于应用程序上下文的引导阶段。 application.yml 由父Spring ApplicationContext加载。 四.多版本控制1.新增prod配置文件 2.修改项目的配置文件 五. Nacos集群模式官方文档：https://nacos.io/en-us/docs/cluster-mode-quick-start.html视频教程：https://www.bilibili.com/video/BV1D7411A7Ru?p=43","categories":[{"name":"Java","slug":"Java","permalink":"https://utinner.gitee.io/categories/Java/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://utinner.gitee.io/tags/SpringCloud/"}]},{"title":"服务注册与发现nacos","slug":"服务注册与发现nacos","date":"2020-08-05T09:15:39.000Z","updated":"2021-12-06T09:23:00.906Z","comments":true,"path":"2020/08/05/服务注册与发现nacos/","link":"","permalink":"https://utinner.gitee.io/2020/08/05/%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E4%B8%8E%E5%8F%91%E7%8E%B0nacos/","excerpt":"服务治理基本的概念服务治理概念：在RPC远程调用过程中，服务与服务之间依赖关系非常大，服务Url地址管理非常复杂，所以这时候需要对我们服务的url实现治理，通过服务治理可以实现服务注册与发现、负载均衡、容错等。服务注册中心的概念每次调用该服务如果地址直接写死的话，一旦接口发生变化的情况下，这时候需要重新发布版本才可以该接口调用地址，所以需要一个注册中心统一管理我们的服务注册与发现。","text":"服务治理基本的概念服务治理概念：在RPC远程调用过程中，服务与服务之间依赖关系非常大，服务Url地址管理非常复杂，所以这时候需要对我们服务的url实现治理，通过服务治理可以实现服务注册与发现、负载均衡、容错等。服务注册中心的概念每次调用该服务如果地址直接写死的话，一旦接口发生变化的情况下，这时候需要重新发布版本才可以该接口调用地址，所以需要一个注册中心统一管理我们的服务注册与发现。 注册中心：我们的服务注册到我们注册中心，key为服务名称、value为该服务调用地址，该类型为集合类型。常用的注册中心有：Eureka、consul、zookeeper、nacos等。 服务注册:我们生产者项目启动的时候，会将当前服务自己的信息地址注册到注册中心。 服务发现:消费者从我们的注册中心上获取生产者调用的地址（集合），在使用负载均衡的策略获取集群中某个地址实现本地rpc远程调用。 微服务调用接口常用名词生产者： 提供接口被其他服务调用消费者： 调用生产者接口实现消费服务注册： 将当前服务地址注册服务发现： NacosNacos可以实现分布式服务注册与发现/分布式配置中心框架。官网的介绍: https://nacos.io/zh-cn/docs/what-is-nacos.html Nacos安装及基本操作：https://nacos.io/zh-cn/docs/quick-start.html","categories":[{"name":"Java","slug":"Java","permalink":"https://utinner.gitee.io/categories/Java/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://utinner.gitee.io/tags/SpringCloud/"}]},{"title":"作业帮面试题","slug":"作业帮面试题","date":"2020-08-03T08:48:14.000Z","updated":"2021-12-06T09:23:00.895Z","comments":true,"path":"2020/08/03/作业帮面试题/","link":"","permalink":"https://utinner.gitee.io/2020/08/03/%E4%BD%9C%E4%B8%9A%E5%B8%AE%E9%9D%A2%E8%AF%95%E9%A2%98/","excerpt":"作业帮的面试官是做python的，所以java基本也没怎么问，主要是问了最近做的项目，更多的是redis和算法、linux的相关命令等操作，详细列一下吧 算法题 1、手写二叉树的先序遍历2、给定义一个int数组（里面给的都是不重复的0-9的数字）和一个数字（这个数字是这个字符数组的随机组合）num，求出这个int数组所有随机排列组合的数字中比给定的num大的组合中，最小的一个例子：字符数组：[1,2,3,4,5]，num：34125。那么最终结果为：34152","text":"作业帮的面试官是做python的，所以java基本也没怎么问，主要是问了最近做的项目，更多的是redis和算法、linux的相关命令等操作，详细列一下吧 算法题 1、手写二叉树的先序遍历2、给定义一个int数组（里面给的都是不重复的0-9的数字）和一个数字（这个数字是这个字符数组的随机组合）num，求出这个int数组所有随机排列组合的数字中比给定的num大的组合中，最小的一个例子：字符数组：[1,2,3,4,5]，num：34125。那么最终结果为：34152 redis 你都用过哪几种数据结构？在项目中都是怎么用的 实现一个微博热搜榜的功能，有什么想法（实时性、海量数据两个维度去考虑） 什么样的数据需要进行哈希存取 mysql设计表，手写sql语句索引 数据结构B+树 ELK对于海量数据量，Elasticsearch的搜索如何做的 linux命令一个日志文件中有接口的请求地址和接口的请求时间，从小到大打印出每个接口的访问次数，降序排列。 网络一个http请求，是怎么打入到java服务中去，相关结果又是怎么返回给前端的。","categories":[{"name":"面试题","slug":"面试题","permalink":"https://utinner.gitee.io/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[{"name":"面试题","slug":"面试题","permalink":"https://utinner.gitee.io/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"}]},{"title":"Maven解决jar包冲突","slug":"Maven解决jar包冲突","date":"2020-07-13T09:31:28.000Z","updated":"2021-12-06T09:23:00.734Z","comments":true,"path":"2020/07/13/Maven解决jar包冲突/","link":"","permalink":"https://utinner.gitee.io/2020/07/13/Maven%E8%A7%A3%E5%86%B3jar%E5%8C%85%E5%86%B2%E7%AA%81/","excerpt":"一、Maven中jar包冲突产生原因MAVEN项目运行中如果报如下错误： Caused by:java.lang.NoSuchMethodError Caused by: java.lang.ClassNotFoundException十有八九是Maven jar包冲突造成的。那么jar包冲突是如何产生的？首先我们需要了解jar包依赖的传递性。1、依赖传递当我们需要A的依赖的时候，就会在pom.xml中引入A的jar包；而引入的A的jar包中可能又依赖B的jar包，这样Maven在解析pom.xml的时候，会依次将A、B 的jar包全部都引入进来。","text":"一、Maven中jar包冲突产生原因MAVEN项目运行中如果报如下错误： Caused by:java.lang.NoSuchMethodError Caused by: java.lang.ClassNotFoundException十有八九是Maven jar包冲突造成的。那么jar包冲突是如何产生的？首先我们需要了解jar包依赖的传递性。1、依赖传递当我们需要A的依赖的时候，就会在pom.xml中引入A的jar包；而引入的A的jar包中可能又依赖B的jar包，这样Maven在解析pom.xml的时候，会依次将A、B 的jar包全部都引入进来。 举个例子：在Spring Boot应用中导入Hystrix和原生Guava的jar包： 12345678910111213&lt;!--原生Guava API--&gt;&lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;20.0&lt;/version&gt;&lt;/dependency&gt;&lt;!--hystrix依赖（包含对Guava的依赖）--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;version&gt;1.4.4.RELEASE&lt;/version&gt;&lt;/dependency&gt; 利用Maven Helper插件得到项目导入的jar包依赖树：从图中可以看出Hystrix包含对Guava jar包依赖的引用： Hystrix -&gt; Guava，所以在引入Hystrix的依赖的时候，会将Guava的依赖也引入进来。 2.jar包冲突原理假设有如下依赖关系： A-&gt;B-&gt;C-&gt;D1(log 15.0)：A中包含对B的依赖，B中包含对C的依赖，C中包含对D1的依赖，假设是D1是日志jar包，version为15.0 E-&gt;F-&gt;D2(log 16.0)：E中包含对F的依赖，F包含对D2的依赖，假设是D2是同一个日志jar包，version为16.0 当pom.xml文件中引入A、E两个依赖后，根据Maven传递依赖的原则，D1、D2都会被引入，而D1、D2是同一个依赖D的不同版本。当我们在调用D2中的method1()方法，而D1中是15.0版本（method1可能是D升级后增加的方法），可能没有这个方法，这样JVM在加载A中D1依赖的时候，找不到method1方法，就会报NoSuchMethodError的错误，此时就产生了jar包冲突。 注： 如果在调用method2()方法的时候，D1、D2都含有这个方法（且升级的版本D2没有改动这个方法，这样即使D有多个版本，也不会产生版本冲突的问题。） 举个例子： 利用Maven Helper插件分析得出：Guava这个依赖包产生冲突。我们之前导入了Guava的原生jar包，版本号是20.0；而现在提示Guava产生冲突，且冲突发生位置是Hystrix所在的jar包，所以可以猜测Hystrix中包含了对Guava不同版本的jar包的引用。 为了验证我们的猜想，使用Maven Helper插件找到Hystrix依赖的jar： 可以看到：Hystrix jar中所依赖的Guava jar包是15.0版本的，而我们之前在pom.xml中引入的原生Guava jar包是20.0版本的，这样Guava就有15.0 与20.0这两个版本，因此发生了jar包冲突。 二、 Maven中jar包冲突的解决方案Maven 解析 pom.xml 文件时，同一个 jar 包只会保留一个，那么面对多个版本的jar包，需要怎么解决呢？ 1、 Maven默认处理策略最短路径优先 Maven 面对 D1 和 D2 时，会默认选择最短路径的那个 jar 包，即 D2。E-&gt;F-&gt;D2 比 A-&gt;B-&gt;C-&gt;D1 路径短 1。 最先声明优先 如果路径一样的话，如： A-&gt;B-&gt;C1, E-&gt;F-&gt;C2 ，两个依赖路径长度都是 2，那么就选择最先声明。 2、移除依赖：用于排除某项依赖的依赖jar包（1）我们可以借助Maven Helper插件中的Dependency Analyzer分析冲突的jar包，然后在对应标红版本的jar包上面点击execlude，就可以将该jar包排除出去。 再刷新以后冲突就会消失。 （2）手动排除或者手动在pom.xml中使用标签去排除冲突的jar包（上面利用插件Maven Helper中的execlude方法其实等同于该方法）： 123456789101112&lt;!--hystrix依赖（包含对Guava的依赖）--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;version&gt;1.4.4.RELEASE&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt; 3 版本锁定原则：一般用在继承项目的父项目中正常项目都是多模块的项目，如moduleA和moduleB共同依赖X这个依赖的话，那么可以将X抽取出来，同时设置其版本号，这样X依赖在升级的时候，不需要分别对moduleA和moduleB模块中的依赖X进行升级，避免太多地方（moduleC、moduleD….）引用X依赖的时候忘记升级造成jar包冲突，这也是实际项目开发中比较常见的方法。 首先定义一个父pom.xml，将公共依赖放在该pom.xml中进行声明： 12345678910111213&lt;properties&gt; &lt;spring.version&gt;spring4.2.4&lt;/spring.version&gt; &lt;properties&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.versio&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; 这样如moduleA和moduleB在引用Spring-beans jar包的时候，直接使用父pom.xml中定义的公共依赖就可以：moduleA在其pom.xml使用spring-bean的jar包(不用再定义版本)： 123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; moduleB在其pom.xml使用spring-bean的jar包如上类似： 123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 三、相关命令如果不用Maven Helper这个从插件，maven还支持用命令的方式进行分析jar包冲突： 1mvn dependency:tree 以上命令是输出到控制台，还可以输出到文件： 1mvn dependency:tree&gt;/Users/tinner/Desktop/1.txt 查询指定jar包的冲突: 1mvn dependency:tree -Dverbose -Dincludes=com.google.guava","categories":[{"name":"Java","slug":"Java","permalink":"https://utinner.gitee.io/categories/Java/"}],"tags":[{"name":"Maven","slug":"Maven","permalink":"https://utinner.gitee.io/tags/Maven/"}]},{"title":"git操作","slug":"git操作","date":"2020-07-13T09:31:28.000Z","updated":"2021-12-06T09:23:00.860Z","comments":true,"path":"2020/07/13/git操作/","link":"","permalink":"https://utinner.gitee.io/2020/07/13/git%E6%93%8D%E4%BD%9C/","excerpt":"基本操作就不说了，这里详细介绍其他中高级操作 ##### 1、查看日志 1git log","text":"基本操作就不说了，这里详细介绍其他中高级操作 ##### 1、查看日志 1git log 这个命令对于提交少的项目比较友好，但是对于提交很多的项目，会输出一大长串，很不方便，于是有一个比较简便的命令： 1git log --pretty=oneline 输出： ![git log](https://upload-images.jianshu.io/upload_images/15200008-45ddb710fbaa4feb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240) 2、撤销修改背景在一个文件中添加了一点代码，现在我git add .了但是没提交，现在我想撤销我修改的东西 解决方案两个命令： 123git reset HEAD src/main/java/com/tinner/demo03/constant/RedisContant.javagit checkout -- src/main/java/com/tinner/demo03/constant/RedisContant.java 效果 3、创建分支两个命令： 12git checkout -b devgit switch -c dev 4、删除分支1git branch -d &lt;name&gt; 如果要丢弃一个没有被合并过的分支，可以通过git branch -D &lt;name&gt;强行删除。 5、合并代码1git merge --no-ff -m &quot;注释。。。。&quot; &lt;分支名&gt; 6、stash背景在一个新的需求开发过程中，我在dev分支开发了一些东西，但是并没有提交我也不想提交，这个时候来了一个bug，我必须将bug改完才能进行dev的开发，那么这个时候就需要用到git stash命令步骤 首先，我看看git仓库中的状态可以看到，在dev分支，我创建了一个文件，修改了一个文件。 然后，使用git stash命令，之后再来查看状态：此时工作区是干净的。然后我切换到master分支，创建一个issue分支，解决bug，合并到master，发版，之后再切换到dev分支，可以看到我的工作区还是干净的，那么之前的代码跑哪去了？ 使用git stash list可以查看储藏的代码列表 现在我们需要恢复之前的代码，有两个命令可以参考：12git stash applygit stash pop git stash apply命令恢复后，stash内容并不删除，你需要用git stash drop来删除； 另一种方式是用git stash pop，恢复的同时把stash内容也删了 你可以多次stash，恢复的时候，先用git stash list查看，然后恢复指定的stash，用命令:1git stash apply stash@&#123;0&#125; 扩展我们知道，master的bug修复之后，在现在的dev代码相关的bug并没有修复，所以，这个bug其实在当前dev分支上也存在。如何快速修复？同样的bug，要在dev上修复，我们只需要把修复issuebug这个提交所做的修改“复制”到dev分支。注意：我们只想复制修复issuebug这个提交所做的修改，并不是把整个master分支merge过来。 为了方便操作，Git专门提供了一个cherry-pick命令，让我们能复制一个特定的提交到当前分支： 1git cherry-pick &lt;版本号&gt; 用git cherry-pick，我们就不需要在dev分支上手动再把修bug的过程重复一遍。 几个命令的区别merge和rebase的区别merge和rebase都是用来合并分支的。 采用merge和rebase后，git log的区别，merge命令不会保留merge的分支的commit： 处理冲突的方式：（一股脑）使用merge命令合并分支，解决完冲突，执行git add .和git commit -m ‘fix conflict’。这个时候会产生一个commit。（交互式）使用rebase命令合并分支，解决完冲突，执行git add .和git rebase –continue，不会产生额外的commit。这样的好处是”干净”，分支上不会有无意义的解决分支的commit；坏处：如果合并的分支中存在多个commit，需要重复处理多次冲突。git pull和git pull –rebasegit pull做了两个操作分别是获取和合并。所以加了rebase就是以rebase的方式进行合并分支，默认为merge。git merge 和 git merge –no-ff的区别git merge –no-ff 可以保存你之前的分支历史。能够更好的查看 merge历史，以及branch 状态。git merge 则不会显示 feature，只保留单条分支记录。 tag相关在当前分支的最新commit上打tag 1git tag v1.0 在f52c633版本的提交上打tag 1git tag v0.9 f52c633 查看所有的tag 1git tag 注意，标签不是按时间顺序列出，而是按字母排序的 还可以创建带有说明的标签，用-a指定标签名，-m指定说明文字： 1git tag -a v0.1 -m &quot;文字说明&quot; 1094adb 用命令git show &lt;tagname&gt;可以看到说明文字提交v1.0标签 1git push origin v1.0 提交所有的标签 1git push origin --tags 从本地删除tag： 1git tag -d v0.9 删除远程tag： 1git push origin :refs/tags/v0.9 Git HEAD^与HEAD~的关系一张图： Git reset后面跟的参数比如我在我的本地目录下面新建了一个文件c.txt，add到了我的暂存区（缓冲区），同时也commit提交到了本地仓库默认：git reset = git reset --mixed，这个命令会跳转到指定版本、缓存区的文件还原、但是工作区（本地目录）下的文件不会还原git reset --hard这个命令会跳转到指定版本、缓存区的文件还原、工作区（本地目录）下的文件也会被还原git reset --soft这个命令会跳转到指定版本、缓存区的文件不会被还原、而且工作区（本地目录）下的文件也不会还原 git revertgit revert会产生一个commit，撤销某次操作，此次操作之前和之后的commit和history都会被保留，并且会把这次撤销作为一次最新的提交。","categories":[{"name":"Java","slug":"Java","permalink":"https://utinner.gitee.io/categories/Java/"}],"tags":[{"name":"git","slug":"git","permalink":"https://utinner.gitee.io/tags/git/"}]},{"title":"gitFlow工作流","slug":"gitFlow工作流","date":"2020-07-01T09:01:03.000Z","updated":"2021-12-06T09:23:00.860Z","comments":true,"path":"2020/07/01/gitFlow工作流/","link":"","permalink":"https://utinner.gitee.io/2020/07/01/gitFlow%E5%B7%A5%E4%BD%9C%E6%B5%81/","excerpt":"Gitflow工作流通过为功能开发、发布准备和维护（bug修复）分配独立的分支，让发布迭代过程更流畅。严格的分支模型也为大型项目提供了一些非常必要的结构。虽然有这么优秀的版本管理工具，但是我们面对版本管理的时候，依然有非常大得挑战，我们都知道大家工作在同一个仓库上，那么彼此的代码协作必然带来很多问题和挑战，如下：","text":"Gitflow工作流通过为功能开发、发布准备和维护（bug修复）分配独立的分支，让发布迭代过程更流畅。严格的分支模型也为大型项目提供了一些非常必要的结构。虽然有这么优秀的版本管理工具，但是我们面对版本管理的时候，依然有非常大得挑战，我们都知道大家工作在同一个仓库上，那么彼此的代码协作必然带来很多问题和挑战，如下： 如何开始一个Feature的开发，而不影响别的Feature？ 由于很容易创建新分支，分支多了如何管理，时间久了，如何知道每个分支是干什么的？哪些分支已经合并回了主干？ 如何进行Release的管理？开始一个Release的时候如何冻结Feature, 如何在Prepare Release的时候，开发人员可以继续开发新的功能？ 线上代码出Bug了，如何快速修复？而且修复的代码要包含到开发人员的分支以及下一个Release? 大部分开发人员现在使用Git就只是用三个甚至两个分支，一个是Master, 一个是Develop, 还有一个是基于Develop打得各种分支。这个在小项目规模的时候还勉强可以支撑，因为很多人做项目就只有一个Release, 但是人员一多，而且项目周期一长就会出现各种问题。 一、Git Flow常用的分支Master 分支这个分支最近发布到生产环境的代码，最近发布的Release， 这个分支只能从其他分支合并，不能在这个分支直接修改Dev 分支这个分支是我们是我们的主开发分支，包含所有要发布到下一个Release的代码，这个主要合并与其他分支，比如Feature分支Feature 分支这个分支主要是用来开发一个新的功能，一旦开发完成，我们合并回Develop分支进入下一个ReleaseRelease分支当你需要一个发布一个新Release的时候，我们基于Develop分支创建一个Release分支，完成Release后，我们合并到Master和Develop分支Hotfix分支当我们在Master发现新的Bug时候，我们需要创建一个Hotfix, 完成Hotfix后，我们合并回Master和Dev分支，所以Hotfix的改动会进入下一个Release 二、Git Flow如何工作1. Master分支所有在Master分支上的Commit应该Tag 2. Feature 分支Feature分支做完后，必须合并回Develop分支, 合并完分支后一般会删点这个Feature分支，但是我们也可以保留 每个新功能位于一个自己的分支，这样可以push到中央仓库以备份和协作。 但功能分支不是从master分支上拉出新分支，而是使用develop分支作为父分支。当新功能完成时，合并回develop分支。 新功能提交应该从不直接与master分支交互。 3. Release分支Release分支基于Develop分支创建，打完Release分之后，我们可以在这个Release分支上测试，修改Bug等。同时，其它开发人员可以基于开发新的Feature (记住：一旦打了Release分支之后不要从Develop分支上合并新的改动到Release分支) 发布Release分支时，合并Release到Master和Develop， 同时在Master分支上打个Tag记住Release版本号，然后可以删除Release分支了。 一旦develop分支上有了做一次发布（或者说快到了既定的发布日）的足够功能，就从develop分支上checkout一个发布分支。 新建的分支用于开始发布循环，所以从这个时间点开始之后新的功能不能再加到这个分支上—— 这个分支只应该做Bug修复、文档生成和其它面向发布任务。 一旦对外发布的工作都完成了，发布分支合并到master分支并分配一个版本号打好Tag。 另外，这些从新建发布分支以来的做的修改要合并回develop分支。 使用一个用于发布准备的专门分支，使得一个团队可以在完善当前的发布版本的同时，另一个团队可以继续开发下个版本的功能。 这也打造定义良好的开发阶段（比如，可以很轻松地说，『这周我们要做准备发布版本4.0』，并且在仓库的目录结构中可以实际看到）。 4. Hotfix分支hotfix分支基于Master分支创建，开发完后需要合并回Master和Develop分支，同时在Master上打一个tag该分支用于生成快速给产品发布版本（production releases）打补丁，这是唯一可以直接从master分支fork出来的分支。 修复完成，修改应该马上合并回master分支和develop分支（当前的发布分支），master分支应该用新的版本号打好Tag。 为Bug修复使用专门分支，让团队可以处理掉问题而不用打断其它工作或是等待下一个发布循环。 你可以把维护分支想成是一个直接在master分支上处理的临时发布。 三、如何进行测试Testing On Feature Branch开发人员在功能分支开发完成后，提测给对应测试人员，标明其对应的功能分支，测试人员发现bug，开发人员仍在该分支修改bug，修改完交给测试人员测试，当测试通过后，开发人员发起一个pull request合并会develop分支，然后从develop检出release，测试人员在预发环境部署并快速回归测试，发现bug，开发人员直接在release分支进行修正，测试通过后，将release合回develop并合并到master准备上线。","categories":[{"name":"Java","slug":"Java","permalink":"https://utinner.gitee.io/categories/Java/"}],"tags":[{"name":"git","slug":"git","permalink":"https://utinner.gitee.io/tags/git/"}]},{"title":"链表","slug":"链表","date":"2019-12-13T11:53:04.000Z","updated":"2021-12-06T09:23:00.938Z","comments":true,"path":"2019/12/13/链表/","link":"","permalink":"https://utinner.gitee.io/2019/12/13/%E9%93%BE%E8%A1%A8/","excerpt":"链表的定义链表是有序的列表，它在内存中的存储不一定是连续的，有如下几个特点： 链表是以节点的方式来存储的，是链式存储 每个节点包含data域、next域（指向下一个节点） 链表的各个节点不一定是连续存储 链表分带头节点的和不带头节点的链表。","text":"链表的定义链表是有序的列表，它在内存中的存储不一定是连续的，有如下几个特点： 链表是以节点的方式来存储的，是链式存储 每个节点包含data域、next域（指向下一个节点） 链表的各个节点不一定是连续存储 链表分带头节点的和不带头节点的链表。 关于链表的几个操作以下定义都是基于带头节点的链表去实现的(头节点的number值为0) 链表的定义：123456789public class Node &#123; public int number; public Node next; public Node(int number) &#123; this.number = number; &#125;&#125; 链表的基础操作（增删改查）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139public class TestLinkedList &#123; //头节点 private static Node head = new Node(0); public static void main(String[] args) &#123; Node node1 = new Node(1); Node node2 = new Node(2); Node node3 = new Node(3); Node node4 = new Node(4); Node node5 = new Node(5); addByOrder(node1); addByOrder(node2); addByOrder(node4); addByOrder(node3); addByOrder(node5); display(head);// modifyNumber(5,100);// display(head);// System.out.println(&quot;删除节点之前的长度为：&quot;+length(head));//// delete(3);// display(head);//// System.out.println(&quot;删除节点之后的长度为：&quot;+length(head));// Node revertNode = revert(head);// display(revertNode); revertPrint(head); &#125; /** * 向链表中添加元素 * @param node */ public static void add(Node node)&#123; Node temp = head; while (temp.next != null)&#123; temp = temp.next; &#125; temp.next = node; &#125; /** * 按照元素大小值排列添加元素 * @param node */ public static void addByOrder(Node node)&#123; boolean flag = false; Node temp = head; while (temp.next != null)&#123; if (temp.next.number &gt; node.number)&#123; flag = true; break; &#125; temp = temp.next; &#125; if (flag)&#123; Node nextNode = temp.next; temp.next = node; node.next = nextNode; &#125;else&#123; temp.next = node; &#125; &#125; /** * 打印链表中的元素 * @param node */ public static void display(Node node)&#123; if (node == null)&#123; System.out.println(&quot;链表为空&quot;); &#125; Node temp = node.next; while (temp != null )&#123; System.out.print(temp.number + &quot;,&quot;); temp = temp.next; &#125; System.out.println(); &#125; /** * 修改链表中指定索引的node的值 * @param index 要修改的索引下标 * @param newNum 需要修改的新值 */ public static void modifyNumber(int index ,int newNum)&#123; Node temp = head; int indexSum = 1; while (temp.next != null)&#123; if (index == indexSum)&#123; temp.next.number = newNum; break; &#125; indexSum ++; temp = temp.next; &#125; &#125; /** * 删除一个node * @param index 需要删除的索引下标 */ public static void delete(int index)&#123; Node temp = head; int indexSum = 1; while (temp.next != null)&#123; if (index == indexSum)&#123; temp.next = temp.next.next; break; &#125; indexSum ++; temp = temp.next; &#125; &#125; /** * 计算链表的长度 * @param node * @return */ public static int length(Node node)&#123; int result = 0; while (node.next != null)&#123; result++; node = node.next; &#125; return result; &#125;&#125; 将链表反转1234567891011121314151617181920212223/** * 将链表反转 * @return */public static Node revert(Node node)&#123; if (node.next == null)&#123; return null; &#125; Node revertNode = new Node(0); Node cur = node.next; Node next = null; while (cur!=null)&#123; //1.保存下一个节点指针 next = cur.next; //2.将当前节点的下一个节点指向新节点的下一个节点 cur.next = revertNode.next; //3.新节点的下一个节点指向当前节点 revertNode.next = cur; //4.当前节点为下一个节点，继续执行循环 cur = next; &#125; return revertNode;&#125; 将链表反向打印（用stack的方式）123456789101112131415/** * 将链表反向打印（stack方式） */public static void revertPrint(Node node)&#123; Node temp = node.next; Stack&lt;Node&gt; stack = new Stack&lt;&gt;(); while (temp!= null)&#123; stack.push(temp); temp = temp.next; &#125; while (stack.size() &gt; 0)&#123; Node pop = stack.pop(); System.out.println(pop.number); &#125;&#125; 递归打印链表12345678public static void printDigui(Node node)&#123; if (node.number != 0) &#123; System.out.println(node.number); &#125; if (node.next != null)&#123; printDigui(node.next); &#125; &#125; 将链表反向打印（用递归的方式）123456789//默认认为头节点的number的值为0public static void printDigui(Node node)&#123; if (node.next != null)&#123; printDigui(node.next); &#125; if (node.number != 0) &#123; System.out.println(node.number); &#125;&#125; 将链表两两反转12345678910111213141516171819/** * 链表两两反转 * @param node * @return */public static Node revertNode(Node node)&#123; Node head = node; while(head.next != null &amp;&amp; head.next.next != null)&#123; // 开始反转 Node next1 = head.next; Node next2 = next1.next; head.next = next2; next1.next = next2.next; next2.next = next1; // dummy 指针前移 head = next1; &#125; return head;&#125;","categories":[{"name":"算法和数据结构","slug":"算法和数据结构","permalink":"https://utinner.gitee.io/categories/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"链表","slug":"链表","permalink":"https://utinner.gitee.io/tags/%E9%93%BE%E8%A1%A8/"}]},{"title":"音视频行业业务名词","slug":"音视频行业业务名词","date":"2019-09-21T10:44:15.000Z","updated":"2021-12-06T09:23:00.941Z","comments":true,"path":"2019/09/21/音视频行业业务名词/","link":"","permalink":"https://utinner.gitee.io/2019/09/21/%E9%9F%B3%E8%A7%86%E9%A2%91%E8%A1%8C%E4%B8%9A%E4%B8%9A%E5%8A%A1%E5%90%8D%E8%AF%8D/","excerpt":"在K12教育行业呆了1年左右的时间，期间经历了音视频流相关的业务开发，在直播、备播行业相关的业务名词需要理解 1. 视频上传顾名思义，视频上传 即通过使用相关工具，将视频从本地导入到云端服务器进行存储的过程。一般使用阿里云OSS、七牛云进行上传到云服务上。 2. stream视频流视频流是指视频数据的传输，例如，它能够被作为一个稳定的和连续的流通过网络处理。 因为流动，客户机浏览器或插件能够在整个文件被传输完成前显示多媒体数据。 视频流式传输的优点： 启动时延大幅度缩短，边下边播，不需要等待所有内容下载完成才开始浏览。网络状况较好的情况下，卡顿较少，但快进、快退需要时间等待 对系统缓存容量的需求大大降低， 由于Internet是以包传输为基础进行断续的异步传输，数据被分解为许多包进行传输，动态变化的网络使各个包可能选择不同的路由，故到达用户计算机的时间延迟也就不同。所以，在客户端需要缓存系统来弥补延迟和抖动的影响和保证数据包传输顺序的正确，使媒体数据能连续输出，不会因网络暂时拥堵而使播放出现停顿。虽然流式传输仍需要缓存，但由于不需要把所有的动画、视音频内容都下载到缓存中，因此，对缓存的要求降低。 流式传输的实现有特定的实时传输协议采用RTSP等实时传输协议，更加适合动画、视音频在网上的流式实时传输。","text":"在K12教育行业呆了1年左右的时间，期间经历了音视频流相关的业务开发，在直播、备播行业相关的业务名词需要理解 1. 视频上传顾名思义，视频上传 即通过使用相关工具，将视频从本地导入到云端服务器进行存储的过程。一般使用阿里云OSS、七牛云进行上传到云服务上。 2. stream视频流视频流是指视频数据的传输，例如，它能够被作为一个稳定的和连续的流通过网络处理。 因为流动，客户机浏览器或插件能够在整个文件被传输完成前显示多媒体数据。 视频流式传输的优点： 启动时延大幅度缩短，边下边播，不需要等待所有内容下载完成才开始浏览。网络状况较好的情况下，卡顿较少，但快进、快退需要时间等待 对系统缓存容量的需求大大降低， 由于Internet是以包传输为基础进行断续的异步传输，数据被分解为许多包进行传输，动态变化的网络使各个包可能选择不同的路由，故到达用户计算机的时间延迟也就不同。所以，在客户端需要缓存系统来弥补延迟和抖动的影响和保证数据包传输顺序的正确，使媒体数据能连续输出，不会因网络暂时拥堵而使播放出现停顿。虽然流式传输仍需要缓存，但由于不需要把所有的动画、视音频内容都下载到缓存中，因此，对缓存的要求降低。 流式传输的实现有特定的实时传输协议采用RTSP等实时传输协议，更加适合动画、视音频在网上的流式实时传输。 2.1 流媒体的组成部分 编码工具：用于创建、捕捉和编辑多媒体数据，形成流媒体格式 流媒体数据 服务器：存放和控制流媒体的数据 网络：适合多媒体传输协议甚至是实时传输协议的网络 播放器：供客户端浏览流媒体文件 这5个部分有些是网站需要的，有些是客户端需要的，而且不同的流媒体标准和不同公司的解决方案会在某些方面有所不同。 2.2 科普各种多媒体信息的流媒体传输格式 在Internet上所传输的多媒体格式中，基本上只有文本、图形可以照原格式在网上传输。动画、音频、视频等虽然可以直接播放在网上播放，但文件偏大，即使使用专线上网，也要等完全下载后才能观看，这三种类型的媒体均要采用流式技术来进行处理以便于在网上传输。另外，还有一些如PowerPoint文件、多媒体课件等内容也需要用流式技术进行传输。 流媒体格式是将一个资料（动画、影音等）分段传送，用户不必等待整个内容传送完毕，就可以观看到即时的连续的内容，甚至可以随时的暂停、快进、快倒。由于不同的公司发展的文件格式不同，传送的方式也有所差异，因此，我们必须非常清楚各种流媒体文件的格式。 2.3 视频播放流媒体是从英语Streaming Media中翻译过来，它是一种可以使音频、视频和其它多媒体能在Internet及Intranet上以实时的、无需下载等待的方式进行播放的技术。流媒体文件格式是支持采用流式传输及播放的媒体格式。流式传输方式是将动画、视音频等多媒体文件经过特殊的压缩方式分成一个个压缩包用户不必像非流式播放那样等到整个文件全部下载完毕后才能看到当中的内容，而是只需经过几秒或几十秒的启动延时即可在用户的计算机上利用相应的播放器或其它的硬件、软件对压缩的动画、视音频等流式多媒体文件解压后进行播放和观看，多媒体文件的剩余部分将在后台的服务器内继续下载。 2.4 流式下载编辑下载边播放的BT软件,下载时必须要从电影的开头下载,而并非是其它BT软件的下载方式，这种可以边下载边播放的下载方式,就可以称为流式下载。 如果想要边下载边播放的话,就推荐你用流式下载。 如果是其它无法在线播放的资源,推荐使用非流式下载。媒体是指采用流式传输的方式在Internet播放的媒体格式。流式传输方式则是将整个A/V及3D等多媒体文件经过特殊的压缩方式分成一个个压缩包，由视频服务器向用户计算机连续、实时传送。在采用流式传输方式的系统中，用户不必像采用下载方式那样等到整个文件全部下载完毕，而是只需经过几秒或几十秒的启动延时即可在用户的计算机上利用解压设备(硬件或软件)对压缩的A/V、3D等多媒体文件解压后进行播放和观看。此时多媒体文件的剩余部分将在后台的服务器内继续下载。与单纯的下载方式相比，这种对多媒体文件边下载边播放的流式传输方式不仅使启动延时大幅度地缩短，而且对系统缓存容量的需求也大大降低。 3. H264 H265H.265与H.264有何不同,同等画质体积仅为一半、带宽占用省一半、画质更细腻等诸多优势 首先分别介绍一下：H.264与H.265 H.264也称作MPEG-4AVC(Advanced Video Codec，高级视频编码)，是一种视频压缩标准，同时也是一种被广泛使用的高精度视频的录制、压缩和发布格式。H.264因其是蓝光光盘的一种编解码标准而着名，所有蓝光播放器都必须能解码H.264。H.264相较于以前的编码标准有着一些新特性，如多参考帧的运动补偿、变块尺寸运动补偿、帧内预测编码等，通过利用这些新特性，H.264比其他编码标准有着更高的视频质量和更低的码率 H.265/HEVC的编码架构大致上和H.264/AVC的架构相似，也主要包含：帧内预测(intra prediction)、帧间预测(inter prediction)、转换 (transform)、量化 (quantization)、去区块滤波器(deblocking filter)、熵编码(entropy coding)等模块。但在HEVC编码架构中，整体被分为了三个基本单位，分别是：编码单位(coding unit，CU)、预测单位(predict unit，PU) 和转换单位(transform unit，TU )。 H.265是新的编码协议，也即是H.264的升级版。 4. 视频拆条视频拆条是因互联网视频和新媒体短视频内容平台的需要，对传统电视媒体节目进行二次加工，将原来完整的一条节目内容，按照某种逻辑思维或特定需要，将其拆分成多条视频。 互联网视频内容的主要来源包括传统电视媒体的节目、各类机构视频成品、影视公司影视作品，通过将这些视频拆条，可以深度挖掘有价值的信息，重新编目后，可用于IPTV、OTT、手机电视和新媒体短视频平台，满足新媒体视听节目碎片化要求，是视音频编目行业一个新的尝试和探索。 5.视频抽帧从视频流中截取关键的帧 简单的说，视频抽帧就是从视频中把要做抽帧的片段在轨道里放到能看见一帧帧画面的模式，用刀片再割断删除你要去除的某帧，比如每隔一帧去除一帧，或者每隔三帧去除二帧~等等等等，然后将剩下的帧移动紧挨对齐，这就是抽帧。 6. 视频帧率视频帧率（Frame rate）是用于测量显示帧数的量度。所谓的测量单位为每秒显示帧数(Frames per Second，简：FPS）或“赫兹”（Hz）。此词多用于影视制作和电子游戏。 7. 视频分发一般视频分发基于算法进行 视频来源多样化，有的基于UCG（用户主动生成），有些基于爬虫，爬取其他平台的内容（一般都有水印） 视频分发还可以配合精准推荐算法，进行定向广告投放 在爱奇艺头条的商业化上，爱奇艺与百度合作力求让信息流广告更精准：依托从百度搜索引擎的数据，知道每个爱奇艺用户过去三十天在百度上搜索过什么类型关键词，根据他的消费兴趣爱好，可以帮助广告主投放定向广告。无论对于广告主、视频创作者还是爱奇艺，这都是件好事。 8. 视频缩略图一般会抽取视频第一帧作为视频缩略图，或者支持后台上传图片作为视频缩略图 9. ffmpegFFmpeg是一个开源免费跨平台的视频和音频流方案，属于自由软件，采用LGPL或GPL许可证（依据你选择的组件）。它提供了录制、转换以及流化音视频的完整解决方案。它包含了非常先进的音频/视频编解码库libavcodec，为了保证高可移植性和编解码质量，libavcodec里很多codec都是从头开发的。 这个项目最早由Fabrice Bellard发起，现在由Michael Niedermayer维护。许多FFmpeg的开发人员都来自MPlayer项目，而且当前FFmpeg也是放在MPlayer项目组的服务器上。项目的名称来自MPEG视频编码标准，前面的”FF”代表”Fast Forward”。 FFmpeg是一套可以用来记录、转换数字音频、视频，并能将其转化为流的开源计算机程序。它包括了目前领先的音/视频编码库libavcodec。 FFmpeg是在Linux下开发出来的，但它可以在包括Windows在内的大多数操作系统中编译。这个项目是由Fabrice Bellard发起的，现在由Michael Niedermayer主持。可以轻易地实现多种视频格式之间的相互转换，例如可以将摄录下的视频avi等转成现在视频网站所采用的flv格式。 10. 视频加工通过工具对视频进行基本分析（长宽），格式校验，压缩，编解码，格式转换，缩略图抽取等操作 11. 视频格式 问题：本地视频文件常见有MP4、MKV、AVI等，这些都是什么？有什么区别？ 首先，MP4、AVI、MKV都是本地视频文件的后缀，在windows系统下，用于提示操作系统应该采用哪个应用程序打开。而在流媒体领域，这些都被称为『视频封装格式』，因为除了音视频流之外，它们还包含了一些辅助信息以及组织视音频的方式。不同格式的视频在不同平台上用户体验不同，很大原因在于对视音频的组织方式带来的差异。笔者以为百度百科上的解释蛮通俗易懂的（维基百科的说法不够直白）： 视频格式是视频播放软件为了能够播放视频文件而赋予视频文件的一种识别符号。 简言之，视频格式规定了和播放器的通信协议。 12. 视频协议 问题：在腾讯视频、哔哩哔哩网上看的视频，与本地播放的MP4、MKV、AVI文件，有什么区别？ 『视频协议』是针对网络流媒体而言的，也就是只有在有网络时通过浏览器或者移动端APP才能看到的视频，目前常见的协议有RTSP、RTMP、HLS、HTTP等。笔者短暂地接触过GStreamer开发，在连接到RSTP视频时，发现除了视音频流和metadata之外，还携带了播放的信令。 也有文章会把『视频协议』归入『视频封装格式』。『视频协议』和『视频封装格式』都同时携带了视音频和metadata，以及协议/格式需要的其他信息。以FFMpeg为例，并不区分视频格式和视频协议；但是GStreamer的话，还时需要指定『视频协议』，但是不区分『视频封装格式』。 剥开『视频封装格式』和『视频协议』的外壳，接下来了解视音频流本身，这才是流媒体领域中真正的主角。 13. 视频流 以及 编解码 / 视频转码就视频流而言，相信大家平时一定经常听到类似“h264码流”、“yuv流”、“编码流”、“解码流”，“原始流”、“裸流”，“压缩后的流”或者“未压缩的流”等等。归纳而言，提到『视频流』的时候，一定只有两种形式： 经过压缩算法压缩的流数据，称为『编码流』，又因为目前压缩/编码算法以H264为主，因此也常常称为『H264码流』。 未经压缩的流数据，是解码后的流数据，称为『原始流』，可以想象视频是由一幅一幅在时间上连续的“图像”组成的，而因为视频内部的“图像”是『YUV』（后文将介绍），因此也常常称为『YUV流』。 总结出现的名称，“h264码流”、“编码流”、“压缩后的流”是压缩/编码后的视频流；而“yuv流”、“解码流”、“未压缩的流”则是未经压缩/编码的视频流。“裸流”是一个具有歧义的词，是上下文内容，既可以是前者，也可以是后者。 因此，如果以后阅读任何流媒体相关的文章时，看到『视频流』都应该搞清楚，这究竟是编码/压缩的，还是没有。在生活中，接触到的视频文件绝大部分都是编码/压缩后的；在网络传输场景中，绝大部分也是编码/压缩后的。只有在视频播放时，观众观赏到的时一帧帧被『转码』为『RGB』的解码后视频流。 编码/压缩在流媒体领域是一项非常重要的技术：从『H264码流』到『YUV流』的过程称为解码，反之称为编码 14. 常见的帧名词(重点)14.1 帧率（FPS）『帧率』，FPS，全称Frames Per Second。指每秒传输的帧数，或者每秒显示的帧数，一般来说，『帧率』影响画面流畅度，且成正比：帧率越大，画面越流畅；帧率越小，画面越有跳动感。一个较权威的说法：当视频帧率不低于24fps时，人眼才会觉得视频时连贯的，称为“视觉暂留”现象。因此，才有说法：尽管『帧率』越高越流畅，但在很多实际应用场景中24fps就可以了。 14.2 分辨率（Resolution）『分辨率』，也常被俗称为『图像的尺寸』或者『图像的大小』。指一帧图像包含的像素的多少，常见有1280x720（720P），1920X1080（1080P）等规格。『分辨率』影响图像大小，且与之成正比：『分辨率』越高，图像越大；反之，图像越小。 14.3 码率（BPS）『码率』，BPS，全称Bits Per Second。指每秒传送的数据位数，常见单位KBPS（千位每秒）和MBPS（兆位每秒）。笔者认为这个概念真正要理解起来还是需要好好说明的，网上一说：“『码率』与体积成正比：码率越大，体积越大；码率越小，体积越小”；另一说：“『码率』越大，说明单位时间内取样率越大，数据流精度就越高，这样表现出来的的效果就是：视频画面更清晰画质更高”；还有说法是：“『码率』就是『失真度』”。 15. 参考链接https://www.bgteach.com/article/134","categories":[{"name":"程序员","slug":"程序员","permalink":"https://utinner.gitee.io/categories/%E7%A8%8B%E5%BA%8F%E5%91%98/"}],"tags":[{"name":"音视频行业","slug":"音视频行业","permalink":"https://utinner.gitee.io/tags/%E9%9F%B3%E8%A7%86%E9%A2%91%E8%A1%8C%E4%B8%9A/"},{"name":"科普","slug":"科普","permalink":"https://utinner.gitee.io/tags/%E7%A7%91%E6%99%AE/"}]},{"title":"Fork/Join分而治之","slug":"分而治之","date":"2018-01-09T06:10:00.000Z","updated":"2021-12-06T09:23:00.903Z","comments":true,"path":"2018/01/09/分而治之/","link":"","permalink":"https://utinner.gitee.io/2018/01/09/%E5%88%86%E8%80%8C%E6%B2%BB%E4%B9%8B/","excerpt":"一、十大经典算法快速排序、堆排序、归并排序、二分查找、线性查找、深度优先、广度优先、Dijkstra、动态规划、朴素贝叶斯分类（黑体的算法体现了分而治之的思想）动态规划与分而治之特别像，但是不算是分而治之。 分而治之的小问题之间是相互独立的，没有关联的。 动态规划的小问题之间是有关联的。外部排序：https://blog.csdn.net/zssapple/article/details/82770607体现了分而治之的思想，本质上来说就是归并排序 二、Fork/JoinFork/Join框架：就是在必要的情况下，将一个大任务拆分（fork）成若干个小任务（拆到不可再拆时），再将一个个的小任务运算的结果进行join汇总。Fork/Join 将任务调度的部分给程序员屏蔽掉了。我们只需要关心如何把任务进行拆解以及每个具体任务怎么做就可以了。除此之外，Fork/Join还提供了一个工作密取的概念。不同的小任务执行的速度也是不一样的，假设现在有两个线程去分别执行50个小任务，A线程提前完事了，然后看到B线程还有20个任务没有完事，A线程就会去窃取B线程尾部的任务去处理，处理完之后再将任务塞回到B线程的任务队列中去。工作密取就是为了提高CPU的利用率而设计的。","text":"一、十大经典算法快速排序、堆排序、归并排序、二分查找、线性查找、深度优先、广度优先、Dijkstra、动态规划、朴素贝叶斯分类（黑体的算法体现了分而治之的思想）动态规划与分而治之特别像，但是不算是分而治之。 分而治之的小问题之间是相互独立的，没有关联的。 动态规划的小问题之间是有关联的。外部排序：https://blog.csdn.net/zssapple/article/details/82770607体现了分而治之的思想，本质上来说就是归并排序 二、Fork/JoinFork/Join框架：就是在必要的情况下，将一个大任务拆分（fork）成若干个小任务（拆到不可再拆时），再将一个个的小任务运算的结果进行join汇总。Fork/Join 将任务调度的部分给程序员屏蔽掉了。我们只需要关心如何把任务进行拆解以及每个具体任务怎么做就可以了。除此之外，Fork/Join还提供了一个工作密取的概念。不同的小任务执行的速度也是不一样的，假设现在有两个线程去分别执行50个小任务，A线程提前完事了，然后看到B线程还有20个任务没有完事，A线程就会去窃取B线程尾部的任务去处理，处理完之后再将任务塞回到B线程的任务队列中去。工作密取就是为了提高CPU的利用率而设计的。 如何使用？JDK将Fork/Join框架进行了一个抽象，抽象成了一个ForkJoinTask抽象类。为了方便实现，还提供了两个实现类，一个是RecursiveTask，另一个是RecursiveAction。它们都是抽象类，RecursiveTask有个泛型，泛型意味着有返回结果，而action是没有返回结果的任务。产生任务之后如何去执行呢？jdk交给ForkJoinPool这个线程池去执行。ForkJoinPool中有三个方法： invoke：是一个同步方法,当我们调用这个方法之后，必须等这个任务全部完成了，invoke会返回一个任务的执行结果，在那之后我才能执行后面的代码。 submit、execute：异步方法，不必要等待全部执行，可以执行后面的代码。execute没有返回值，而submit会有一个返回值，返回一个ForkJoinTask，然后我们可以通过一个get()方法拿到执行结果。 使用范式我们只需要关心在compute方法中任务的拆分以及任务的业务实现就可以了。 二、使用Fork/Join完成归并排序参考：forkjoin相关代码示例 三、常用的并发工具类1.CountDownLatch闭锁，CountDownLatch这个类能够使一个线程等待其他线程完成各自的工作后再执行。例如，应用程序的主线程希望在负责启动框架服务的线程已经启动所有的框架服务之后再执行。CountDownLatch是通过一个计数器来实现的，计数器的初始值为初始任务的数量。每当完成了一个任务后，计数器的值就会减1（CountDownLatch.countDown()方法）。当计数器值到达0时，它表示所有的已经完成了任务，然后在闭锁上等待CountDownLatch.await()方法的线程就可以恢复执行任务。实现最大的并行性：有时我们想同时启动多个线程，实现最大程度的并行性。例如，我们想测试一个单例类。如果我们创建一个初始计数为1的CountDownLatch，并让所有线程都在这个锁上等待，那么我们可以很轻松地完成测试。我们只需调用 一次countDown()方法就可以让所有的等待线程同时恢复执行。开始执行前等待n个线程完成各自任务：例如应用程序启动类要确保在处理用户请求前，所有N个外部系统已经启动和运行了，例如处理excel中多个表单。 2.CyclicBarrierCyclicBarrier的字面意思是可循环使用（Cyclic）的屏障（Barrier）。它要做的事情是，让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续运行。CyclicBarrier默认的构造方法是CyclicBarrier（int parties），其参数表示屏障拦截的线程数量，每个线程调用await方法告诉CyclicBarrier我已经到达了屏障，然后当前线程被阻塞。CyclicBarrier还提供一个更高级的构造函数CyclicBarrier（int parties，Runnable barrierAction），用于在线程到达屏障时，优先执行barrierAction，方便处理更复杂的业务场景。CyclicBarrier可以用于多线程计算数据，最后合并计算结果的场景。 3.CyclicBarrier和CountDownLatch的区别CountDownLatch的计数器只能使用一次，而CyclicBarrier的计数器可以使用reset()方法重置，CountDownLatch.await一般阻塞主线程，所有的工作线程执行countDown，而CyclicBarrierton通过工作线程调用await从而阻塞工作线程，直到所有工作线程达到屏障。 4.控制并发线程数的SemaphoreSemaphore（信号量）是用来控制同时访问特定资源的线程数量，它通过协调各个线程，以保证合理的使用公共资源。应用场景Semaphore可以用于做流量控制，特别是公用资源有限的应用场景，比如数据库连接。假如有一个需求，几十个线程并发地存储到数据库中，而数据库的连接数只有10个，这时我们必须控制只有10个线程同时获取数据库连接保存数据，否则会报错无法获取数据库连接。这个时候，就可以使用Semaphore来做流量控制。。Semaphore的构造方法Semaphore（int permits）接受一个整型的数字，表示可用的许可证数量。Semaphore的用法也很简单，首先线程使用Semaphore的acquire()方法获取一个许可证，使用完之后调用release()方法归还许可证。还可以用tryAcquire()方法尝试获取许可证。Semaphore还提供一些其他方法，具体如下。 intavailablePermits()：返回此信号量中当前可用的许可证数。 intgetQueueLength()：返回正在等待获取许可证的线程数。 booleanhasQueuedThreads()：是否有线程正在等待获取许可证。 void reducePermits（int reduction）：减少reduction个许可证，是个protected方法。 Collection getQueuedThreads()：返回所有等待获取许可证的线程集合，是个protected方法。 5.ExchangerExchanger（交换者）是一个用于线程间协作的工具类。Exchanger用于进行线程间的数据交换。它提供一个同步点，在这个同步点，两个线程可以交换彼此的数据。这两个线程通过exchange方法交换数据，如果第一个线程先执行exchange()方法，它会一直等待第二个线程也执行exchange方法，当两个线程都到达同步点时，这两个线程就可以交换数据，将本线程生产出来的数据传递给对方。","categories":[{"name":"Java","slug":"Java","permalink":"https://utinner.gitee.io/categories/Java/"}],"tags":[{"name":"Java基础","slug":"Java基础","permalink":"https://utinner.gitee.io/tags/Java%E5%9F%BA%E7%A1%80/"}]}],"categories":[{"name":"生活小记","slug":"生活小记","permalink":"https://utinner.gitee.io/categories/%E7%94%9F%E6%B4%BB%E5%B0%8F%E8%AE%B0/"},{"name":"考研英语","slug":"考研英语","permalink":"https://utinner.gitee.io/categories/%E8%80%83%E7%A0%94%E8%8B%B1%E8%AF%AD/"},{"name":"Java","slug":"Java","permalink":"https://utinner.gitee.io/categories/Java/"},{"name":"计算机基础","slug":"计算机基础","permalink":"https://utinner.gitee.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"},{"name":"运维","slug":"运维","permalink":"https://utinner.gitee.io/categories/%E8%BF%90%E7%BB%B4/"},{"name":"数据库","slug":"数据库","permalink":"https://utinner.gitee.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"中间件","slug":"中间件","permalink":"https://utinner.gitee.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"大数据","slug":"大数据","permalink":"https://utinner.gitee.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"面试题","slug":"面试题","permalink":"https://utinner.gitee.io/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"name":"算法和数据结构","slug":"算法和数据结构","permalink":"https://utinner.gitee.io/categories/%E7%AE%97%E6%B3%95%E5%92%8C%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"程序员","slug":"程序员","permalink":"https://utinner.gitee.io/categories/%E7%A8%8B%E5%BA%8F%E5%91%98/"}],"tags":[{"name":"生活","slug":"生活","permalink":"https://utinner.gitee.io/tags/%E7%94%9F%E6%B4%BB/"},{"name":"考研英语","slug":"考研英语","permalink":"https://utinner.gitee.io/tags/%E8%80%83%E7%A0%94%E8%8B%B1%E8%AF%AD/"},{"name":"定时任务","slug":"定时任务","permalink":"https://utinner.gitee.io/tags/%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1/"},{"name":"Java","slug":"Java","permalink":"https://utinner.gitee.io/tags/Java/"},{"name":"IO","slug":"IO","permalink":"https://utinner.gitee.io/tags/IO/"},{"name":"网络","slug":"网络","permalink":"https://utinner.gitee.io/tags/%E7%BD%91%E7%BB%9C/"},{"name":"http，ssl","slug":"http，ssl","permalink":"https://utinner.gitee.io/tags/http%EF%BC%8Cssl/"},{"name":"JVM","slug":"JVM","permalink":"https://utinner.gitee.io/tags/JVM/"},{"name":"多线程","slug":"多线程","permalink":"https://utinner.gitee.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"内存模型","slug":"内存模型","permalink":"https://utinner.gitee.io/tags/%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/"},{"name":"Docker","slug":"Docker","permalink":"https://utinner.gitee.io/tags/Docker/"},{"name":"Java基础","slug":"Java基础","permalink":"https://utinner.gitee.io/tags/Java%E5%9F%BA%E7%A1%80/"},{"name":"MongoDB","slug":"MongoDB","permalink":"https://utinner.gitee.io/tags/MongoDB/"},{"name":"Mysql","slug":"Mysql","permalink":"https://utinner.gitee.io/tags/Mysql/"},{"name":"redis","slug":"redis","permalink":"https://utinner.gitee.io/tags/redis/"},{"name":"Spring","slug":"Spring","permalink":"https://utinner.gitee.io/tags/Spring/"},{"name":"基础知识","slug":"基础知识","permalink":"https://utinner.gitee.io/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"name":"Flink","slug":"Flink","permalink":"https://utinner.gitee.io/tags/Flink/"},{"name":"面试题","slug":"面试题","permalink":"https://utinner.gitee.io/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"name":"分布式","slug":"分布式","permalink":"https://utinner.gitee.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://utinner.gitee.io/tags/SpringCloud/"},{"name":"Maven","slug":"Maven","permalink":"https://utinner.gitee.io/tags/Maven/"},{"name":"git","slug":"git","permalink":"https://utinner.gitee.io/tags/git/"},{"name":"链表","slug":"链表","permalink":"https://utinner.gitee.io/tags/%E9%93%BE%E8%A1%A8/"},{"name":"音视频行业","slug":"音视频行业","permalink":"https://utinner.gitee.io/tags/%E9%9F%B3%E8%A7%86%E9%A2%91%E8%A1%8C%E4%B8%9A/"},{"name":"科普","slug":"科普","permalink":"https://utinner.gitee.io/tags/%E7%A7%91%E6%99%AE/"}]}